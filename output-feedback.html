<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Output Feedback | Optimal Control and Estimation</title>
  <meta name="description" content="Lecture notes for Harvard ES/AM 158 Introduction to Optimal Control and Estimation." />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Output Feedback | Optimal Control and Estimation" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Lecture notes for Harvard ES/AM 158 Introduction to Optimal Control and Estimation." />
  <meta name="github-repo" content="hankyang94/OptimalControlEstimation" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Output Feedback | Optimal Control and Estimation" />
  
  <meta name="twitter:description" content="Lecture notes for Harvard ES/AM 158 Introduction to Optimal Control and Estimation." />
  

<meta name="author" content="Heng Yang" />


<meta name="date" content="2025-03-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="stability.html"/>
<link rel="next" href="geometric-vision.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Optimal Control and Estimation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="formulation.html"><a href="formulation.html"><i class="fa fa-check"></i><b>1</b> The Optimal Control Formulation</a>
<ul>
<li class="chapter" data-level="1.1" data-path="formulation.html"><a href="formulation.html#the-basic-problem"><i class="fa fa-check"></i><b>1.1</b> The Basic Problem</a></li>
<li class="chapter" data-level="1.2" data-path="formulation.html"><a href="formulation.html#dynamic-programming-and-principle-of-optimality"><i class="fa fa-check"></i><b>1.2</b> Dynamic Programming and Principle of Optimality</a></li>
<li class="chapter" data-level="1.3" data-path="formulation.html"><a href="formulation.html#infinite-horizon"><i class="fa fa-check"></i><b>1.3</b> Infinite-horizon Formulation</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="exactdp.html"><a href="exactdp.html"><i class="fa fa-check"></i><b>2</b> Exact Dynamic Programming</a>
<ul>
<li class="chapter" data-level="2.1" data-path="exactdp.html"><a href="exactdp.html#lqr"><i class="fa fa-check"></i><b>2.1</b> Linear Quadratic Regulator</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="exactdp.html"><a href="exactdp.html#infinite-horizon-lqr"><i class="fa fa-check"></i><b>2.1.1</b> Infinite-Horizon LQR</a></li>
<li class="chapter" data-level="2.1.2" data-path="exactdp.html"><a href="exactdp.html#lqr-with-constraints"><i class="fa fa-check"></i><b>2.1.2</b> LQR with Constraints</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="exactdp.html"><a href="exactdp.html#mdp-exact-dp"><i class="fa fa-check"></i><b>2.2</b> Markov Decision Process</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="exactdp.html"><a href="exactdp.html#bellman-optimality-equations"><i class="fa fa-check"></i><b>2.2.1</b> Bellman Optimality Equations</a></li>
<li class="chapter" data-level="2.2.2" data-path="exactdp.html"><a href="exactdp.html#value-iteration"><i class="fa fa-check"></i><b>2.2.2</b> Value Iteration</a></li>
<li class="chapter" data-level="2.2.3" data-path="exactdp.html"><a href="exactdp.html#value-iteration-with-barycentric-interpolation"><i class="fa fa-check"></i><b>2.2.3</b> Value Iteration with Barycentric Interpolation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="approximatedp.html"><a href="approximatedp.html"><i class="fa fa-check"></i><b>3</b> Approximate Optimal Control</a>
<ul>
<li class="chapter" data-level="3.1" data-path="approximatedp.html"><a href="approximatedp.html#fitted-value-iteration"><i class="fa fa-check"></i><b>3.1</b> Fitted Value Iteration</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="approximatedp.html"><a href="approximatedp.html#linear-features"><i class="fa fa-check"></i><b>3.1.1</b> Linear Features</a></li>
<li class="chapter" data-level="3.1.2" data-path="approximatedp.html"><a href="approximatedp.html#neural-network-features"><i class="fa fa-check"></i><b>3.1.2</b> Neural Network Features</a></li>
<li class="chapter" data-level="3.1.3" data-path="approximatedp.html"><a href="approximatedp.html#fitted-q-value-iteration"><i class="fa fa-check"></i><b>3.1.3</b> Fitted Q-value Iteration</a></li>
<li class="chapter" data-level="3.1.4" data-path="approximatedp.html"><a href="approximatedp.html#deep-q-network"><i class="fa fa-check"></i><b>3.1.4</b> Deep Q Network</a></li>
<li class="chapter" data-level="3.1.5" data-path="approximatedp.html"><a href="approximatedp.html#deep-shallow"><i class="fa fa-check"></i><b>3.1.5</b> Deep + Shallow</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="approximatedp.html"><a href="approximatedp.html#trajectory-optimization"><i class="fa fa-check"></i><b>3.2</b> Trajectory Optimization</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="approximatedp.html"><a href="approximatedp.html#direct-single-shooting"><i class="fa fa-check"></i><b>3.2.1</b> Direct Single Shooting</a></li>
<li class="chapter" data-level="3.2.2" data-path="approximatedp.html"><a href="approximatedp.html#direct-multiple-shooting"><i class="fa fa-check"></i><b>3.2.2</b> Direct Multiple Shooting</a></li>
<li class="chapter" data-level="3.2.3" data-path="approximatedp.html"><a href="approximatedp.html#direct-collocation"><i class="fa fa-check"></i><b>3.2.3</b> Direct Collocation</a></li>
<li class="chapter" data-level="3.2.4" data-path="approximatedp.html"><a href="approximatedp.html#direct-orthogonal-collocation"><i class="fa fa-check"></i><b>3.2.4</b> Direct Orthogonal Collocation</a></li>
<li class="chapter" data-level="3.2.5" data-path="approximatedp.html"><a href="approximatedp.html#failure-of-open-loop-control"><i class="fa fa-check"></i><b>3.2.5</b> Failure of Open-Loop Control</a></li>
<li class="chapter" data-level="3.2.6" data-path="approximatedp.html"><a href="approximatedp.html#lqr-trajectory-tracking"><i class="fa fa-check"></i><b>3.2.6</b> LQR Trajectory Tracking</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="approximatedp.html"><a href="approximatedp.html#model-predictive-control"><i class="fa fa-check"></i><b>3.3</b> Model Predictive Control</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="approximatedp.html"><a href="approximatedp.html#turn-trajectory-optimization-into-feedback-control"><i class="fa fa-check"></i><b>3.3.1</b> Turn Trajectory Optimization into Feedback Control</a></li>
<li class="chapter" data-level="3.3.2" data-path="approximatedp.html"><a href="approximatedp.html#controllability-reachability-and-invariance"><i class="fa fa-check"></i><b>3.3.2</b> Controllability, Reachability, and Invariance</a></li>
<li class="chapter" data-level="3.3.3" data-path="approximatedp.html"><a href="approximatedp.html#basic-formulation-for-linear-systems"><i class="fa fa-check"></i><b>3.3.3</b> Basic Formulation for Linear Systems</a></li>
<li class="chapter" data-level="3.3.4" data-path="approximatedp.html"><a href="approximatedp.html#persistent-feasibility"><i class="fa fa-check"></i><b>3.3.4</b> Persistent Feasibility</a></li>
<li class="chapter" data-level="3.3.5" data-path="approximatedp.html"><a href="approximatedp.html#mpc-stability"><i class="fa fa-check"></i><b>3.3.5</b> Stability</a></li>
<li class="chapter" data-level="3.3.6" data-path="approximatedp.html"><a href="approximatedp.html#explicit-mpc"><i class="fa fa-check"></i><b>3.3.6</b> Explicit MPC</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="approximatedp.html"><a href="approximatedp.html#policy-gradient"><i class="fa fa-check"></i><b>3.4</b> Policy Gradient</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html"><i class="fa fa-check"></i><b>4</b> Continuous-time Optimal Control</a>
<ul>
<li class="chapter" data-level="4.1" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#the-basic-problem-1"><i class="fa fa-check"></i><b>4.1</b> The Basic Problem</a></li>
<li class="chapter" data-level="4.2" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#the-hamilton-jacobi-bellman-equation"><i class="fa fa-check"></i><b>4.2</b> The Hamilton-Jacobi-Bellman Equation</a></li>
<li class="chapter" data-level="4.3" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#linear-quadratic-regulator"><i class="fa fa-check"></i><b>4.3</b> Linear Quadratic Regulator</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#lqr-trajectory-tracking-1"><i class="fa fa-check"></i><b>4.3.1</b> LQR Trajectory Tracking</a></li>
<li class="chapter" data-level="4.3.2" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#lqr-trajectory-stabilization"><i class="fa fa-check"></i><b>4.3.2</b> LQR Trajectory Stabilization</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#the-pontryagin-minimum-principle"><i class="fa fa-check"></i><b>4.4</b> The Pontryagin Minimum Principle</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#numerical-solution-of-the-tpbvp"><i class="fa fa-check"></i><b>4.4.1</b> Numerical Solution of the TPBVP</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#infinite-horizon-problems"><i class="fa fa-check"></i><b>4.5</b> Infinite-Horizon Problems</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#continuous-time-infinite-horizon-lqr"><i class="fa fa-check"></i><b>4.5.1</b> Infinite-Horizon LQR</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#viscosity-solution"><i class="fa fa-check"></i><b>4.6</b> Viscosity Solution</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="stability.html"><a href="stability.html"><i class="fa fa-check"></i><b>5</b> Stability Analysis</a>
<ul>
<li class="chapter" data-level="5.1" data-path="stability.html"><a href="stability.html#autonomous-systems"><i class="fa fa-check"></i><b>5.1</b> Autonomous Systems</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="stability.html"><a href="stability.html#concepts-of-stability"><i class="fa fa-check"></i><b>5.1.1</b> Concepts of Stability</a></li>
<li class="chapter" data-level="5.1.2" data-path="stability.html"><a href="stability.html#stability-by-linearization"><i class="fa fa-check"></i><b>5.1.2</b> Stability by Linearization</a></li>
<li class="chapter" data-level="5.1.3" data-path="stability.html"><a href="stability.html#lyapunov-analysis"><i class="fa fa-check"></i><b>5.1.3</b> Lyapunov Analysis</a></li>
<li class="chapter" data-level="5.1.4" data-path="stability.html"><a href="stability.html#invariant-set-theorem"><i class="fa fa-check"></i><b>5.1.4</b> Invariant Set Theorem</a></li>
<li class="chapter" data-level="5.1.5" data-path="stability.html"><a href="stability.html#computing-lyapunov-certificates"><i class="fa fa-check"></i><b>5.1.5</b> Computing Lyapunov Certificates</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="stability.html"><a href="stability.html#controlled-systems"><i class="fa fa-check"></i><b>5.2</b> Controlled Systems</a></li>
<li class="chapter" data-level="5.3" data-path="stability.html"><a href="stability.html#non-autonomous-systems"><i class="fa fa-check"></i><b>5.3</b> Non-autonomous Systems</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="output-feedback.html"><a href="output-feedback.html"><i class="fa fa-check"></i><b>6</b> Output Feedback</a>
<ul>
<li class="chapter" data-level="6.1" data-path="output-feedback.html"><a href="output-feedback.html#least-squares-estimation"><i class="fa fa-check"></i><b>6.1</b> Least-Squares Estimation</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="output-feedback.html"><a href="output-feedback.html#linear-least-squares-estimation"><i class="fa fa-check"></i><b>6.1.1</b> Linear Least-Squares Estimation</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="output-feedback.html"><a href="output-feedback.html#kalman-filter"><i class="fa fa-check"></i><b>6.2</b> Kalman Filter</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="output-feedback.html"><a href="output-feedback.html#steady-state-kalman-filter"><i class="fa fa-check"></i><b>6.2.1</b> Steady-State Kalman Filter</a></li>
<li class="chapter" data-level="6.2.2" data-path="output-feedback.html"><a href="output-feedback.html#continuous-time-kalman-filter"><i class="fa fa-check"></i><b>6.2.2</b> Continuous-time Kalman Filter</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="output-feedback.html"><a href="output-feedback.html#linear-quadratic-gaussian-control"><i class="fa fa-check"></i><b>6.3</b> Linear Quadratic Gaussian Control</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="output-feedback.html"><a href="output-feedback.html#steady-state-lqg"><i class="fa fa-check"></i><b>6.3.1</b> Steady-state LQG</a></li>
<li class="chapter" data-level="6.3.2" data-path="output-feedback.html"><a href="output-feedback.html#continuous-time-lqg"><i class="fa fa-check"></i><b>6.3.2</b> Continuous-time LQG</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="output-feedback.html"><a href="output-feedback.html#nonlinear-filtering"><i class="fa fa-check"></i><b>6.4</b> Nonlinear Filtering</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="output-feedback.html"><a href="output-feedback.html#extended-kalman-filter"><i class="fa fa-check"></i><b>6.4.1</b> Extended Kalman Filter</a></li>
<li class="chapter" data-level="6.4.2" data-path="output-feedback.html"><a href="output-feedback.html#unscented-kalman-filter"><i class="fa fa-check"></i><b>6.4.2</b> Unscented Kalman Filter</a></li>
<li class="chapter" data-level="6.4.3" data-path="output-feedback.html"><a href="output-feedback.html#particle-filter"><i class="fa fa-check"></i><b>6.4.3</b> Particle Filter</a></li>
<li class="chapter" data-level="6.4.4" data-path="output-feedback.html"><a href="output-feedback.html#feedback-particle-filter"><i class="fa fa-check"></i><b>6.4.4</b> Feedback Particle Filter</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="output-feedback.html"><a href="output-feedback.html#state-observer"><i class="fa fa-check"></i><b>6.5</b> State Observer</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="output-feedback.html"><a href="output-feedback.html#general-design-strategy"><i class="fa fa-check"></i><b>6.5.1</b> General Design Strategy</a></li>
<li class="chapter" data-level="6.5.2" data-path="output-feedback.html"><a href="output-feedback.html#luenberger-template"><i class="fa fa-check"></i><b>6.5.2</b> Luenberger Template</a></li>
<li class="chapter" data-level="6.5.3" data-path="output-feedback.html"><a href="output-feedback.html#state-affine-template"><i class="fa fa-check"></i><b>6.5.3</b> State-affine Template</a></li>
<li class="chapter" data-level="6.5.4" data-path="output-feedback.html"><a href="output-feedback.html#kazantzis-kravaris-luenberger-kkl-template"><i class="fa fa-check"></i><b>6.5.4</b> Kazantzis-Kravaris-Luenberger (KKL) Template</a></li>
<li class="chapter" data-level="6.5.5" data-path="output-feedback.html"><a href="output-feedback.html#triangular-template"><i class="fa fa-check"></i><b>6.5.5</b> Triangular Template</a></li>
<li class="chapter" data-level="6.5.6" data-path="output-feedback.html"><a href="output-feedback.html#design-with-convex-optimization"><i class="fa fa-check"></i><b>6.5.6</b> Design with Convex Optimization</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="output-feedback.html"><a href="output-feedback.html#observer-feedback"><i class="fa fa-check"></i><b>6.6</b> Observer Feedback</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="geometric-vision.html"><a href="geometric-vision.html"><i class="fa fa-check"></i><b>7</b> Geometric Vision</a>
<ul>
<li class="chapter" data-level="7.1" data-path="geometric-vision.html"><a href="geometric-vision.html#d-rotations-and-poses"><i class="fa fa-check"></i><b>7.1</b> 3D Rotations and Poses</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="geometric-vision.html"><a href="geometric-vision.html#rotation-matrices"><i class="fa fa-check"></i><b>7.1.1</b> Rotation matrices</a></li>
<li class="chapter" data-level="7.1.2" data-path="geometric-vision.html"><a href="geometric-vision.html#coordinate-frame"><i class="fa fa-check"></i><b>7.1.2</b> Coordinate Frame</a></li>
<li class="chapter" data-level="7.1.3" data-path="geometric-vision.html"><a href="geometric-vision.html#representations-of-the-rotations"><i class="fa fa-check"></i><b>7.1.3</b> Representations of the rotations</a></li>
<li class="chapter" data-level="7.1.4" data-path="geometric-vision.html"><a href="geometric-vision.html#miscellaneous-topics-on-rotations"><i class="fa fa-check"></i><b>7.1.4</b> Miscellaneous topics on rotations</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="geometric-vision.html"><a href="geometric-vision.html#the-pinhole-camera-model"><i class="fa fa-check"></i><b>7.2</b> The Pinhole Camera Model</a></li>
<li class="chapter" data-level="7.3" data-path="geometric-vision.html"><a href="geometric-vision.html#camera-pose-estimation"><i class="fa fa-check"></i><b>7.3</b> Camera Pose Estimation</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="geometric-vision.html"><a href="geometric-vision.html#the-p3p-problem"><i class="fa fa-check"></i><b>7.3.1</b> The P3P Problem</a></li>
<li class="chapter" data-level="7.3.2" data-path="geometric-vision.html"><a href="geometric-vision.html#the-pnp-problem"><i class="fa fa-check"></i><b>7.3.2</b> The PnP Problem</a></li>
<li class="chapter" data-level="7.3.3" data-path="geometric-vision.html"><a href="geometric-vision.html#global-optimality"><i class="fa fa-check"></i><b>7.3.3</b> Global Optimality</a></li>
<li class="chapter" data-level="7.3.4" data-path="geometric-vision.html"><a href="geometric-vision.html#handling-outliers"><i class="fa fa-check"></i><b>7.3.4</b> Handling Outliers</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="geometric-vision.html"><a href="geometric-vision.html#point-cloud-registration"><i class="fa fa-check"></i><b>7.4</b> Point Cloud Registration</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html"><i class="fa fa-check"></i><b>8</b> Adaptive Control</a>
<ul>
<li class="chapter" data-level="8.1" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html#model-reference-adaptive-control"><i class="fa fa-check"></i><b>8.1</b> Model-Reference Adaptive Control</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html#first-order-systems"><i class="fa fa-check"></i><b>8.1.1</b> First-Order Systems</a></li>
<li class="chapter" data-level="8.1.2" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html#high-order-systems"><i class="fa fa-check"></i><b>8.1.2</b> High-Order Systems</a></li>
<li class="chapter" data-level="8.1.3" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html#robotic-manipulator"><i class="fa fa-check"></i><b>8.1.3</b> Robotic Manipulator</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html#certainty-equivalent-adaptive-control"><i class="fa fa-check"></i><b>8.2</b> Certainty-Equivalent Adaptive Control</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="psets.html"><a href="psets.html"><i class="fa fa-check"></i><b>9</b> Problem Sets</a></li>
<li class="chapter" data-level="" data-path="acknowledgement.html"><a href="acknowledgement.html"><i class="fa fa-check"></i>Acknowledgement</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html"><i class="fa fa-check"></i><b>A</b> Linear Algebra and Differential Equations</a>
<ul>
<li class="chapter" data-level="A.1" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html#linear-algebra"><i class="fa fa-check"></i><b>A.1</b> Linear Algebra</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html#matrix-exponential"><i class="fa fa-check"></i><b>A.1.1</b> Matrix Exponential</a></li>
<li class="chapter" data-level="A.1.2" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html#gradients"><i class="fa fa-check"></i><b>A.1.2</b> Gradients</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html#solving-an-ordinary-differential-equation"><i class="fa fa-check"></i><b>A.2</b> Solving an Ordinary Differential Equation</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html#separation-of-variables"><i class="fa fa-check"></i><b>A.2.1</b> Separation of Variables</a></li>
<li class="chapter" data-level="A.2.2" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html#first-order-linear-ode"><i class="fa fa-check"></i><b>A.2.2</b> First-order Linear ODE</a></li>
<li class="chapter" data-level="A.2.3" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html#gronwall-inequality"><i class="fa fa-check"></i><b>A.2.3</b> Gronwall Inequality</a></li>
<li class="chapter" data-level="A.2.4" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html#matlab"><i class="fa fa-check"></i><b>A.2.4</b> Matlab</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appconvex.html"><a href="appconvex.html"><i class="fa fa-check"></i><b>B</b> Convex Analysis and Optimization</a>
<ul>
<li class="chapter" data-level="B.1" data-path="appconvex.html"><a href="appconvex.html#appconvex-theory"><i class="fa fa-check"></i><b>B.1</b> Theory</a>
<ul>
<li class="chapter" data-level="B.1.1" data-path="appconvex.html"><a href="appconvex.html#sets"><i class="fa fa-check"></i><b>B.1.1</b> Sets</a></li>
<li class="chapter" data-level="B.1.2" data-path="appconvex.html"><a href="appconvex.html#appconvex-theory-convexfunction"><i class="fa fa-check"></i><b>B.1.2</b> Convex function</a></li>
<li class="chapter" data-level="B.1.3" data-path="appconvex.html"><a href="appconvex.html#lagrange-dual"><i class="fa fa-check"></i><b>B.1.3</b> Lagrange dual</a></li>
<li class="chapter" data-level="B.1.4" data-path="appconvex.html"><a href="appconvex.html#appconvex-theory-kkt"><i class="fa fa-check"></i><b>B.1.4</b> KKT condition</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="appconvex.html"><a href="appconvex.html#appconvex-practice"><i class="fa fa-check"></i><b>B.2</b> Practice</a>
<ul>
<li class="chapter" data-level="B.2.1" data-path="appconvex.html"><a href="appconvex.html#cvx-introduction"><i class="fa fa-check"></i><b>B.2.1</b> CVX Introduction</a></li>
<li class="chapter" data-level="B.2.2" data-path="appconvex.html"><a href="appconvex.html#linear-programming-lp"><i class="fa fa-check"></i><b>B.2.2</b> Linear Programming (LP)</a></li>
<li class="chapter" data-level="B.2.3" data-path="appconvex.html"><a href="appconvex.html#quadratic-programming-qp"><i class="fa fa-check"></i><b>B.2.3</b> Quadratic Programming (QP)</a></li>
<li class="chapter" data-level="B.2.4" data-path="appconvex.html"><a href="appconvex.html#quadratically-constrained-quadratic-programming-qcqp"><i class="fa fa-check"></i><b>B.2.4</b> Quadratically Constrained Quadratic Programming (QCQP)</a></li>
<li class="chapter" data-level="B.2.5" data-path="appconvex.html"><a href="appconvex.html#second-order-cone-programming-socp"><i class="fa fa-check"></i><b>B.2.5</b> Second-Order Cone Programming (SOCP)</a></li>
<li class="chapter" data-level="B.2.6" data-path="appconvex.html"><a href="appconvex.html#semidefinite-programming-sdp"><i class="fa fa-check"></i><b>B.2.6</b> Semidefinite Programming (SDP)</a></li>
<li class="chapter" data-level="B.2.7" data-path="appconvex.html"><a href="appconvex.html#cvxpy-introduction-and-examples"><i class="fa fa-check"></i><b>B.2.7</b> CVXPY Introduction and Examples</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html"><i class="fa fa-check"></i><b>C</b> Linear System Theory</a>
<ul>
<li class="chapter" data-level="C.1" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#app-lti-stability"><i class="fa fa-check"></i><b>C.1</b> Stability</a>
<ul>
<li class="chapter" data-level="C.1.1" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#app-lti-stability-ct"><i class="fa fa-check"></i><b>C.1.1</b> Continuous-Time Stability</a></li>
<li class="chapter" data-level="C.1.2" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#app-lti-stability-dt"><i class="fa fa-check"></i><b>C.1.2</b> Discrete-Time Stability</a></li>
<li class="chapter" data-level="C.1.3" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#lyapunov-analysis-1"><i class="fa fa-check"></i><b>C.1.3</b> Lyapunov Analysis</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#app-lti-controllable-observable"><i class="fa fa-check"></i><b>C.2</b> Controllability and Observability</a>
<ul>
<li class="chapter" data-level="C.2.1" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#cayley-hamilton-theorem"><i class="fa fa-check"></i><b>C.2.1</b> Cayley-Hamilton Theorem</a></li>
<li class="chapter" data-level="C.2.2" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#equivalent-statements-for-controllability"><i class="fa fa-check"></i><b>C.2.2</b> Equivalent Statements for Controllability</a></li>
<li class="chapter" data-level="C.2.3" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#duality"><i class="fa fa-check"></i><b>C.2.3</b> Duality</a></li>
<li class="chapter" data-level="C.2.4" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#equivalent-statements-for-observability"><i class="fa fa-check"></i><b>C.2.4</b> Equivalent Statements for Observability</a></li>
</ul></li>
<li class="chapter" data-level="C.3" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#stabilizability-and-detectability"><i class="fa fa-check"></i><b>C.3</b> Stabilizability And Detectability</a>
<ul>
<li class="chapter" data-level="C.3.1" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#equivalent-statements-for-stabilizability"><i class="fa fa-check"></i><b>C.3.1</b> Equivalent Statements for Stabilizability</a></li>
<li class="chapter" data-level="C.3.2" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#equivalent-statements-for-detectability"><i class="fa fa-check"></i><b>C.3.2</b> Equivalent Statements for Detectability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="algebraic-techniques-and-sum-of-squares.html"><a href="algebraic-techniques-and-sum-of-squares.html"><i class="fa fa-check"></i><b>D</b> Algebraic Techniques and Sum-of-Squares</a>
<ul>
<li class="chapter" data-level="D.1" data-path="algebraic-techniques-and-sum-of-squares.html"><a href="algebraic-techniques-and-sum-of-squares.html#algebra"><i class="fa fa-check"></i><b>D.1</b> Algebra</a>
<ul>
<li class="chapter" data-level="D.1.1" data-path="algebraic-techniques-and-sum-of-squares.html"><a href="algebraic-techniques-and-sum-of-squares.html#polynomials"><i class="fa fa-check"></i><b>D.1.1</b> Polynomials</a></li>
<li class="chapter" data-level="D.1.2" data-path="algebraic-techniques-and-sum-of-squares.html"><a href="algebraic-techniques-and-sum-of-squares.html#representation-of-nonnegative-polynomial-univariate-case"><i class="fa fa-check"></i><b>D.1.2</b> Representation of nonnegative polynomial: Univariate case</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="E" data-path="the-kalman-yakubovich-lemma.html"><a href="the-kalman-yakubovich-lemma.html"><i class="fa fa-check"></i><b>E</b> The Kalman-Yakubovich Lemma</a></li>
<li class="chapter" data-level="F" data-path="feedbacklinearization.html"><a href="feedbacklinearization.html"><i class="fa fa-check"></i><b>F</b> Feedback Linearization</a></li>
<li class="chapter" data-level="G" data-path="slidingcontrol.html"><a href="slidingcontrol.html"><i class="fa fa-check"></i><b>G</b> Sliding Control</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Optimal Control and Estimation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="output-feedback" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Chapter 6</span> Output Feedback<a href="output-feedback.html#output-feedback" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>We have presented many algorithms for optimal control of dynamical systems. These algorithms, however, have a strict assumption, i.e., the state of the system is directly available. These controllers are called <em>state-feedback</em> controllers.</p>
<p>In many applications, the state of the system is not readily available but measured via sensors. Therefore, a more realistic model of the dynamical system is
<span class="math display" id="eq:output-feedback-system">\[\begin{equation}
\begin{split}
\dot{x} &amp;= f(x,u) + w  \\
y &amp;= h(x,u) + v
\end{split}
\tag{6.1}
\end{equation}\]</span>
where <span class="math inline">\(x(t) \in \mathbb{X} \subseteq \mathbb{R}^n\)</span> the state of the system, <span class="math inline">\(u(t) \in \mathbb{U} \subseteq \mathbb{R}^m\)</span> the control (or input), <span class="math inline">\(y(t) \in \mathbb{Y} \subseteq \mathbb{R}^{d}\)</span> the output (i.e., measurement) of the state and control, and <span class="math inline">\(f,g\)</span> the evolution and measurement functions (which are sufficiently smooth). <span class="math inline">\(w(t)\)</span> and <span class="math inline">\(v(t)\)</span> denote disturbance and measurement noise, respectively. The discrete-time analog of <a href="output-feedback.html#eq:output-feedback-system">(6.1)</a> is
<span class="math display" id="eq:output-feedback-system-discrete-time">\[\begin{equation}
\begin{split}
x_{k+1} &amp;= f(x_k,u_k) + w_k  \\
y_k &amp;= h(x_k,u_k) + v_k
\end{split},
\tag{6.2}
\end{equation}\]</span>
with <span class="math inline">\(k\)</span> denoting the discrete timestep. When faced with systems like <a href="output-feedback.html#eq:output-feedback-system">(6.1)</a> and <a href="output-feedback.html#eq:output-feedback-system-discrete-time">(6.2)</a>, the controller typically needs to use the history of all measurements, also known as <em>output feedback</em>
<span class="math display">\[
u(t) = \pi(\{y(\tau)\}_{\tau=0}^t), \quad u_k = \pi (\{y_0,\dots,y_k\}).
\]</span></p>
<div id="least-squares-estimation" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Least-Squares Estimation<a href="output-feedback.html#least-squares-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose we are given two random variables <span class="math inline">\(x \in \mathbb{R}^n\)</span> and <span class="math inline">\(y \in \mathbb{R}^m\)</span>, where <span class="math inline">\(y\)</span> is a measurement that provides some information about the model <span class="math inline">\(x\)</span>. We are interested in finding an <em>estimator</em>, i.e., a function <span class="math inline">\(x(y)\)</span>, that minimizes
<span class="math display">\[
\mathbb{E}_{x,y} \left\{ \Vert x - x(y) \Vert^2 \right\}.
\]</span>
The optimal estimator, <span class="math inline">\(x^\star(y)\)</span>, is called a <em>least-squares estimator</em>:
<span class="math display">\[
x^\star(y) = \arg\min_{x(\cdot)} \mathbb{E}_{x,y} \left\{ \Vert x - x(y) \Vert^2 \right\}.
\]</span>
Note that <span class="math inline">\(x^\star(y)\)</span> is a function with input <span class="math inline">\(y\)</span>.
Since
<span class="math display" id="eq:expand-conditional-expectation">\[\begin{equation}
\mathbb{E}_{x,y}\left\{ \Vert x - x(y) \Vert^2 \right\} = \mathbb{E}_y \left\{ \mathbb{E}_x \left\{ \Vert x - x(y) \Vert^2 \mid y\right\} \right\},
\tag{6.3}
\end{equation}\]</span>
it is clear that <span class="math inline">\(x^\star(y)\)</span> is a least-squares estimator if <span class="math inline">\(x^\star(y)\)</span> minimizes the conditional expectation in <a href="output-feedback.html#eq:expand-conditional-expectation">(6.3)</a> for every <span class="math inline">\(y \in \mathbb{R}^m\)</span>, that is,
<span class="math display" id="eq:rewrite-least-squares-conditional">\[\begin{equation}
x^\star(y) = \arg\min_{z \in \mathbb{R}^n} \mathbb{E}_x \left\{ \Vert x - z \Vert^2 \mid y \right\}, \quad \forall y \in \mathbb{R}^m.
\tag{6.4}
\end{equation}\]</span>
With this observation, we have the following proposition.</p>
<div class="theorembox">
<div class="proposition">
<p><span id="prp:least-squares-estimator" class="proposition"><strong>Proposition 6.1  (Least Squares Estimator) </strong></span>The least squares estimator <span class="math inline">\(x^\star(y)\)</span> is given by
<span class="math display" id="eq:conditional-mean">\[\begin{equation}
x^\star(y) = \mathbb{E}_x \left\{ x \mid y \right\}, \quad \forall y \in \mathbb{R}^m,
\tag{6.5}
\end{equation}\]</span>
i.e., <span class="math inline">\(x^\star(y)\)</span> returns the conditional mean of <span class="math inline">\(x\)</span> given <span class="math inline">\(y\)</span>.</p>
</div>
</div>
<div class="proofbox">
<div class="proof">
<p><span id="unlabeled-div-14" class="proof"><em>Proof</em>. </span>We expand the objective in <a href="output-feedback.html#eq:rewrite-least-squares-conditional">(6.4)</a>
<span class="math display">\[
\mathbb{E}_x \left\{ \Vert x - z \Vert^2 \mid y \right\} = \mathbb{E}_x \left\{ \Vert x \Vert^2 \mid y \right\} - 2 z^T \mathbb{E}_x \left\{x \mid y \right\} + \Vert z \Vert^2.
\]</span>
Observe that problem <a href="output-feedback.html#eq:rewrite-least-squares-conditional">(6.4)</a> is an unconstrained quadratic optimization, whose optimal solution can be obtained by setting the gradient of objective (w.r.t. <span class="math inline">\(z\)</span>) to zero:
<span class="math display">\[
z = \mathbb{E}_x \left\{ x \mid y \right\},
\]</span>
concluding the proof.</p>
</div>
</div>
<p>Depending on the joint distribution of <span class="math inline">\((x,y)\)</span>, the least-squares estimator can be very complicated (due to <span class="math inline">\(\mathbb{E}_x\left\{ x \mid y\right\}\)</span> being complicated) and in general does not admit a clean solution. We now turn to the family of linear estimators.</p>
<div id="linear-least-squares-estimation" class="section level3 hasAnchor" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> Linear Least-Squares Estimation<a href="output-feedback.html#linear-least-squares-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A linear estimator <span class="math inline">\(x(y)\)</span> takes the following form
<span class="math display">\[
x(y) = Ay + b, \quad A \in \mathbb{R}^{n \times m}, b \in \mathbb{R}^n.
\]</span>
The optimal linear estimator
<span class="math display" id="eq:linear-least-squares-estimator">\[\begin{equation}
(A^\star, b^\star) = \arg\min_{A,b} \mathbb{E}_{x,y} \left\{ \Vert x - Ay - b \Vert^2 \right\}
\tag{6.6}
\end{equation}\]</span>
is called a <em>linear least-squares estimator</em>.</p>
<p>In the special case where <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are jointly Gaussian random variables, the conditional expectation <span class="math inline">\(\mathbb{E}_{x} \{x \mid y \}\)</span> is indeed linear, and hence a linear least-squares estimator is also the true least-squares estimator.</p>
<div class="theorembox">
<div class="proposition">
<p><span id="prp:linear-least-squares-estimator" class="proposition"><strong>Proposition 6.2  (Linear Least-Squares Estimator) </strong></span>If the random variables <span class="math inline">\((x,y)\)</span> are jointly Gaussian, then the conditional expectation <span class="math inline">\(\mathbb{E}_x \{x \mid y \}\)</span> is linear in <span class="math inline">\(y\)</span>. Therefore, the linear least-squares estimator <a href="output-feedback.html#eq:linear-least-squares-estimator">(6.6)</a> is also the least-squares estimator.</p>
</div>
</div>
<p>Now let us turn to characterize the linear least-squares estimator.</p>
<div class="theorembox">
<div class="proposition">
<p><span id="prp:linear-least-squares-solution" class="proposition"><strong>Proposition 6.3  (Solution of Linear Least-Squares Estimator) </strong></span>Let <span class="math inline">\(x,y\)</span> be random variables in <span class="math inline">\(\mathbb{R}^n\)</span> and <span class="math inline">\(\mathbb{R}^m\)</span> drawn from some underlying distribution. The means and covariances of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are given by
<span class="math display">\[\begin{equation}
\begin{split}
\mathbb{E}\{ x\} = \bar{x}, \quad \mathbb{E} \{ y \} = \bar{y}. \\
\mathbb{E}\{ (x - \bar{x})(x - \bar{x})^T \} = \Sigma_{xx}, \quad \mathbb{E}\{ (y - \bar{y})(y-\bar{y})^T \} = \Sigma_{yy}, \\
\mathbb{E}\{ (x - \bar{x})(y - \bar{y})^T \} = \Sigma_{xy}, \quad \mathbb{E}\{ (y - \bar{y})(x - \bar{x})^T \} = \Sigma^T_{xy},
\end{split}
\end{equation}\]</span>
and assume <span class="math inline">\(\Sigma_{yy}\)</span> is invertible (positive definite). Then the linear least-squares estimator <span class="math inline">\(x^\star(y)\)</span>, i.e., solution of <a href="output-feedback.html#eq:linear-least-squares-estimator">(6.6)</a>, is given by
<span class="math display" id="eq:linear-least-squares-solution">\[\begin{equation}
x^\star(y) = \bar{x} + \Sigma_{xy} \Sigma^{-1}_{yy} (y - \bar{y}).
\tag{6.7}
\end{equation}\]</span>
The corresponding error covariance matrix is given by
<span class="math display" id="eq:linear-least-squares-solution-covariance">\[\begin{equation}
\mathbb{E}_{x,y} \left\{ (x - x^\star(y))(x - x^\star(y))^T \right\} = \Sigma_{xx} - \Sigma_{xy} \Sigma^{-1}_{yy} \Sigma^T_{xy}.
\tag{6.8}
\end{equation}\]</span></p>
</div>
</div>
<div class="proofbox">
<div class="proof">
<p><span id="unlabeled-div-15" class="proof"><em>Proof</em>. </span>Problem <a href="output-feedback.html#eq:linear-least-squares-estimator">(6.6)</a> is an unconstrained quadratic optimization in <span class="math inline">\((A,b)\)</span>. Therefore, its optimal solution can be computed by taking the derivative of the objective, i.e., <span class="math inline">\(f(A,b) = \mathbb{E}_{x,y} \{ \Vert x - Ay - b \Vert^2 \}\)</span> , w.r.t. <span class="math inline">\((A,b)\)</span> and setting them to zero
<span class="math display" id="eq:linear-least-squares-derivative-zero">\[\begin{equation}
\begin{split}
0 = \frac{\partial f}{\partial A} = 2 \mathbb{E}_{x,y} \{ (b + Ay -x) y^T \}, \\
0 = \frac{\partial f}{\partial b} = 2 \mathbb{E}_{x,y} \{ b + Ay - x \}.
\end{split}
\tag{6.9}
\end{equation}\]</span>
The second equation gives us the solution of <span class="math inline">\(b^\star\)</span>
<span class="math display" id="eq:linear-least-squares-proof-solution-b">\[\begin{equation}
b^\star = \bar{x} - A \bar{y}.
\tag{6.10}
\end{equation}\]</span>
Plug the solution <a href="output-feedback.html#eq:linear-least-squares-proof-solution-b">(6.10)</a> back into the first equation in <a href="output-feedback.html#eq:linear-least-squares-derivative-zero">(6.9)</a>, we obtain
<span class="math display" id="eq:linear-least-squares-proof-simplify-first-equation">\[\begin{equation}
\mathbb{E}_{x,y} \{ (A(y - \bar{y}) - (x - \bar{x})) y^T\} = 0.
\tag{6.11}
\end{equation}\]</span>
On the other hand, we have
<span class="math display" id="eq:linear-least-squares-proof-simplify-first-equation-other">\[\begin{equation}
\left( \mathbb{E}_{x,y} \{ A (y - \bar{y}) - (x - \bar{x})\} \right) \bar{y}^T = 0.
\tag{6.12}
\end{equation}\]</span>
Subtracting <a href="output-feedback.html#eq:linear-least-squares-proof-simplify-first-equation-other">(6.12)</a> from <a href="output-feedback.html#eq:linear-least-squares-proof-simplify-first-equation">(6.11)</a>, we have
<span class="math display">\[
\mathbb{E}_{x,y} \left\{ (A(y-\bar{y}) - (x - \bar{x})) (y - \bar{y})^T \right\} = 0,
\]</span>
which is exactly
<span class="math display">\[
A \Sigma_{yy} - \Sigma_{xy} = 0.
\]</span>
Therefore, we obtain the optimal <span class="math inline">\(A\)</span>
<span class="math display" id="eq:linear-least-squares-proof-solution-A">\[\begin{equation}
A^\star = \Sigma_{xy} \Sigma^{-1}_{yy}.
\tag{6.13}
\end{equation}\]</span>
Combining <a href="output-feedback.html#eq:linear-least-squares-proof-solution-A">(6.13)</a> and <a href="output-feedback.html#eq:linear-least-squares-proof-solution-b">(6.10)</a>, we get the optimal linear least-squares estimator
<span class="math display">\[
x^\star(y) = \Sigma_{xy} \Sigma^{-1}_{yy} y + \left( \bar{x} -  \Sigma_{xy} \Sigma^{-1}_{yy} \bar{y} \right) = \bar{x} + \Sigma_{xy} \Sigma^{-1}_{yy} (y - \bar{y}).
\]</span>
The error covariance <a href="output-feedback.html#eq:linear-least-squares-solution-covariance">(6.8)</a> follows by direct computation.</p>
</div>
</div>
<p>We next list a few useful properties of the linear least-squares estimator.</p>
<div class="theorembox">
<div class="corollary">
<p><span id="cor:properties-linear-least-squares-estimator" class="corollary"><strong>Corollary 6.1  (Properties of the Linear Least-Squares Estimator) </strong></span>The linear least-squares estimator <span class="math inline">\(x^\star(y)\)</span> in <a href="output-feedback.html#eq:linear-least-squares-solution">(6.7)</a> is unbiased, i.e.,
<span class="math display">\[
\mathbb{E}_y \{ x^\star(y) \} = \bar{x}.
\]</span></p>
<p>The estimation error <span class="math inline">\(x - x^\star(y)\)</span> is uncorrelated with both <span class="math inline">\(y\)</span> and <span class="math inline">\(x^\star(y)\)</span>, i.e.,
<span class="math display" id="eq:linear-least-squares-orthogonal-projection">\[\begin{equation}
\begin{split}
\mathbb{E}_{x,y} \{  (x - x^\star(y))y^T \} = 0. \\
\mathbb{E}_{x,y} \{  (x - x^\star(y)) (x^\star(y))^T \} = 0.
\end{split}
\tag{6.14}
\end{equation}\]</span></p>
</div>
</div>
<p>Equation <a href="output-feedback.html#eq:linear-least-squares-orthogonal-projection">(6.14)</a> is known as the <em>orthogonal projection principle</em>.</p>
<p>The next corollary considers the linear least-squares estimator of a new variable <span class="math inline">\(z\)</span> that is a linear function of <span class="math inline">\(x\)</span>.</p>
<div class="theorembox">
<div class="corollary">
<p><span id="cor:linear-least-squares-z" class="corollary"><strong>Corollary 6.2  </strong></span>Consider in addition to <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, the random vector <span class="math inline">\(z\)</span> defined by
<span class="math display">\[
z = Cx,
\]</span>
where <span class="math inline">\(C \in \mathbb{R}^{p \times n}\)</span> is given. Then the linear least-squares estimator of <span class="math inline">\(z\)</span> given <span class="math inline">\(y\)</span> is
<span class="math display">\[
z^\star(y) = C x^\star(y),
\]</span>
and the corresponding error covariance matrix is
<span class="math display">\[
\mathbb{E}_{z,y}\left\{ (z - z^\star(y))(z - z^\star(y))^T \right\} = C \mathbb{E}_{x,y} \left\{ (x - x^\star(y))(x - x^\star(y))^T \right\} C^T,
\]</span>
where <span class="math inline">\(\mathbb{E}_{x,y} \left\{ (x - x^\star(y))(x - x^\star(y))^T \right\}\)</span> is given in <a href="output-feedback.html#eq:linear-least-squares-solution-covariance">(6.8)</a>.</p>
</div>
</div>
<div class="proofbox">
<div class="proof">
<p><span id="unlabeled-div-16" class="proof"><em>Proof</em>. </span>Since <span class="math inline">\(z = Cx\)</span>, we have <span class="math inline">\(\mathbb{E} \{ z \} = C \bar{x} = \bar{z}\)</span>, and
<span class="math display">\[
\Sigma_{zz} = \mathbb{E} \{ (z - \bar{z})(z - \bar{z})^T \} = C \Sigma_{xx} C^T, \\
\Sigma_{zy} = \mathbb{E} \{ (z - \bar{z})(y - \bar{y})^T \} = C \Sigma_{xy}, \\
\Sigma_{yz} = \mathbb{E} \{ (y - \bar{y}) (z - \bar{z})^T \} = \Sigma^T_{xy} C^T.
\]</span>
The result then follows by applying Proposition <a href="output-feedback.html#prp:linear-least-squares-solution">6.3</a> to <span class="math inline">\(z\)</span> and <span class="math inline">\(y\)</span>.</p>
</div>
</div>
<p>The next corollary considers the linear least-squares estimator of <span class="math inline">\(x\)</span> given <span class="math inline">\(z\)</span>, a random vector that is a linear function of <span class="math inline">\(y\)</span>.</p>
<div class="theorembox">
<div class="corollary">
<p><span id="cor:linear-least-squares-x-z" class="corollary"><strong>Corollary 6.3  </strong></span>Consider in addition to <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, an additional random variable <span class="math inline">\(z\)</span>
<span class="math display">\[
z = C y + u,
\]</span>
where <span class="math inline">\(C \in \mathbb{R}^{p \times m}\)</span>, with rank <span class="math inline">\(p\)</span>, and <span class="math inline">\(u \in \mathbb{R}^p\)</span> are given. Then the linear least-squares estimator of <span class="math inline">\(x\)</span> given <span class="math inline">\(z\)</span> is
<span class="math display">\[
x^\star(z) = \bar{x} + \Sigma_{xy} C^T (C \Sigma_{yy} C^T)^{-1} (z - C \bar{y} - u),
\]</span>
and the corresponding error covariance matrix is
<span class="math display">\[
\mathbb{E}_{x,z}\left\{ (x - x^\star(z))(x - x^\star(z))^T \right\} = \Sigma_{xx} - \Sigma_{xy} C^T (C \Sigma_{yy} C^T)^{-1} C \Sigma_{xy}^T.
\]</span></p>
</div>
</div>
<div class="proofbox">
<div class="proof">
<p><span id="unlabeled-div-17" class="proof"><em>Proof</em>. </span>Since <span class="math inline">\(z = Cy + u\)</span>, we have <span class="math inline">\(\bar{z} = \mathbb{E}\{ z \} = C \bar{y} + u\)</span>, and
<span class="math display">\[
\Sigma_{zz} = \mathbb{E}\{ (z - \bar{z})(z - \bar{z})^T \} = C \Sigma_{yy} C^T, \\
\Sigma_{zx} = \mathbb{E}\{ (z - \bar{z})(x - \bar{x})^T \} = C \Sigma_{xy}^T, \\
\Sigma_{xz} = \mathbb{E}\{ (x - \bar{x})(z - \bar{z})^T \} = \Sigma_{xy}C^T.
\]</span>
The result then follows by applying Proposition <a href="output-feedback.html#prp:linear-least-squares-solution">6.3</a>.</p>
</div>
</div>
<p>Frequently, we want to estimate a vector of parameters <span class="math inline">\(x \in \mathbb{R}^n\)</span> given a measurement vector <span class="math inline">\(z \in \mathbb{R}^m\)</span> of the form <span class="math inline">\(z = C x + v\)</span> with <span class="math inline">\(C \in \mathbb{R}^{m \times n}\)</span> a given matrix and <span class="math inline">\(v \in \mathbb{R}^m\)</span> a noise vector. The following corollary gives the linear least squares estimator <span class="math inline">\(x^\star(z)\)</span> and its error covariance.</p>
<div class="theorembox">
<div class="corollary">
<p><span id="cor:linear-least-squares-noise" class="corollary"><strong>Corollary 6.4  (Linear Least-Squares Estimator with Noise) </strong></span>Let
<span class="math display">\[
z = C x + v,
\]</span>
where <span class="math inline">\(C \in \mathbb{R}^{m \times n}\)</span> is a given matrix, and the random variable <span class="math inline">\(x\)</span> and <span class="math inline">\(v\)</span> are uncorrelated. Denote
<span class="math display">\[
\mathbb{E}\{x \} = \bar{x}, \quad \mathbb{E}\{ (x - \bar{x})(x - \bar{x})^T \} = \Sigma_{xx}, \\
\mathbb{E}\{ v\} = \bar{v}, \quad \mathbb{E}\{ (v - \bar{v})(v - \bar{v})^T \} = \Sigma_{vv},
\]</span>
and assume <span class="math inline">\(\Sigma_{vv}\)</span> is positive definite. Then the linear least-squares estimator of <span class="math inline">\(x\)</span> given <span class="math inline">\(z\)</span> is
<span class="math display">\[
x^\star(z) = \bar{x} + \Sigma_{xx} C^T (C \Sigma_{xx} C^T + \Sigma_{vv})^{-1} (z - C \bar{x} - \bar{v}),
\]</span>
and the corresponding error covariance is
<span class="math display">\[
\mathbb{E}_{x,v} \{ (x - x^\star(z))(x - x^\star(z))^T \} = \Sigma_{xx} - \Sigma_{xx}C^T (C \Sigma_{xx} C^T + \Sigma_{vv})^{-1} C \Sigma_{xx}.
\]</span></p>
</div>
</div>
<div class="proofbox">
<div class="proof">
<p><span id="unlabeled-div-18" class="proof"><em>Proof</em>. </span>Denote
<span class="math display">\[
y = \begin{bmatrix} x \\ v \end{bmatrix}, \quad \bar{y} = \begin{bmatrix} \bar{x} \\ \bar{v} \end{bmatrix},
\]</span>
then clearly we have
<span class="math display">\[
x = \underbrace{ \begin{bmatrix} I &amp; 0 \end{bmatrix}}_{C_x} y,
\]</span>
and
<span class="math display">\[
z = \underbrace{\begin{bmatrix} C &amp; I \end{bmatrix}}_{\tilde{C}} y.
\]</span>
Using Corollary <a href="output-feedback.html#cor:linear-least-squares-z">6.2</a>, we have
<span class="math display">\[
x^\star(z) = C_x y^\star(z) \\
\mathbb{E}\{ (x - x^\star(z))(x - x^\star(z))^T \} = C_x \mathbb{E}\{(y - y^\star(z))(y - y^\star(z))^T \} C_x^T,
\]</span>
where <span class="math inline">\(y^\star(z)\)</span> is the linear least-sqaures estimator of <span class="math inline">\(y\)</span> given <span class="math inline">\(z\)</span>.</p>
<p>To obtain <span class="math inline">\(y^\star(z)\)</span>, we can apply Corollary <a href="output-feedback.html#cor:linear-least-squares-x-z">6.3</a> with <span class="math inline">\(u=0\)</span> and <span class="math inline">\(x=y\)</span>, leading to
<span class="math display">\[
y^\star(z) = \bar{y} + \Sigma_{yy} \tilde{C}^T (\tilde{C} \Sigma_{yy} \tilde{C}^T)^{-1} (z - \tilde{C}\bar{y}),
\]</span>
and the error covariance
<span class="math display">\[
\mathbb{E}\{(y - y^\star(z))(y - y^\star(z))^T \} = \Sigma_{yy} - \Sigma_{yy} \tilde{C}^T (\tilde{C}\Sigma_{yy}\tilde{C}^T)^{-1} \tilde{C} \Sigma_{yy}.
\]</span>
The result then follows by noting
<span class="math display">\[
\Sigma_{yy} = \begin{bmatrix} \Sigma_{xx} &amp; 0 \\ 0 &amp; \Sigma_{vv} \end{bmatrix}
\]</span>
because <span class="math inline">\(x\)</span> and <span class="math inline">\(v\)</span> are uncorrelated.</p>
</div>
</div>
<p>The next two corollaries deal with least-squares estimators involving multiple measurements arriving sequentially. In particular, the corollaries show how to modify an existing least-squares estimate <span class="math inline">\(x^\star(y)\)</span> to obtain <span class="math inline">\(x^\star(y,z)\)</span> once an additional measurement <span class="math inline">\(z\)</span> becomes available. This is a central operation in Kalman filtering.</p>
<div class="theorembox">
<div class="corollary">
<p><span id="cor:linear-least-squares-correction-uncorrelated" class="corollary"><strong>Corollary 6.5  (Linear Least-Squares Estimator of Uncorrelated Measurements) </strong></span>Consider in addition to <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, an additional random vector <span class="math inline">\(z \in \mathbb{R}^p\)</span> that is uncorrelated with <span class="math inline">\(y\)</span>. Then the linear least-squares estimator <span class="math inline">\(x^\star(y,z)\)</span> of <span class="math inline">\(x\)</span> given both <span class="math inline">\(y\)</span> and <span class="math inline">\(z\)</span> has the form
<span class="math display">\[
x^\star(y,z) = x^\star(y) + x^\star(z) - \bar{x},
\]</span>
where <span class="math inline">\(x^\star(y)\)</span> and <span class="math inline">\(x^\star(z)\)</span> are the linear least-squares estimates of <span class="math inline">\(x\)</span> given <span class="math inline">\(y\)</span> and given <span class="math inline">\(z\)</span>, respectively. Furthermore, the error covariance matrix is
<span class="math display">\[
\mathbb{E}_{x,y,z} \{ (x - x^\star(y,z))(x - x^\star(y,z))^T \} = \Sigma_{xx} - \Sigma_{xy} \Sigma^{-1}_{yy} \Sigma^T_{xy} - \Sigma_{xz} \Sigma^{-1}_{zz} \Sigma_{xz}^T,
\]</span>
where
<span class="math display">\[
\Sigma_{xz} = \mathbb{E}_{x,z}\{ (x - \bar{x})(z - \bar{z})^T \}, \quad \Sigma_{zz} = \mathbb{E}_{z} \{ (z - \bar{z})(z - \bar{z})^T \}, \quad \bar{z} = \mathbb{E}_z \{ z \},
\]</span>
and it is assumed that <span class="math inline">\(\Sigma_{zz}\)</span> and <span class="math inline">\(\Sigma_{yy}\)</span> are both invertible.</p>
</div>
</div>
<div class="proofbox">
<div class="proof">
<p><span id="unlabeled-div-19" class="proof"><em>Proof</em>. </span>Let
<span class="math display">\[
w = \begin{bmatrix} y \\ z \end{bmatrix}, \quad \bar{w} = \begin{bmatrix} \bar{y} \\ \bar{z} \end{bmatrix}.
\]</span>
Then we can apply Proposition <a href="output-feedback.html#prp:linear-least-squares-solution">6.3</a> to compute the linear least-squares estimator of <span class="math inline">\(x\)</span> given <span class="math inline">\(w\)</span>
<span class="math display">\[
x^\star(w) = \bar{x} + \Sigma_{xw} \Sigma^{-1}_{ww} (w - \bar{w}).
\]</span>
On the other hand, we have
<span class="math display">\[
\Sigma_{xw} = \mathbb{E}\{ (x - \bar{x}) \begin{bmatrix} (y - \bar{y})^T &amp; ( z - \bar{z} )^T \end{bmatrix} \} = \begin{bmatrix} \Sigma_{xy} &amp; \Sigma_{xz} \end{bmatrix},
\]</span>
and since <span class="math inline">\(y\)</span> and <span class="math inline">\(z\)</span> are uncorrelated, we have
<span class="math display">\[
\Sigma_{ww} = \begin{bmatrix} \Sigma_{yy} &amp; 0 \\ 0 &amp; \Sigma_{zz} \end{bmatrix}.
\]</span>
The result then follows by direct computation.</p>
</div>
</div>
<p>The next corollary generalizes the previous result to the case where <span class="math inline">\(y\)</span> and <span class="math inline">\(z\)</span> are correlated.</p>
<div class="theorembox">
<div class="corollary">
<p><span id="cor:linear-least-squares-correction-correlated" class="corollary"><strong>Corollary 6.6  (Linear Least-Squares Estimator of Correlated Measurements) </strong></span>Consider the situation in Corollary <a href="output-feedback.html#cor:linear-least-squares-correction-uncorrelated">6.5</a>, but with <span class="math inline">\(z\)</span> and <span class="math inline">\(y\)</span> being correlated
<span class="math display">\[
\Sigma_{yz} = \mathbb{E}_{y,z} \{ (y - \bar{y})(z - \bar{z})^T \} \neq 0.
\]</span>
Then <span class="math inline">\(x^\star(y,z)\)</span> has the following form
<span class="math display">\[
x^\star(y,z) = x^\star(y) + x^\star(z - z^\star(y)) - \bar{x},
\]</span>
where <span class="math inline">\(x^\star(z - z^\star(y))\)</span> denotes the linear least-squares estimate of <span class="math inline">\(x\)</span> given the random vector <span class="math inline">\(z - z^\star(y)\)</span> and <span class="math inline">\(z^\star(y)\)</span> is the linear least-squares estimate of <span class="math inline">\(z\)</span> given <span class="math inline">\(y\)</span>. Furthermore, the error covariance matrix is
<span class="math display">\[
\mathbb{E}_{x,y,z} \{ (x - x^\star(y,z))(x - x^\star(y,z))^T \} = \Sigma_{xx} - \Sigma_{xy} \Sigma^{-1}_{yy} \Sigma^T_{xy} - \hat{\Sigma}_{xz} \hat{\Sigma}^{-1}_{zz} \hat{\Sigma}^T_{xz},
\]</span>
where
<span class="math display">\[
\hat{\Sigma}_{xz} = \mathbb{E}_{x,y,z} \{ (x - \bar{x})(z - z^\star(y))^T \}, \quad \hat{\Sigma}_{zz} = \mathbb{E}_{y,z} \{ (z - z^\star(y))(z - z^\star(y))^T \}.
\]</span></p>
</div>
</div>
<div class="proofbox">
<div class="proof">
<p><span id="unlabeled-div-20" class="proof"><em>Proof</em>. </span>By Proposition <a href="output-feedback.html#prp:linear-least-squares-solution">6.3</a>, we know <span class="math inline">\(z^\star(y)\)</span> is linear in <span class="math inline">\(y\)</span> as
<span class="math display">\[
z^\star(y) = \bar{z} + \Sigma_{zy} \Sigma^{-1}_{yy} (y - \bar{y}) := B y + c,
\]</span>
where <span class="math inline">\(B = \Sigma_{zy} \Sigma^{-1}_{yy}\)</span> and <span class="math inline">\(c = \bar{z} - \Sigma_{zy} \Sigma^{-1}_{yy} \bar{y}\)</span>. The linear least-squares estimate of <span class="math inline">\(x\)</span> given <span class="math inline">\((y,z)\)</span> has the form
<span class="math display" id="eq:linear-least-squares-solution-A-b">\[\begin{equation}
x = \begin{bmatrix} A_y^\star &amp; A_z^\star \end{bmatrix} \begin{bmatrix} y \\ z \end{bmatrix} + b^\star,
\tag{6.15}
\end{equation}\]</span>
where <span class="math inline">\((A_y^\star, A_z^\star, b^\star)\)</span> is solution to
<span class="math display" id="eq:correlated-A-b">\[\begin{equation}
(A_y^\star, A_z^\star, b^\star) = \arg\min_{A_y,A_z,b} \mathbb{E}_{x,y,z} \left\{ \Vert x - A_y y - A_z z - b  \Vert^2 \right\}.
\tag{6.16}
\end{equation}\]</span>
The linear least-squares estimate of <span class="math inline">\(x\)</span> given <span class="math inline">\((y, z - z^\star(y))\)</span> has the form
<span class="math display" id="eq:linear-least-squares-solution-G-h">\[\begin{equation}
x = \begin{bmatrix} G_y^\star &amp; G_z^\star \end{bmatrix} \begin{bmatrix} y \\ z - By - c \end{bmatrix} + h^\star,
\tag{6.17}
\end{equation}\]</span>
where <span class="math inline">\((G_y^\star,G_z^\star,h^\star)\)</span> is solution to
<span class="math display" id="eq:correlated-G-h">\[\begin{equation}
(G_y^\star,G_z^\star,h^\star) = \arg\min_{G_y,G_z,h} \mathbb{E}_{x,y,z} \left\{ \Vert x - G_y y - G_z (z - By - c) - h \Vert^2 \right\}.
\tag{6.18}
\end{equation}\]</span>
Observe that the objective in <a href="output-feedback.html#eq:correlated-G-h">(6.18)</a> can be rewritten as
<span class="math display">\[
\mathbb{E}_{x,y,z} \left\{ \Vert x - (G_y - G_z B) y - G_z z - (h - G_z c) \Vert^2 \right\},
\]</span>
when matched with the objective of <a href="output-feedback.html#eq:correlated-A-b">(6.16)</a> we have
<span class="math display">\[
A_y^\star = G_y^\star - G_z^\star B, \quad  A_z^\star = G_z^\star, \quad b^\star = h^\star - G_z^\star c.
\]</span>
As a result, the linear least-squares estimator in <a href="output-feedback.html#eq:linear-least-squares-solution-G-h">(6.17)</a> becomes
<span class="math display">\[
x = (A_y^\star + A_z^\star B) y + A_z^\star (z - By - c) + b^\star + A_z^\star c = A^\star_y y + A^\star_z z + b^\star,
\]</span>
which is the same as <a href="output-feedback.html#eq:linear-least-squares-solution-A-b">(6.15)</a>. Therefore, we have
<span class="math display">\[
x^\star(y,z) = x^\star(y, z - z^\star(y)).
\]</span></p>
<p>From Corollary <a href="output-feedback.html#cor:properties-linear-least-squares-estimator">6.1</a>, we know <span class="math inline">\(y\)</span> and <span class="math inline">\(z - z^\star(y)\)</span> is uncorrelated. Consequently, we reduce to the uncorrelated setup in Corollary <a href="output-feedback.html#cor:linear-least-squares-correction-uncorrelated">6.5</a> and the result follows.</p>
</div>
</div>
</div>
</div>
<div id="kalman-filter" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Kalman Filter<a href="output-feedback.html#kalman-filter" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Consider now a linear dynamical system without control
<span class="math display" id="eq:kalman-filter-linear-system-discrete">\[\begin{equation}
\begin{cases}
x_{k+1} = A_k x_k + w_k \\
y_k = C_k x_k + v_k
\end{cases}, k=0,1,\dots,N-1,
\tag{6.19}
\end{equation}\]</span>
where <span class="math inline">\(x_k \in \mathbb{R}^n\)</span> the state, <span class="math inline">\(w_k \in \mathbb{R}^n\)</span> the random disturbance, <span class="math inline">\(y_k \in \mathbb{R}^d\)</span> the measurement (output), and <span class="math inline">\(v_k \in \mathbb{R}^d\)</span> the measurement noise.</p>
<p>We assume <span class="math inline">\(x_0,w_0,\dots,w_{N-1},v_0,\dots,v_{N-1}\)</span> are independent random vectors with means
<span class="math display">\[
\mathbb{E}\{ w_k \} = \mathbb{E} \{ v_k \} = 0, \quad k=0,\dots,N-1,
\]</span>
and covariances
<span class="math display">\[
\mathbb{E} \{ w_k w_k^T \} = M_k, \quad \mathbb{E} \{ v_k v_k^T \} = N_k, \quad k=0,\dots,N-1,
\]</span>
with <span class="math inline">\(N_k\)</span> positive definite for all <span class="math inline">\(k\)</span>. We assume the initial state <span class="math inline">\(x_0\)</span> has mean <span class="math inline">\(\mathbb{E}\{ x_0 \}\)</span> and covariance
<span class="math display">\[
S = \mathbb{E} \{ (x_0 - \mathbb{E}\{x_0 \} ) (x_0 - \mathbb{E}\{x_0 \} )^T \}.
\]</span>
Let
<span class="math display">\[
Y_k = (y_0,\dots,y_k)
\]</span>
be the set of measurements up to time <span class="math inline">\(k\)</span>, our goal is to obtain the linear least-squares estimate of <span class="math inline">\(x_k\)</span> given <span class="math inline">\(Y_k\)</span>, denoted as
<span class="math display">\[
x^\star_{k \mid k} := x^\star_k (Y_k),
\]</span>
and its error covariance matrix
<span class="math display">\[
\Sigma_{k \mid k} := \mathbb{E} \{ (x_k - x^\star_{k \mid k}) (x_k - x^\star_{k \mid k})^T\}.
\]</span>
By definition, we have
<span class="math display" id="eq:kalman-filter-initial-condition">\[\begin{equation}
x^\star_{0 \mid -1} = \mathbb{E}\{ x_0 \}, \quad \Sigma_{0 \mid -1} = S.
\tag{6.20}
\end{equation}\]</span></p>
<p>The Kalman filter <span class="citation">(<a href="#ref-kalman60new">Rudolph Emil Kalman 1960</a>)</span> will derive a recursion to update <span class="math inline">\(x^\star_{k \mid k}\)</span> and <span class="math inline">\(\Sigma_{k \mid k}\)</span>.</p>
<p><strong>Road map</strong>. Towards this, let us assume we have computed <span class="math inline">\(x^\star_{k \mid k-1}\)</span> and its error covariance <span class="math inline">\(\Sigma_{k \mid k-1}\)</span> (the initial condition is given by <a href="output-feedback.html#eq:kalman-filter-initial-condition">(6.20)</a>). Our goal is to compute <span class="math inline">\(x^\star_{k+1 \mid k}\)</span> and its error covariance <span class="math inline">\(\Sigma_{k+1\mid k}\)</span>. We will see that, to compute <span class="math inline">\(x^\star_{k+1 \mid k}\)</span>, we compute <span class="math inline">\(x^\star_{k \mid k}\)</span> first, and to compute <span class="math inline">\(\Sigma_{k+1 \mid k}\)</span>, we compute <span class="math inline">\(\Sigma_{k\mid k}\)</span> first, as illustrated below.
<span class="math display">\[\begin{equation}
\begin{split}
\text{Update estimate:}\quad x^\star_{k \mid k-1} \longrightarrow x^\star_{k \mid k} \longrightarrow x^\star_{k+1 \mid k}. \\
\text{Update covariance:}\quad \Sigma_{k \mid k-1} \longrightarrow \Sigma_{k \mid k} \longrightarrow \Sigma_{k+1 \mid k}.
\end{split}
\end{equation}\]</span></p>
<p><strong>Using the measurement</strong>. At time <span class="math inline">\(k\)</span>, we receive a new measurement
<span class="math display">\[
y_k = C_k x_k + v_k.
\]</span>
We have
<span class="math display">\[
x^\star_{k\mid k} = x^\star_k (Y_k) = x^\star_k(Y_{k-1},y_k),
\]</span>
by Corollary <a href="output-feedback.html#cor:linear-least-squares-correction-correlated">6.6</a>, we have
<span class="math display" id="eq:kalman-filter-derivation-1">\[\begin{equation}
x^\star_{k \mid k} = x^\star_{k \mid k-1} + x^\star_k (y_k - y_k^\star(Y_{k-1})) - \mathbb{E}\{ x_k \},
\tag{6.21}
\end{equation}\]</span>
where <span class="math inline">\(y_k^\star(Y_{k-1})\)</span> is the linear least-squares estimate of <span class="math inline">\(y_k\)</span> given <span class="math inline">\(Y_{k-1}\)</span>.</p>
<p><strong>Simplify <a href="output-feedback.html#eq:kalman-filter-derivation-1">(6.21)</a></strong>. First note that by Corollary <a href="output-feedback.html#cor:linear-least-squares-z">6.2</a> and independence of <span class="math inline">\(v_k\)</span>, we have
<span class="math display">\[
y_k^\star(Y_{k-1}) = C_k x^\star_{k \mid k-1}.
\]</span>
We now need to compute <span class="math inline">\(x_k^\star(y_k - y_k^\star(Y_{k-1}))\)</span>. We do so by Proposition <a href="output-feedback.html#prp:linear-least-squares-solution">6.3</a>. The covariance matrix of <span class="math inline">\(y_k - y_k^\star(Y_{k-1})\)</span> is, by Corollary <a href="output-feedback.html#cor:linear-least-squares-z">6.2</a>,
<span class="math display">\[
\mathbb{E} \{ (y_k - y_k^\star(Y_{k-1}))(y_k - y_k^\star(Y_{k-1}))^T \} = C_k \Sigma_{k \mid k-1} C_k^T + N_k.
\]</span>
The correlation between <span class="math inline">\(x_k\)</span> and <span class="math inline">\(y_k - y_k^\star(Y_{k-1})\)</span> is
<span class="math display">\[\begin{equation}
\begin{split}
\mathbb{E}\{ x_k (y_k - y_k^\star(Y_{k-1}))^T \} = \mathbb{E} \{ x_k(C_k (x_k - x^\star_{k\mid k-1}))^T \} + \underbrace{ \mathbb{E}\{ x_k v_k^T \} }_{=0 \text{ by independence of } v_k} \\
= \mathbb{E}\{(x_k - x^\star_{k \mid k-1}) (x_k - x^\star_{k \mid k-1})^T \}C_k^T + \underbrace{\mathbb{E}\{ x^\star_{k \mid k-1}(x_k - x^\star_{k \mid k-1})^T \}}_{=0 \text{ by the orthogonal projection principle}}C_k^T \\
= \Sigma_{k \mid k-1} C_k^T.
\end{split}
\end{equation}\]</span>
As a result, by Proposition <a href="output-feedback.html#prp:linear-least-squares-solution">6.3</a>, we have
<span class="math display">\[
x_k^\star(y_k - y_k^\star(Y_{k-1})) = \mathbb{E}\{x_k \} + \Sigma_{k \mid k-1} C_k^T (C_k \Sigma_{k \mid k-1} C_k^T + N_k)^{-1} (y_k - C_k x^\star_{k \mid k-1}).
\]</span></p>
<p><strong>Update the estimate</strong>. Thus, <a href="output-feedback.html#eq:kalman-filter-derivation-1">(6.21)</a> is simplified as
<span class="math display" id="eq:kalman-filter-update-1">\[\begin{equation}
x^\star_{k\mid k} = x^\star_{k \mid k-1} + \Sigma_{k \mid k-1} C_k^T (C_k \Sigma_{k \mid k-1} C_k^T + N_k)^{-1} (y_k - C_k x^\star_{k \mid k-1}),
\tag{6.22}
\end{equation}\]</span>
which describes the update from <span class="math inline">\(x^\star_{k \mid k-1}\)</span> to <span class="math inline">\(x^\star_{k \mid k}\)</span>.</p>
<p>To update <span class="math inline">\(x^\star_{k+1 \mid k}\)</span> from <span class="math inline">\(x^\star_{k \mid k}\)</span>, by Corollary <a href="output-feedback.html#cor:linear-least-squares-z">6.2</a>, we have
<span class="math display" id="eq:kalman-filter-update-2">\[\begin{equation}
x^\star_{k+1 \mid k} = A_k x^\star_{k \mid k}.
\tag{6.23}
\end{equation}\]</span></p>
<p><strong>Update the covariance</strong>. The error covariance <span class="math inline">\(\Sigma_{k \mid k}\)</span>, by Corollary <a href="output-feedback.html#cor:linear-least-squares-correction-correlated">6.6</a>, can be written as
<span class="math display" id="eq:kalman-filter-update-3">\[\begin{equation}
\Sigma_{k \mid k} = \Sigma_{k \mid k-1} - \Sigma_{k\mid k-1} C_k^T (C_k \Sigma_{k \mid k-1} C_k^T + N_k)^{-1} C_k \Sigma_{k \mid k-1}.
\tag{6.24}
\end{equation}\]</span>
(This requires just a little bit thinking.) To update <span class="math inline">\(\Sigma_{k+1 \mid k}\)</span> from <span class="math inline">\(\Sigma_{k \mid k}\)</span>, we can use Corollary <a href="output-feedback.html#cor:linear-least-squares-z">6.2</a> and the independence of <span class="math inline">\(w_k\)</span> to obtain
<span class="math display" id="eq:kalman-filter-update-4">\[\begin{equation}
\Sigma_{k+1 \mid k} = A_k \Sigma_{k \mid k} A_k^T + M_k.
\tag{6.25}
\end{equation}\]</span></p>
<p>Equations <a href="output-feedback.html#eq:kalman-filter-update-1">(6.22)</a>-<a href="output-feedback.html#eq:kalman-filter-update-4">(6.25)</a> forms the Kalman Filter.</p>
<p><strong>Including controls</strong>. When the dynamics includes control
<span class="math display">\[
x_{k+1} = A_k x_k + B_k u_k + w_k,
\]</span>
the only change that needs to be made to the Kalman Filter is that <a href="output-feedback.html#eq:kalman-filter-update-2">(6.23)</a> should be replaced by
<span class="math display" id="eq:kalman-filter-update-5">\[\begin{equation}
x^\star_{k+1 \mid k} = A_k x^\star_{k \mid k} + B_k u_k.
\tag{6.26}
\end{equation}\]</span></p>
<div id="steady-state-kalman-filter" class="section level3 hasAnchor" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Steady-State Kalman Filter<a href="output-feedback.html#steady-state-kalman-filter" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Combining the two updates on covariance matrices <a href="output-feedback.html#eq:kalman-filter-update-3">(6.24)</a> and <a href="output-feedback.html#eq:kalman-filter-update-4">(6.25)</a>, we obtain
<span class="math display" id="eq:kalman-filter-covariance-recursion">\[\begin{equation}
\Sigma_{k+1 \mid k} = A_k (\Sigma_{k \mid k-1} - \Sigma_{k \mid k-1} C_k^T (C_k \Sigma_{k \mid k-1} C_k^T + N_k)^{-1} C_k \Sigma_{k \mid k-1}  ) A_k^T + M_k,
\tag{6.27}
\end{equation}\]</span>
which is the same as the discrete-time Riccati equation <a href="exactdp.html#eq:finite-discrete-lqr-riccati">(2.7)</a> when we study the solution of the finite-horizon LQR problem in Proposition <a href="exactdp.html#prp:discretetimefinitehorizonlqrsolution">2.1</a>.</p>
<p>When <span class="math inline">\(A_k, C_k, M_k, N_k\)</span> are constant matrices
<span class="math display">\[
A_k = A, \quad C_k = C, \quad, M_k = M, \quad N_k = N,
\]</span>
the recursion <a href="output-feedback.html#eq:kalman-filter-covariance-recursion">(6.27)</a> tends to the algebraic Riccati equation
<span class="math display" id="eq:kalman-filter-algebraic-riccati-equation">\[\begin{equation}
\Sigma = A(\Sigma - \Sigma C^T(C \Sigma C^T + N)^{-1}C \Sigma)A^T + M,
\tag{6.28}
\end{equation}\]</span>
for which a unique positive definite solution <span class="math inline">\(\Sigma\)</span> exists if <span class="math inline">\((A,C)\)</span> is observable and <span class="math inline">\((A,D)\)</span> is controllable with <span class="math inline">\(M = D D^T\)</span>. Then, using equation <a href="output-feedback.html#eq:kalman-filter-update-3">(6.24)</a>, we have that <span class="math inline">\(\Sigma_{k \mid k}\)</span> tends to
<span class="math display">\[
\bar{\Sigma} = \Sigma - \Sigma C^T (C \Sigma C^T + N)^{-1} C \Sigma.
\]</span>
This leads to the simple steady-state Kalman filter
<span class="math display" id="eq:steady-state-kalman-filter">\[\begin{equation}
x^\star_{k \mid k} = \underbrace{A x^\star_{k-1 \mid k-1}}_{\text{prediction}} + \underbrace{\Sigma C^T(C \Sigma C^T + N)^{-1} (y_k - CA x_{k-1 \mid k-1})}_{\text{feedback correction}}.
\tag{6.29}
\end{equation}\]</span></p>
</div>
<div id="continuous-time-kalman-filter" class="section level3 hasAnchor" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Continuous-time Kalman Filter<a href="output-feedback.html#continuous-time-kalman-filter" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider the continuous-time analog of the linear system in <a href="output-feedback.html#eq:kalman-filter-linear-system-discrete">(6.19)</a>
<span class="math display" id="eq:kalman-filter-linear-system-continuous">\[\begin{equation}
\begin{cases}
\dot{x} = A x + Bu + w \\
y = C x + v
\end{cases}
\tag{6.30}
\end{equation}\]</span>
where <span class="math inline">\(x \in \mathbb{R}^n\)</span> the state, <span class="math inline">\(u \in \mathbb{R}^m\)</span> the control, <span class="math inline">\(y \in \mathbb{R}^d\)</span> the measurement, and <span class="math inline">\(w,v\)</span> are white noises with
<span class="math display">\[
\mathbb{E}\{w\}=0, \quad \mathbb{E}\{ w w^T \} = M, \quad \mathbb{E}\{v\} = 0, \quad  \mathbb{E}\{ v v^T\} = N.
\]</span></p>
<p>Suppose the initial state <span class="math inline">\(x(0)\)</span> satisfies
<span class="math display">\[
\mathbb{E}\{ x(0) \} = \hat{x}_0, \quad \mathbb{E}\{ (x(0) - \hat{x}_0) (x(0) - \hat{x}_0)^T \} = \Sigma_0.
\]</span>
Then the continuous-time Kalman Filter updates the state estimate as
<span class="math display" id="eq:continuous-time-kalman-filter-state">\[\begin{equation}
\dot{\hat{x}} = \underbrace{A \hat{x} + Bu}_{\text{prediction}} + \underbrace{K (y - C \hat{x})}_{\text{feedback correction}},
\tag{6.31}
\end{equation}\]</span>
where <span class="math inline">\(K\)</span> is a feedback gain computed by
<span class="math display">\[
K = \Sigma C^T N^{-1},
\]</span>
with <span class="math inline">\(\Sigma\)</span> satisfying the following differential equation
<span class="math display" id="eq:continuous-time-kalman-filter-covariance">\[\begin{equation}
\dot{\Sigma} = A \Sigma + \Sigma A^T + M - \Sigma C^T N^{-1} C \Sigma.
\tag{6.32}
\end{equation}\]</span>
Similarly, at steady state, the differential equation <a href="output-feedback.html#eq:continuous-time-kalman-filter-covariance">(6.32)</a> tends to the continuous-time algebraic Riccati equation
<span class="math display">\[
0 = A \Sigma + \Sigma A^T + M - \Sigma C^T N^{-1} C \Sigma.
\]</span></p>
</div>
</div>
<div id="linear-quadratic-gaussian-control" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Linear Quadratic Gaussian Control<a href="output-feedback.html#linear-quadratic-gaussian-control" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>With our knowledge about the Kalman filter, we are ready to solve a particular instance of output-feedback control, known as the Linear Quadratic Gaussian (LQG) control.</p>
<p>Consider the discrete-time linear dynamical system:
<span class="math display" id="eq:lqg-linear-dynamical-system">\[\begin{equation}
\begin{cases}
x_{k+1} = A_k x_k + B_k u_k + w_k \\
y_k = C_k x_k + v_k
\end{cases}, \quad k=0,\dots,N-1,
\tag{6.33}
\end{equation}\]</span>
where <span class="math inline">\(w_k\)</span> and <span class="math inline">\(v_k\)</span> are white noises with
<span class="math display">\[
\mathbb{E}\{ w_k \} = 0, \mathbb{E}\{ v_k \} = 0, \quad k=0,\dots,N-1, \\
\mathbb{E} \{ w_k w_k^T \} = M_k, \mathbb{E} \{ v_k v_k^T \} = N_k, \quad k=0,\dots,N-1.
\]</span>
Assume the initial state <span class="math inline">\(x_0\)</span> follows a Gaussian distribution <span class="math inline">\(x_0 \sim \mathcal{N}(\bar{x}_0, S)\)</span>. This is the same setup as Section <a href="output-feedback.html#kalman-filter">6.2</a> Kalman filter.</p>
<p>The goal of the LQG control is
<span class="math display" id="eq:lqg-cost-to-go">\[\begin{equation}
\min_{u_k,k=0,\dots,N-1} \mathbb{E} \left\{ x_N^T Q_N x_N + \sum_{k=0}^{N-1} (x_k^T Q_k x_k + u_k^T R_k u_k)  \right\},
\tag{6.34}
\end{equation}\]</span>
where the expectation is taken over the randomness of both <span class="math inline">\(w_k\)</span> and <span class="math inline">\(v_k\)</span>. The LQG cost function <a href="output-feedback.html#eq:lqg-cost-to-go">(6.34)</a> reads exactly the same as the LQR problem in <a href="exactdp.html#eq:lqr-formulation">(2.2)</a>. However, the key difference between the LQG problem <a href="output-feedback.html#eq:lqg-cost-to-go">(6.34)</a> and the LQR problem <a href="exactdp.html#eq:lqr-formulation">(2.2)</a> is that in LQR the controller has full access to the state <span class="math inline">\(x_k\)</span> of the system, while in LQG the controller only has access to a sequence of measurements
<span class="math display">\[
Y_k = \{y_0,\dots,y_k \}.
\]</span></p>
<p>We will now show that the Kalman filter brings us back to the setup of LQR.</p>
<p>Let us rewrite the cost
<span class="math display">\[
\mathbb{E}\{x_k^T Q_k x_k \} = \mathbb{E} \left\{ \mathbb{E} \{ x_k^T Q_k x_k \mid Y_k \} \right\} = \mathbb{E} \left\{ \mathbb{E} \{ (x_k - x^\star_{k \mid k} + x^\star_{k \mid k})^T Q_k (x_k - x^\star_{k \mid k} + x^\star_{k \mid k}) \mid Y_k \}  \right\} \\
= \mathbb{E}\left\{ \mathbb{E}\{ (x_k - x^\star_{k \mid k})^T Q_k (x_k - x^\star_{k \mid k}) + 2 (x^\star_{k \mid k})^T Q_k (x_k - x^\star_{k \mid k}) + (x^\star_{k \mid k})^T Q_k  x^\star_{k \mid k}  \mid Y_k\} \right\} \\
= \mathbb{E}\{ (x^\star_{k \mid k})^T Q_k  x^\star_{k \mid k} \} +
\underbrace{\mathbb{E}\{ \mathbb{E}\{ 2 (x^\star_{k \mid k})^T Q_k (x_k - x^\star_{k \mid k}) \mid Y_k \} \}}_{=0 \text{ due to orthogonal projection principle}}
+ \underbrace{\mathbb{E}\{ (x_k - x^\star_{k \mid k})^T Q_k (x_k - x^\star_{k \mid k}) \}}_{=\text{tr}(Q_k \Sigma_{k \mid k})},
\]</span>
where <span class="math inline">\(x^\star_{k\mid k}\)</span> is the Kalman filter estimate of the state (i.e., the linear least squares estimate, or the conditional expectation). Note that from the Kalman filter we know the error covariance <span class="math inline">\(\Sigma_{k \mid k}\)</span> (and hence <span class="math inline">\(\text{tr}(Q_k \Sigma_{k \mid k})\)</span>) is independent from the control. Therefore, the LQG problem <a href="output-feedback.html#eq:lqg-cost-to-go">(6.34)</a> is equivalent to the following LQR problem
<span class="math display" id="eq:lqg-to-lqr">\[\begin{equation}
\min_{u_k, k=0,\dots,N-1} \mathbb{E} \left\{ (x^\star_{N\mid N})^T Q_N x^\star_{N\mid N} + \sum_{k=0}^{N-1} (x^\star_{k \mid k})^T Q_k x^\star_{k \mid k} + u_k^T R_k u_k \right\},
\tag{6.35}
\end{equation}\]</span>
for which we know the optimal control is (according to Proposition <a href="exactdp.html#prp:discretetimefinitehorizonlqrsolution">2.1</a>)
<span class="math display" id="eq:lqg-lqr-solution-u">\[\begin{equation}
u_k^\star = - \underbrace{(R_k + B_k^T S_{k+1} B_k)^{-1} B_k^T S_{k+1} A_k}_{K_k} x^\star_{k \mid k},
\tag{6.36}
\end{equation}\]</span>
with <span class="math inline">\(S_k\)</span> computed backwards as <span class="math inline">\(S_N = Q_N\)</span>,
<span class="math display" id="eq:lqg-lqr-solution-S">\[\begin{equation}
S_k = Q_k + A_k^T \left[ S_{k+1} - S_{k+1} B_k (R_k + B_k^T S_{k+1} B_k)^{-1} B_k^T S_{k+1}  \right] A_k.
\tag{6.37}
\end{equation}\]</span></p>
<p>In summary, to implement the optimal controller for LQR problem, we need to</p>
<ul>
<li><p>Compute <span class="math inline">\(S_k\)</span> backwards in time according to <a href="output-feedback.html#eq:lqg-lqr-solution-S">(6.37)</a></p></li>
<li><p>Run the Kalman filter <a href="output-feedback.html#eq:kalman-filter-update-1">(6.22)</a> and <a href="output-feedback.html#eq:kalman-filter-update-2">(6.23)</a> to obtain <span class="math inline">\(x^\star_{k \mid k}\)</span></p></li>
<li><p>Compute control according to <a href="output-feedback.html#eq:lqg-lqr-solution-u">(6.36)</a></p></li>
</ul>
<p><strong>Separation theorem</strong>. Our derivation above shows that the optimal output-feedback control for LQG consists of (i) an optimal estimator, the Kalman filter, and (ii) an optimal state-feedback controller, the LQR controller.</p>
<div id="steady-state-lqg" class="section level3 hasAnchor" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> Steady-state LQG<a href="output-feedback.html#steady-state-lqg" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In steady-state LQG, we consider the dynamical system
<span class="math display">\[\begin{equation}
\begin{cases}
x_{k+1} = A x_k + B u_k + w_k \\
y_k = C x_k + v_k
\end{cases}, \quad k=0,\dots
\end{equation}\]</span>
where <span class="math inline">\(\mathbb{E}\{ w_k\} =0, \mathbb{E}\{ v_k\} = 0\)</span>, and
<span class="math display">\[
\mathbb{E}\{w_k w_k^T \} = M, \quad \mathbb{E}\{v_k v_k^T \} = N.
\]</span>
The LQG control problem is
<span class="math display">\[\begin{equation}
\min \mathbb{E} \left\{ \sum_{k=0}^{\infty} (x_k^T Q_k x_k + u_k^T R_k u_k) \right\}.
\end{equation}\]</span>
The optimal controller is
<span class="math display">\[
u^\star_k = - \left[ (R + B^T S B)^{-1} B^T S A \right]x^\star_{k \mid k},
\]</span>
where <span class="math inline">\(S\)</span> is the solution to the discrete-time algebraic Riccati equation
<span class="math display">\[
S = Q + A^T \left[  S - SB (R + B^T S B)^{-1} B^T S \right]A,
\]</span>
and <span class="math inline">\(x^\star_{k\mid k}\)</span> comes from the steady-state Kalman filter
<span class="math display">\[
x_{k \mid k}^\star = A x^\star_{k-1\mid k-1} + B u_{k-1} + \Sigma C^T (C \Sigma C^T + N)^{-1} (y_k - C(A x^\star_{k-1\mid k-1} + B u_{k-1})),
\]</span>
with <span class="math inline">\(\Sigma\)</span> the solution to another discrete-time algebraic Riccati equation
<span class="math display">\[
\Sigma = M + A\left[ \Sigma - \Sigma C^T (N + C \Sigma C^T)^{-1} C \Sigma \right]A^T.
\]</span></p>
<div class="examplebox">
<div class="example">
<p><span id="exm:lqg-control-pendulum" class="example"><strong>Example 6.1  (LQG Stabilization of Simple Pendulum) </strong></span>Consider the pendulm dynamics that has already been shifted such that <span class="math inline">\(x=[\theta,\dot{\theta}]=0\)</span> represents the upright position that we want to stabilize (cf.Example <a href="exactdp.html#exm:lqr-pendulum-stabilization">2.1</a>)
<span class="math display">\[
\dot{x} = \begin{bmatrix}
x_2 \\
\frac{1}{ml^2} (u - b x_2 + mgl \sin x_1)
\end{bmatrix} + \begin{bmatrix} 0 \\ w \end{bmatrix},
\]</span>
where <span class="math inline">\(w\)</span> is a random white noise.</p>
<p>Linearizing the dynamics around <span class="math inline">\(x=0\)</span> we have
<span class="math display">\[
\dot{x} \approx \underbrace{\begin{bmatrix} 0 &amp; 1 \\ \frac{g}{l} &amp; - \frac{b}{ml^2} \end{bmatrix}}_{A_c} x + \underbrace{\begin{bmatrix} 0 \\ \frac{1}{ml^2} \end{bmatrix}}_{B_c} u + \begin{bmatrix} 0 \\ w \end{bmatrix}.
\]</span></p>
<p>We convert the continuous-time dynamics to discrete time with a fixed discretization <span class="math inline">\(h\)</span>
<span class="math display">\[
x_{k+1} = \dot{x}_k \cdot h + x_k = (h \cdot A_c + I) x_k + (h\cdot B_c) u_k + h \begin{bmatrix} 0 \\ w \end{bmatrix}  \\
= A x_k + B u_k + w_k.
\]</span></p>
<p>We assume we can only observe the angular position of the pendulum
<span class="math display">\[
y_k = \underbrace{\begin{bmatrix} 1 &amp; 0 \end{bmatrix}}_{C} x_k + v_k,
\]</span>
with <span class="math inline">\(v_k\)</span> some white noise.</p>
<p>We start with the true initial state <span class="math inline">\(x_0 = [2;-2]\)</span>, but with a noisy estimate <span class="math inline">\(x^\star_{0 \mid 0} = [0;0]\)</span>. Implementing the steady-state LQG controller produces the following result.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pendulum-lqg"></span>
<img src="images/pendulum_lqg.png" alt="LQG Stabilization of Simple Pendulum." width="80%" />
<p class="caption">
Figure 6.1: LQG Stabilization of Simple Pendulum.
</p>
</div>
<p>You can find code for this example <a href="https://github.com/ComputationalRobotics/OptimalControlEstimation-Examples/blob/main/pendulum_stabilization_lqg.m">here</a>.</p>
</div>
</div>
<p><strong>Closed-loop analysis</strong>. Now that we have the Kalman filter and LQR controller implemented, let us take a look at the closed-loop response of the system. To ease our notation, let us denote <span class="math inline">\(\hat{x}_k := x^\star_{k \mid k}\)</span> as the Kalman estimate of state. Then we can write the LQG controller as
<span class="math display" id="eq:lqg-closed-loop-1">\[\begin{equation}
\begin{cases}
\hat{x}_{k+1} = A \hat{x}_k + B u_k + L (y_{k+1} - C(A \hat{x}_k + B u_k) ) &amp; \text{Kalman filter}\\
x_{k+1} = A x_k + B u_k + w_k &amp; \text{Original dynamics}
\end{cases},
\tag{6.38}
\end{equation}\]</span>
where <span class="math inline">\(L\)</span> is the Kalman gain. The first equation can be simplified as
<span class="math display">\[
\hat{x}_{k+1} = A \hat{x}_k  + Bu_k + L( C\underbrace{(A x_k + B u_k + w_k)}_{x_{k+1}} + v_{k+1} - CA\hat{x}_k - CB u_k   )\\
= A \hat{x}_k + Bu_k + L (CA x_k - CA \hat{x}_k + C w_k + v_{k+1})
\]</span>
Let us denote the estimation error as <span class="math inline">\(e_k = x_k - \hat{x}_k\)</span>, the above equation becomes
<span class="math display">\[
\hat{x}_{k+1} = A \hat{x}_k + B u_k + LCA e_k + LC w_k + L v_{k+1}
\]</span>
Subtracting the equation above from the second equation of <a href="output-feedback.html#eq:lqg-closed-loop-1">(6.38)</a>, we have
<span class="math display" id="eq:lqg-closed-loop-2">\[\begin{equation}
e_{k+1} = (A - LCA) e_k + (I - LC) w_k - L v_{k+1},
\tag{6.39}
\end{equation}\]</span>
which describes the evolution of the error dynamics. Now with
<span class="math display">\[
u_k = - K \hat{x}_k = -K (x_k - e_k) = K e_k - K x_k
\]</span>
inserted into the second equation of <a href="output-feedback.html#eq:lqg-closed-loop-1">(6.38)</a>, we have
<span class="math display" id="eq:lqg-closed-loop-3">\[\begin{equation}
x_{k+1} = (A - BK) x_k + BK e_k + w_k,
\tag{6.40}
\end{equation}\]</span>
which describes the evolution of the true state dynamics.
Combining <a href="output-feedback.html#eq:lqg-closed-loop-2">(6.39)</a> and <a href="output-feedback.html#eq:lqg-closed-loop-3">(6.40)</a>, we have the closed-loop system
<span class="math display" id="eq:lqg-closed-loop-4">\[\begin{equation}
\begin{bmatrix} x_{k+1} \\ e_{k+1} \end{bmatrix} = \underbrace{\begin{bmatrix}
A - BK &amp; BK \\
0 &amp; A - LCA \end{bmatrix}}_{A_{\mathrm{cl}}} \begin{bmatrix} x_k \\ e_k \end{bmatrix} + \begin{bmatrix} w_k \\ (I - LC) w_k - L v_{k+1} \end{bmatrix}.
\tag{6.41}
\end{equation}\]</span>
Now observe that if the Kalman gain <span class="math inline">\(L\)</span> is stable, then <span class="math inline">\(e_{k}\)</span> tends to zero with some noise. In this case, if the LQR gain <span class="math inline">\(K\)</span> is stable, then the state <span class="math inline">\(x_k\)</span> also tends to zero with some noise. In fact, since <span class="math inline">\(A_{\mathrm{cl}}\)</span> is block-diagonal, we know the eigenvalues of <span class="math inline">\(A_{\mathrm{cl}}\)</span> contains those of <span class="math inline">\(A - BK\)</span> and those of <span class="math inline">\(A - LC A\)</span>.</p>
</div>
<div id="continuous-time-lqg" class="section level3 hasAnchor" number="6.3.2">
<h3><span class="header-section-number">6.3.2</span> Continuous-time LQG<a href="output-feedback.html#continuous-time-lqg" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
</div>
<div id="nonlinear-filtering" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> Nonlinear Filtering<a href="output-feedback.html#nonlinear-filtering" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Kalman filter is the optimal filter for linear dynamics, linear measurements, and Gaussian noises. However, interesting real-world systems are often nonlinear
<span class="math display" id="eq:nolinear-filter-system">\[\begin{equation}
\begin{cases}
x_{k+1} = f(x_k) + w_k, \\
y_k = h(x_k) + v_k
\end{cases},
\tag{6.42}
\end{equation}\]</span>
where <span class="math inline">\(w_k\)</span> is white disturbance <span class="math inline">\(\mathbb{E}\{ w_k\} =0, \mathbb{E}\{ w_k w_k^T\} = M_k\)</span>, <span class="math inline">\(v_k\)</span> is white measurement noise <span class="math inline">\(\mathbb{E}\{ v_k\} = 0, \mathbb{E} \{v_k v_k^T \} = N_k\)</span>, and <span class="math inline">\(f,g\)</span> are assumed to be differentiable nonlinear functions.</p>
<p>A nonlinear filter follows the general strategy of a Kalman filter
<span class="math display">\[\begin{equation}
\begin{split}
\text{Update estimate:}\quad \hat{x}_{k \mid k-1} \overset{(3)}{\longrightarrow} \hat{x}_{k \mid k} \overset{(1)}{\longrightarrow} \hat{x}_{k+1 \mid k}. \\
\text{Update covariance:}\quad \Sigma_{k \mid k-1} \overset{(4)}{\longrightarrow} \Sigma_{k \mid k} \overset{(2)}{\longrightarrow} \Sigma_{k+1 \mid k}.
\end{split}
\end{equation}\]</span>
where I have replaced <span class="math inline">\(x^\star\)</span> with <span class="math inline">\(\hat{x}\)</span> because the estimator is often not optimal in the case of nonlinear functions.</p>
<div id="extended-kalman-filter" class="section level3 hasAnchor" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> Extended Kalman Filter<a href="output-feedback.html#extended-kalman-filter" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The key idea of extended Kalman filter (EKF) is to linearize the nonlinear functions <span class="math inline">\(f\)</span> and <span class="math inline">\(h\)</span>.</p>
<p><strong>Prediction (1) and (2)</strong>. To perform prediction update according to the dynamics, we linearize <span class="math inline">\(f\)</span> around <span class="math inline">\(\hat{x}_{k\mid k}\)</span>
<span class="math display">\[
x_{k+1} = f(x_k) + w_k = f(\hat{x}_{k\mid k}) + J_f(\hat{x}_{k \mid k})(x_k - \hat{x}_{k \mid k}) + w_k + \text{h.o.t.},
\]</span>
where <span class="math inline">\(\text{h.o.t.}\)</span> standards for high-order terms, and <span class="math inline">\(J_f\)</span> is the Jacobian of the vector function <span class="math inline">\(f\)</span>:
<span class="math display">\[
J_f = \begin{bmatrix} \frac{\partial f_1}{x_1} &amp; \cdots &amp; \frac{\partial f_1}{\partial x_n} \\
\vdots &amp; \ddots &amp; \vdots \\
\frac{\partial f_n}{\partial x_1} &amp; \cdots &amp; \frac{\partial f_n}{\partial x_n}
\end{bmatrix}.
\]</span>
With this linearization, update (1) of EKF is simply
<span class="math display" id="eq:ekf-update-1">\[\begin{equation}
\hat{x}_{k+1 \mid k} = f(\hat{x}_{k \mid k}),
\tag{6.43}
\end{equation}\]</span>
and covariance update (2) is
<span class="math display" id="eq:ekf-update-2">\[\begin{equation}
\Sigma_{k+1\mid k} = M_k + J_f(\hat{x}_{k \mid k}) \Sigma_{k \mid k} J_f^T (\hat{x}_{k \mid k}).
\tag{6.44}
\end{equation}\]</span></p>
<p><strong>Correction (3) and (4)</strong>. To perform measurement correction from <span class="math inline">\(y_k\)</span>, we linearize <span class="math inline">\(h\)</span> around <span class="math inline">\(\hat{x}_{k \mid k-1}\)</span>
<span class="math display">\[
y_{k} = h(x_k) + v_k = h(\hat{x}_{k \mid k-1}) + J_h(\hat{x}_{k \mid k-1}) (x_k - \hat{x}_{k \mid k-1}) + v_k + \text{h.o.t.}.
\]</span>
With this linearization, update (3) of EKF is
<span class="math display" id="eq:ekf-update-3">\[\begin{equation}
\hspace{-10mm} \hat{x}_{k \mid k} = \hat{x}_{k \mid k-1} + \Sigma_{k\mid k-1}J_h^T(\hat{x}_{k\mid k-1}) ( J_h(\hat{x}_{k\mid k-1})\Sigma_{k \mid k-1} J_h^T(\hat{x}_{k\mid k-1}) + N_k  )^{-1}(y_k - h(\hat{x}_{k\mid k-1})),
\tag{6.45}
\end{equation}\]</span>
and update (4) of EKF is
<span class="math display" id="eq:ekf-update-4">\[\begin{equation}
\hspace{-10mm}\Sigma_{k \mid k-1} - \Sigma_{k \mid k-1}  \Sigma_{k\mid k-1}J_h^T(\hat{x}_{k\mid k-1}) ( J_h(\hat{x}_{k\mid k-1})\Sigma_{k \mid k-1} J_h^T(\hat{x}_{k\mid k-1}) + N_k  )^{-1} J_h(\hat{x}_{k \mid k-1}) \Sigma_{k \mid k-1}.
\tag{6.46}
\end{equation}\]</span></p>
<p>Compared with the original Kalman filter in <a href="output-feedback.html#eq:kalman-filter-update-1">(6.22)</a>-<a href="output-feedback.html#eq:kalman-filter-update-4">(6.25)</a>, we can see that EKF <a href="output-feedback.html#eq:ekf-update-1">(6.43)</a>-<a href="output-feedback.html#eq:ekf-update-4">(6.46)</a> (i) replaces <span class="math inline">\(A_k\)</span> with the Jacobian <span class="math inline">\(J_f(\hat{x}_{k \mid k})\)</span>, (ii) replaces <span class="math inline">\(C_k\)</span> with the Jacobian <span class="math inline">\(J_h(\hat{x}_{k \mid k-1})\)</span>, and (iii) replaces <span class="math inline">\(C_k \hat{x}_{k \mid k-1}\)</span> with <span class="math inline">\(h(\hat{x}_{k \mid k-1})\)</span> (those are the expected measurements).</p>
<p><strong>When does EKF perform well?</strong> Since EKF is based on linearization, it performs well when (i) the functions <span class="math inline">\(f,g\)</span> are locally linear around the linearization points, and (ii) there is less uncertainty in the covariance matrices <span class="math inline">\(\Sigma_{k \mid k-1},\Sigma_{k \mid k}\)</span>. Good illustrations can be found in Fig. 3.5 and Fig. 3.6 of <span class="citation">(<a href="#ref-thrun05book-probabilistic">Thrun, Burgard, and Fox 2005</a>)</span>.</p>
<p><strong>Guarantees</strong>. Under the technical conditions in <span class="citation">(<a href="#ref-reif99tac-stochastic">Reif et al. 1999</a>)</span>, the estimation error of EKF can be guaranteed to be bounded.</p>
</div>
<div id="unscented-kalman-filter" class="section level3 hasAnchor" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> Unscented Kalman Filter<a href="output-feedback.html#unscented-kalman-filter" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In nonlinear filtering, usually the distribution of the true state is never a Gaussian distribution. The key idea of unscented Kalman filter is to use a set of so-called <em>Sigma points</em> to capture the most important statistical properties of the true distribution, notably the first and second-order moments (i.e., mean and covariance).</p>
<p><strong>Sigma points</strong>. Given a distribution with mean and covariance <span class="math inline">\((\mu, \Sigma)\)</span> (assume the random variable has dimension <span class="math inline">\(n\)</span>), it can be shown that <span class="math inline">\((2n+1)\)</span> Sigma points can be chosen to match the mean and covariance <span class="citation">(<a href="#ref-van04-sigma">Van Der Merwe 2004</a>)</span>
<span class="math display">\[\begin{equation}
\begin{split}
x^0 = \mu, \\
x^i = \mu + \left[\sqrt{(n+\lambda)\Sigma} \right]_{i}, \quad i = 1,\dots,n, \\
x^{i} = \mu - \left[\sqrt{(n+\lambda)\Sigma} \right]_{i-n}, \quad i=n+1,\dots,2n,
\end{split}
\end{equation}\]</span>
where <span class="math inline">\(\sqrt{(n+\lambda)\Sigma}\)</span> denotes the square root of the matrix <span class="math inline">\((n+\lambda)\Sigma\)</span>, <span class="math inline">\([\cdot]_i\)</span> denotes the <span class="math inline">\(i\)</span>-th column of the matrix, and
<span class="math display">\[
\lambda = \alpha^2(n+\kappa) - n,
\]</span>
is a scaling parameter determined by hyperparameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\kappa\)</span> (<span class="math inline">\(\alpha\)</span> usually set between <span class="math inline">\(10^{-2}\)</span> and <span class="math inline">\(1\)</span>, and <span class="math inline">\(\kappa\)</span> is usually set to either <span class="math inline">\(0\)</span> or <span class="math inline">\(3-n\)</span>). Each of the Sigma point also comes with two weights as
<span class="math display">\[
w^0_m = \frac{\lambda}{n+\lambda}, w^0_c = \frac{\lambda}{n+\lambda} + (1 - \alpha^2 + \beta), \\
w^i_m = w^i_c = \frac{1}{2(L + \lambda)}, \quad i=1,\dots,2n,
\]</span>
where <span class="math inline">\(\beta\)</span> is an extra hyperparameter (for Gaussian <span class="math inline">\(\beta=2\)</span>).</p>
<p>Now we are ready to use the idea of Sigma points to present the unscented Kalman filter (UKF).</p>
<p><strong>Prediction (1) and (2)</strong>. To perform the prediction step, we generate <span class="math inline">\(2n+1\)</span> Sigma points from the distribution <span class="math inline">\((\hat{x}_{k \mid k}, \Sigma_{k \mid k})\)</span>:
<span class="math display">\[
\bar{x}^0_{k \mid k}, \dots, \bar{x}^{2n}_{k \mid k}.
\]</span>
The estimate <span class="math inline">\(\hat{x}_{k+1\mid k}\)</span> is updated as the sample mean of evaluating <span class="math inline">\(f\)</span> on all Sigma points
<span class="math display" id="eq:ukf-update-1">\[\begin{equation}
\hat{x}_{k+1 \mid k} = \sum_{i=0}^{2n} w^i_m f(\bar{x}^{i}_{k \mid k}),
\tag{6.47}
\end{equation}\]</span>
and the covariance estimate is updated as the sample covariance
<span class="math display" id="eq:ukf-update-2">\[\begin{equation}
\Sigma_{k+1 \mid k} = M_k + \sum_{i=0}^{2n} w^i_c (f(\bar{x}^{i}_{k \mid k}) - \hat{x}_{k+1 \mid k})(f(\bar{x}^{i}_{k \mid k}) - \hat{x}_{k+1 \mid k})^T,
\tag{6.48}
\end{equation}\]</span>
where <span class="math inline">\(M_k\)</span> comes from the disturbance <span class="math inline">\(w_k\)</span> in the dynamics.</p>
<p><strong>Correction (3) and (4)</strong>. To understand the UKF measurement correction, we need to present a key observation of the original Kalman filter. In <a href="output-feedback.html#eq:kalman-filter-update-1">(6.22)</a> and <a href="output-feedback.html#eq:kalman-filter-update-3">(6.24)</a>, the matrix
<span class="math display">\[
C_k \Sigma_{k \mid k-1} C_k^T + N_k
\]</span>
can be interpreted as the covariance of the measurement <span class="math inline">\(y_k\)</span> (conditioned on all past measurements), i.e., <span class="math inline">\(\Sigma_{yy,k}\)</span>, due to the measurement function <span class="math inline">\(y_k = C_k x_k + v_k\)</span>, while the matrix
<span class="math display">\[
\Sigma_{k \mid k-1} C_k^T
\]</span>
can be interpreted as the correlation between <span class="math inline">\(x_k\)</span> and <span class="math inline">\(y_k\)</span>, i.e., <span class="math inline">\(\Sigma_{xy,k}\)</span>.</p>
<p>Now that we have Sigma points in UKF, we can use them to approximate <span class="math inline">\(\Sigma_{yy,k}\)</span> and <span class="math inline">\(\Sigma_{xy,k}\)</span>. To do so, we first generate <span class="math inline">\((2n+1)\)</span> Sigma points from the distribution <span class="math inline">\((\hat{x}_{k \mid k-1}, \Sigma_{k \mid k-1})\)</span>
<span class="math display">\[
\bar{x}^0_{k \mid k-1}, \dots, \bar{x}^{2n}_{k \mid k-1}.
\]</span>
We then compute the expected measurements of these Sigma points
<span class="math display">\[
\bar{y}^i_{k \mid k-1} = h(\bar{x}^i_{k \mid k-1}), i=0,\dots,2n.
\]</span>
The sample mean of these measurements is
<span class="math display">\[
\hat{y}_{k \mid k-1} = \sum_{i=0}^{2n} w^i_m \bar{y}^i_{k \mid k-1},
\]</span>
and the sample covariance is
<span class="math display">\[
\Sigma_{yy,k} = N_k + \sum_{i=0}^{2n} w^i_c (\bar{y}^i_{k \mid k-1} - \hat{y}_{k \mid k-1})(\bar{y}^i_{k \mid k-1} - \hat{y}_{k \mid k-1})^T.
\]</span>
The sample correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> can be computed as
<span class="math display">\[
\Sigma_{xy,k} = \sum_{i=0}^{2n} w^i_c (\bar{x}^i_{k \mid k-1} - \hat{x}_{k \mid k-1}) (\bar{y}^i_{k \mid k-1} - \hat{y}_{k \mid k-1})^T.
\]</span>
As a result, the Kalman gain matrix is
<span class="math display">\[
L_k = \Sigma_{xy,k} \Sigma^{-1}_{yy,k}.
\]</span>
The UKF update (3) is therefore
<span class="math display" id="eq:ukf-update-3">\[\begin{equation}
\hat{x}_{k \mid k} = \hat{x}_{k \mid k-1} + L_k (y_k - \hat{y}_{k \mid k-1}),
\tag{6.49}
\end{equation}\]</span>
and the update (4) is
<span class="math display" id="eq:ukf-update-4">\[\begin{equation}
\Sigma_{k \mid k} = \Sigma_{k \mid k-1} - L_k \Sigma_{yy,k} L_k^T.
\tag{6.50}
\end{equation}\]</span></p>
<p><strong>Applications of EKF and UKF</strong>. Perhaps one of the most of well-known applications of EKF and UKF is simultaneous location and mapping (SLAM) in mobile robotics. Matlab has a <a href="https://www.mathworks.com/help/nav/ug/ekf-based-landmark-slam.html">nice demo</a> that I recommend you to play with.</p>
</div>
<div id="particle-filter" class="section level3 hasAnchor" number="6.4.3">
<h3><span class="header-section-number">6.4.3</span> Particle Filter<a href="output-feedback.html#particle-filter" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Kalman filter, EKF, and UKF all represent the uncertainty of the state as Gaussian distributions, specifically as means and covariances. However, as mentioned before, the true distribution of the state is rarely a Gaussian distribution. How can we faithfully represent non-Gaussian distributions?</p>
<p>The UKF does provide us with a possible solution. UKF represents the Gaussian distribution by <span class="math inline">\(2n+1\)</span> Sigma points. What if we generalize this idea by allowing more points, or in other words, represent a distribution by random samples?</p>
<p>This is the basic idea of a <em>particle filter</em>, which is arguably one of the most high-impact nonlinear filtering techniques. The idea of a particle filter is simple to state. Consider the dynamical system <a href="output-feedback.html#eq:nolinear-filter-system">(6.42)</a>, but this time assume we know the distribution of <span class="math inline">\(w_k\)</span> and <span class="math inline">\(v_k\)</span>. For example, in the case of a Gaussian distribution <span class="math inline">\(\mathcal{N}(\mu,\Sigma)\)</span> (with dimension <span class="math inline">\(n\)</span>), we know its probability density function is
<span class="math display" id="eq:Gaussian-pdf">\[\begin{equation}
\mathbb{P}(x = \xi) = \frac{\exp\left( -\frac{1}{2} (\xi- \mu)^T \Sigma^{-1} (\xi - \mu) \right)}{\sqrt{(2\pi)^n \det \Sigma}}.
\tag{6.51}
\end{equation}\]</span>
The goal of a nonlinear filter is to estimate the conditional distribution (or sometimes called the <em>belief</em>) of <span class="math inline">\(x_k\)</span> given all previous measurements <span class="math inline">\(Y_k = (y_0,\dots,y_k)\)</span>
<span class="math display">\[
p(x_k \mid Y_k).
\]</span>
Since the conditional distribution generally cannot be written analytically, a particle filter will represent the conditional distribution as a set of samples, i.e.,
<span class="math display">\[
\mathcal{X}_{k\mid k} = \{x_{k \mid k}^1,\dots,x_{k\mid k}^M \} \sim p(x_k \mid Y_k),
\]</span>
where <span class="math inline">\(M\)</span> is the total number of samples. The particle filter will then update the set of samples, using a similar prediction-correction two-step approach:
<span class="math display">\[
\mathcal{X}_{k \mid k} \overset{\text{prediction}}{\longrightarrow} \mathcal{X}_{k+1 \mid k} \overset{\text{correction}}{\longrightarrow} \mathcal{X}_{k+1 \mid k+1},
\]</span>
where the prediction step leverages the dynamics, and the correction step leverages the measurement function.</p>
<p><strong>Prediction</strong>. The prediction step is straightforward
<span class="math display">\[
\mathcal{X}_{k+1\mid k} = \{x^i_{k+1\mid k} \}_{i=1}^M, \quad   x_{k+1\mid k}^i = f(x^i_{k\mid k}) + w_k^i, i=1,\dots,M,
\]</span>
which basically passes each sample in <span class="math inline">\(\mathcal{X}_{k\mid k}\)</span> through the nonlinear dynamics <span class="math inline">\(f\)</span> and then add a random disturbance. Note that <span class="math inline">\(w_k^i\)</span> follows the known distribution of the noise that we know how to sample from, for example it can be the Gaussian distribution in <a href="output-feedback.html#eq:Gaussian-pdf">(6.51)</a>.</p>
<p><strong>Correction</strong>. The correction step will leverage the new measurement, <span class="math inline">\(y_{k+1}\)</span>, to adjust the set of samples. Particularly, we will evaluate the probability of observing <span class="math inline">\(y_{k+1}\)</span> for each of the samples in the set <span class="math inline">\(\mathcal{X}_{k+1 \mid k}\)</span>, that is
<span class="math display">\[
\alpha_{k+1}^i = p(y_{k+1} \mid x_{k+1\mid k}^i), i=1,\dots,M.
\]</span>
This is simply the probability of
<span class="math display">\[
\alpha_{k+1}^i = \mathbb{P}(v_{k+1} = y_{k+1} - h(x_{k+1\mid k}^i)),
\]</span>
which can be computed since we know the distribution of <span class="math inline">\(v_{k+1}\)</span>. For example, if the distribution of <span class="math inline">\(v_{k+1}\)</span> is Gaussian, then we can evaluate the probability using <a href="output-feedback.html#eq:Gaussian-pdf">(6.51)</a>. Intuitively, the higher <span class="math inline">\(\alpha_{k+1}^i\)</span> is, the more likely it is for the true state to be <span class="math inline">\(x_{k+1\mid k}^i\)</span>. Therefore, effectively, we have obtained a set of samples together with their probabilities
<span class="math display">\[
\{ (x_{k+1\mid k}^i, \alpha_{k+1}^i) \}_{i=1}^M.
\]</span>
The next step is to perform <em>importance sampling</em>. In particular, we will generate a new set of <span class="math inline">\(M\)</span> samples by sampling (with replacement) from the population <span class="math inline">\(\mathcal{X}_{k+1 \mid k}\)</span> with the probability of sampling the <span class="math inline">\(i\)</span>-th sample being <span class="math inline">\(\alpha_{k+1}^i\)</span>. This leads to the new sample set <span class="math inline">\(\mathcal{X}_{k+1 \mid k+1}\)</span>.</p>
<p>Hopefully you see that the particle filter is very easy to implement. Let us work on a simple example.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:nonlinear-filter-robot-localization" class="example"><strong>Example 6.2  (Robot Localization by Nonlinear Filtering) </strong></span>Consider a 2D robot with state <span class="math inline">\(s = (x,y,\theta)\)</span> where <span class="math inline">\((x,y)\)</span> is the position and <span class="math inline">\(\theta\)</span> is the heading. The robot has two controls, the first one being the linear velocity <span class="math inline">\(l\)</span>, and the second one being the angular velocity (steering) <span class="math inline">\(u\)</span>. Therefore, the dynamics of the robot is
<span class="math display">\[
\begin{bmatrix}
x_{k+1} \\ y_{k+1} \\ \theta_{k+1} \end{bmatrix} =
\begin{bmatrix}
x_k + (l \cos \theta_k)\Delta t \\
y_k + (l \sin \theta_k)\Delta t \\
\theta_k + u \Delta t \end{bmatrix}
+ w_k,
\]</span>
where <span class="math inline">\(w_k\)</span> is assumed to be some Gaussian noise, and <span class="math inline">\(\Delta t\)</span> is time discretization.</p>
<p>There are a set of <span class="math inline">\(N\)</span> landmarks in the environment, each with location <span class="math display">\[
(x_{lm,i},y_{lm,i}),i=1,\dots,N.
\]</span>
The robot is equipped with a sensor that measures distance from each landmark
<span class="math display">\[
o_k = \begin{bmatrix}  \vdots \\ o_{k,i} \\ \vdots  \end{bmatrix} + v_k, \quad o_{k,i} = \sqrt{(x_k - x_{lm,i})^2 + (y_k - y_{lm,i})^2}, i=1,\dots,N,
\]</span>
where <span class="math inline">\(v_k\)</span> is assumed to be known Gaussian noise.</p>
<p>We can implement a particle filter for localizing the robot given distance measurements from the landmarks.</p>
<p>We set <span class="math inline">\(N=20\)</span> landmarks, in the beginning, the prior estimation of the robot location is completely wrong, as shown in Fig. <a href="output-feedback.html#fig:robot-localization-step-1">6.2</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:robot-localization-step-1"></span>
<img src="images/robot_localization_pf_step1.png" alt="Initial estimate of the robot location." width="80%" />
<p class="caption">
Figure 6.2: Initial estimate of the robot location.
</p>
</div>
<p>After 200 steps of particle filter, we can see the particles cluster around the groundtruth robot location.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:robot-localization-step-200"></span>
<img src="images/robot_localization_pf_step200.png" alt="Initial estimate of the robot location." width="80%" />
<p class="caption">
Figure 6.3: Initial estimate of the robot location.
</p>
</div>
<p>You can play with the code <a href="https://github.com/ComputationalRobotics/OptimalControlEstimation-Examples/blob/main/robot_localization_particle_filter.m">here</a>.</p>
</div>
</div>
<p>Particle filters have many advantages:</p>
<ul>
<li><p>Ability to approximate non-Gaussian distributions</p></li>
<li><p>Works for any dynamics model and observation model</p></li>
<li><p>Good scalability, they are ``embarassingly parallelizable</p></li>
<li><p>Easy to implement</p></li>
</ul>
<p>However, there are several notable issues with particle filters</p>
<ul>
<li><p>Lack of diversity: over time, especially with uninformative sensor readings, samples tend to congregate (because the resampling step removes particles)</p></li>
<li><p>Measuring Particle Filter performance is difficult</p></li>
<li><p>Particle Filters are non-deterministic</p></li>
</ul>
</div>
<div id="feedback-particle-filter" class="section level3 hasAnchor" number="6.4.4">
<h3><span class="header-section-number">6.4.4</span> Feedback Particle Filter<a href="output-feedback.html#feedback-particle-filter" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="citation">(<a href="#ref-yang13tac-feedback">T. Yang, Mehta, and Meyn 2013</a>)</span></p>
</div>
</div>
<div id="state-observer" class="section level2 hasAnchor" number="6.5">
<h2><span class="header-section-number">6.5</span> State Observer<a href="output-feedback.html#state-observer" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For the system <a href="output-feedback.html#eq:output-feedback-system">(6.1)</a>, let us denote</p>
<ul>
<li><p><span class="math inline">\(X(x_0,t_0;t;u)\)</span> the solution at time <span class="math inline">\(t\)</span> with input <span class="math inline">\(u\)</span> and initial condition <span class="math inline">\(x_0\)</span> at time <span class="math inline">\(t_0\)</span>; when <span class="math inline">\(t_0 = 0\)</span>, we write <span class="math inline">\(X(x_0;t;u)\)</span></p></li>
<li><p><span class="math inline">\(Y(x_0,t_0;t;u)\)</span> the output at time <span class="math inline">\(t\)</span> with input <span class="math inline">\(u\)</span> and initial condition <span class="math inline">\(x_0\)</span> at time <span class="math inline">\(t_0\)</span>, i.e., <span class="math inline">\(Y(x_0,t_0;t;u) = h(X(x_0,t_0;t;u), u(t))\)</span>; when <span class="math inline">\(t_0 = 0\)</span>, we write <span class="math inline">\(y_{x_0,u}(t)\)</span>;</p></li>
<li><p><span class="math inline">\(\mathcal{X}_0\)</span> a subset of <span class="math inline">\(\mathbb{X}\)</span> containing the initial conditions we consider; for any <span class="math inline">\(x_0 \in \mathcal{X}_0\)</span>, we write <span class="math inline">\(\sigma^+_{\mathcal{X}}(x_0;u)\)</span> the maximal time of existence of <span class="math inline">\(X(x_0,\cdot;t;u)\)</span> in a set <span class="math inline">\(\mathcal{X}\)</span></p></li>
<li><p><span class="math inline">\(\mathcal{U}\)</span> the set of all sufficiently many times differentiable inputs <span class="math inline">\(u: [0,+\infty) \rightarrow \mathbb{U}\)</span>.</p></li>
</ul>
<p>The problem of state observation is to produce an estimated state <span class="math inline">\(\hat{x}(t)\)</span> of the true state <span class="math inline">\(X(x_0,t_0;t;u)\)</span> based on knowledge about the system <a href="output-feedback.html#eq:output-feedback-system">(6.1)</a> and information about the history of inputs <span class="math inline">\(u_{[0,t]}\)</span> and outputs <span class="math inline">\(y_{[0,t]}\)</span>, so that <span class="math inline">\(\hat{x}(t)\)</span> asymptotically converges to <span class="math inline">\(X(x_0,t_0;t;u)\)</span>, for any initial condition <span class="math inline">\(x_0 \in \mathcal{X}_0\)</span> and any input <span class="math inline">\(u \in \mathcal{U}\)</span>.</p>
<p>There are multiple ways for solving the problem of state observation (see e.g., <span class="citation">(<a href="#ref-bernard19book-observer">Bernard 2019</a>)</span>, <span class="citation">(<a href="#ref-bernard22arc-observer">Bernard, Andrieu, and Astolfi 2022</a>)</span>). Here we are particularly interested in the approach using a <em>state observer</em>, i.e., a dynamical system whose <em>internal state</em> evolves according to the history of inputs and outputs, from which a state estimation can be reconstructed that guarantees asymptotic convergence to the true state. We formalize this concept below.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:stateobserver" class="definition"><strong>Definition 6.1  (State Observer) </strong></span>A state observer for system <a href="output-feedback.html#eq:output-feedback-system">(6.1)</a> is a couple <span class="math inline">\((\mathcal{F},\mathcal{T})\)</span> such that</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\mathcal{F}: \mathbb{R}^{l} \times \mathbb{R}^{m} \times \mathbb{R}^d \rightarrow \mathbb{R}^l\)</span> is continuous</p></li>
<li><p><span class="math inline">\(\mathcal{T}\)</span> is a family of continuous functions indexed by <span class="math inline">\(u \in \mathcal{U}\)</span> where each <span class="math inline">\(\mathcal{T}_u: \mathbb{R}^l \times [0,+\infty) \rightarrow \mathbb{R}^n\)</span> respects the causality condition
<span class="math display">\[
\forall \tilde{u}: [0,+\infty) \rightarrow \mathbb{R}^m,\forall t \in [0,+\infty), u_{[0,t]} = \tilde{u}_{[0,t]} \Rightarrow  \mathcal{F}_u (\cdot,t) = \mathcal{F}_{\tilde{u}}(\cdot,t).
\]</span></p></li>
<li><p>For any <span class="math inline">\(u \in \mathcal{U}\)</span>, any <span class="math inline">\(z_0 \in \mathbb{R}^l\)</span>, and any <span class="math inline">\(x_0 \in \mathcal{X}_0\)</span> such that <span class="math inline">\(\sigma^+_{\mathbb{X}}(x_0;u) = +\infty\)</span>, any solution <span class="math inline">\(Z(z_0;t;u,y_{x_0,u})\)</span><a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> to
<span class="math display" id="eq:observer-definition-1">\[\begin{equation}
\dot{z} = \mathcal{F}(z,u,y_{x_0,u})
\tag{6.52}
\end{equation}\]</span>
initialized at <span class="math inline">\(z_0\)</span> at time <span class="math inline">\(0\)</span> with input <span class="math inline">\(u\)</span> and <span class="math inline">\(y_{x_0,u}\)</span> exists on <span class="math inline">\([0,+\infty)\)</span> and satisfies
<span class="math display" id="eq:observer-definition-2">\[\begin{equation}
\lim_{t \rightarrow \infty} \Vert \hat{X}(x_0,z_0;t;u) - X(x_0;t;u) \Vert = 0,
\tag{6.53}
\end{equation}\]</span>
with
<span class="math display" id="eq:observer-definition-3">\[\begin{equation}
\hat{X}(x_0,z_0;t;u) = \mathcal{T}_u(Z(z_0;t;u,y_{x_0,u}),t).
\tag{6.54}
\end{equation}\]</span>
In words, (i) the state observer maintains an internal state (or latent state) <span class="math inline">\(z \in \mathbb{R}^l\)</span> that evolves according to the latent dynamics <span class="math inline">\(\mathcal{F}\)</span> in <a href="output-feedback.html#eq:observer-definition-1">(6.52)</a>, where <span class="math inline">\(u\)</span> and <span class="math inline">\(y_{x_0,u}\)</span> are inputs; (ii) an estimated state can be reconstructed from the internal state using <span class="math inline">\(\mathcal{T}_u\)</span> as in <a href="output-feedback.html#eq:observer-definition-3">(6.54)</a>; and (iii) the error between the estimated state and the true state (defined by a proper distance function <span class="math inline">\(\Vert \cdot \Vert\)</span> on <span class="math inline">\(\mathbb{X}\)</span>) converges to zero.</p></li>
</ol>
<p>If <span class="math inline">\(\mathcal{T}_u\)</span> is the same for any <span class="math inline">\(u \in \mathcal{U}\)</span> and is also time independent, then we say <span class="math inline">\(\mathcal{T}\)</span> is <em>stationary</em>.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> In this case, we can simply write the observer <a href="output-feedback.html#eq:observer-definition-1">(6.52)</a> and <a href="output-feedback.html#eq:observer-definition-3">(6.54)</a> as
<span class="math display" id="eq:observer-definition-simple">\[\begin{equation}
\begin{split}
\dot{z} &amp;= \mathcal{F}(z,u,y) \\
\hat{x} &amp;= \mathcal{T}(z).
\end{split}
\tag{6.55}
\end{equation}\]</span></p>
<p>If <span class="math inline">\(\hat{x}\)</span> can be read off directly from <span class="math inline">\(z\)</span>, then we say the observer <a href="output-feedback.html#eq:observer-definition-simple">(6.55)</a> is <em>in the given coordinates</em>. A special case of this is when <span class="math inline">\(\hat{x} = z\)</span>, i.e., the internal state of the observer is the same as the system state.</p>
</div>
</div>
<div id="general-design-strategy" class="section level3 hasAnchor" number="6.5.1">
<h3><span class="header-section-number">6.5.1</span> General Design Strategy<a href="output-feedback.html#general-design-strategy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:observerdesignmeta" class="theorem"><strong>Theorem 6.1  (Meta Observer) </strong></span>Let <span class="math inline">\(F: \mathbb{R}^p \times \mathbb{R}^m \times \mathbb{R}^d \rightarrow \mathbb{R}^p\)</span>, <span class="math inline">\(H: \mathbb{R}^p \times \mathbb{R}^m \rightarrow \mathbb{R}^d\)</span> and <span class="math inline">\(\mathcal{F}: \mathbb{R}^p \times \mathbb{R}^m \times \mathbb{R}^d \rightarrow \mathbb{R}^p\)</span> be continuous functions such that
<span class="math display" id="eq:meta-observer-zeta-hat">\[\begin{equation}
\dot{\hat{\xi}} = \mathcal{F}(\hat{\xi}, u, \tilde{y})
\tag{6.56}
\end{equation}\]</span>
is an observer for
<span class="math display" id="eq:meta-observer-zeta">\[\begin{equation}
\dot{\xi} = F(\xi,u,H(\xi,u)), \quad \tilde{y} = H(\xi,u),
\tag{6.57}
\end{equation}\]</span>
i.e., for any <span class="math inline">\(\xi_0,\hat{\xi}_0 \in \mathbb{R}^p\)</span> and any <span class="math inline">\(u \in \mathcal{U}\)</span>, the solution of the observer <a href="output-feedback.html#eq:meta-observer-zeta-hat">(6.56)</a>,
denoted by <span class="math inline">\(\hat{\Xi}(\hat{\xi}_0;t;u;\tilde{y}_{\xi_0,u})\)</span>, and the solution of the true system <a href="output-feedback.html#eq:meta-observer-zeta">(6.57)</a>, denoted by <span class="math inline">\(\Xi(\xi_0;t;u)\)</span>, satisfy
<span class="math display" id="eq:meta-observer-zeta-converge">\[\begin{equation}
\lim_{t \rightarrow \infty} \Vert \hat{\Xi}(\hat{\xi}_0;t;u;\tilde{y}_{\xi_0,u}) - \Xi(\xi_0;t;u) \Vert = 0.
\tag{6.58}
\end{equation}\]</span>
Note that the observer <a href="output-feedback.html#eq:meta-observer-zeta-hat">(6.56)</a> is stationary and in the given coordinates for system <a href="output-feedback.html#eq:meta-observer-zeta">(6.57)</a>. Indeed the internal state of the observer is the same as the system state.</p>
<p>Now suppose for any <span class="math inline">\(u \in \mathcal{U}\)</span>, there exists a continuous function (i.e., coordinate transformation) <span class="math inline">\(T_u: \mathbb{R}^n \times \mathbb{R} \rightarrow \mathbb{R}^p\)</span> and a subset <span class="math inline">\(\mathcal{X}\)</span> of <span class="math inline">\(\mathbb{X}\)</span> such that</p>
<ol style="list-style-type: decimal">
<li><p>For any <span class="math inline">\(x_0 \in \mathcal{X}_0\)</span> such that <span class="math inline">\(\sigma^+_{\mathbb{X}}(x_0;u) = + \infty\)</span>, <span class="math inline">\(X(x_0;\cdot;u)\)</span> remains in <span class="math inline">\(\mathcal{X}\)</span></p></li>
<li><p>There exists a concave <span class="math inline">\(\mathcal{K}\)</span><a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> function <span class="math inline">\(\rho\)</span> and a positive number <span class="math inline">\(\bar{t}\)</span> such that
<span class="math display">\[
\Vert x_a - x_b \Vert \leq \rho (| T_u(x_a,t) - T_u(x_b,t) |), \quad \forall x_a,x_b \in \mathcal{X}, t \geq \bar{t},
\]</span>
i.e., <span class="math inline">\(x \mapsto T_u(x,t)\)</span> becomes injective on <span class="math inline">\(\mathcal{X}\)</span>,<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a> uniformly in time and space, after a certain time <span class="math inline">\(\bar{t}\)</span>.</p></li>
<li><p><span class="math inline">\(T_u\)</span> transforms the system <a href="output-feedback.html#eq:output-feedback-system">(6.1)</a> into the system <a href="output-feedback.html#eq:meta-observer-zeta">(6.57)</a>, i.e., for all <span class="math inline">\(x \in \mathcal{X}\)</span> and all <span class="math inline">\(t \geq 0\)</span>, we have
<span class="math display" id="eq:meta-observer-transform">\[\begin{equation}
L_{(f,1)} T_u(x,t) = F(T_u(x,t),u,h(x,u)), \quad h(x,u) = H(T_u(x,t),u),
\tag{6.59}
\end{equation}\]</span>
where <span class="math inline">\(L_{(f,1)} T_u(x,t)\)</span> is the Lie derivative of <span class="math inline">\(T_u\)</span> along the vector field <span class="math inline">\((f,1)\)</span>
<span class="math display">\[
L_{(f,1)} T_u(x,t) = \lim_{\tau \rightarrow 0} \frac{ T_u (X(x,t;t+\tau;u),t+\tau) - T_u(x,t) }{\tau}.
\]</span></p></li>
<li><p><span class="math inline">\(T_u\)</span> respects the causality condition
<span class="math display">\[
\forall \tilde{u}: [0,+\infty) \rightarrow \mathbb{R}^m, \forall t \in [0,+\infty), u_{[0,t]} = \tilde{u}_{[0,t]} \Rightarrow T_u(\cdot,t) = T_{\tilde{u}}(\cdot,t).
\]</span></p></li>
</ol>
<p>Then, for any <span class="math inline">\(u \in \mathcal{U}\)</span>, there exists a function <span class="math inline">\(\mathcal{T}_u: \mathbb{R}^p \times [0,+\infty) \rightarrow \mathcal{X}\)</span> (satisfying the causality condition) such that for any <span class="math inline">\(t \geq \bar{t}\)</span>, <span class="math inline">\(\xi \mapsto \mathcal{T}_u (\xi, t)\)</span> is uniformly continuous on <span class="math inline">\(\mathbb{R}^p\)</span> and satisfies
<span class="math display">\[
\mathcal{T}_u \left( T_u(x,t),t \right) = x, \forall x \in \mathcal{X}.
\]</span>
Moreover, denoting <span class="math inline">\(\mathcal{T}\)</span> the family of functions <span class="math inline">\(\mathcal{T}_u\)</span> for <span class="math inline">\(u \in \mathcal{U}\)</span>, the couple <span class="math inline">\((\mathcal{F}, \mathcal{T})\)</span> is an observer for the system <a href="output-feedback.html#eq:output-feedback-system">(6.1)</a> initialized in <span class="math inline">\(\mathcal{X}_0\)</span>.</p>
</div>
</div>
<div class="proof">
<p><span id="unlabeled-div-21" class="proof"><em>Proof</em>. </span>See Theorem 1.1 in <span class="citation">(<a href="#ref-bernard19book-observer">Bernard 2019</a>)</span>.</p>
</div>
<p>A simpler version of Theorem <a href="output-feedback.html#thm:observerdesignmeta">6.1</a> where the coordinate transformation <span class="math inline">\(T_u\)</span> is stationary and fixed for all <span class="math inline">\(u\)</span> is stated below as a corollary.</p>
<div class="theorembox">
<div class="corollary">
<p><span id="cor:observerdesignmetafixedT" class="corollary"><strong>Corollary 6.7  (Meta Observer with Fixed Transformation) </strong></span>Let <span class="math inline">\(F: \mathbb{R}^p \times \mathbb{R}^m \times \mathbb{R}^d \rightarrow \mathbb{R}^p\)</span>, <span class="math inline">\(H: \mathbb{R}^p \times \mathbb{R}^m \rightarrow \mathbb{R}^d\)</span> and <span class="math inline">\(\mathcal{F}: \mathbb{R}^p \times \mathbb{R}^m \times \mathbb{R}^d \rightarrow \mathbb{R}^p\)</span> be continuous functions such that <a href="output-feedback.html#eq:meta-observer-zeta-hat">(6.56)</a> is an observer for <a href="output-feedback.html#eq:meta-observer-zeta">(6.57)</a>.</p>
<p>Suppose there exists a continuous coordinate transformation <span class="math inline">\(T: \mathbb{R}^p \rightarrow \mathbb{R}^n\)</span> and a compact subset <span class="math inline">\(\Omega\)</span> of <span class="math inline">\(\mathbb{R}^n\)</span> such that</p>
<ol style="list-style-type: decimal">
<li><p>For any <span class="math inline">\(x_0 \in \mathcal{X}_0\)</span> such that <span class="math inline">\(\sigma^+_{\mathbb{X}}(x_0;u) = + \infty\)</span>, <span class="math inline">\(X(x_0;\cdot;u)\)</span> remains in <span class="math inline">\(\Omega\)</span></p></li>
<li><p><span class="math inline">\(x \mapsto T(x)\)</span> is injective on <span class="math inline">\(\Omega\)</span></p></li>
<li><p><span class="math inline">\(T\)</span> transforms the system <a href="output-feedback.html#eq:output-feedback-system">(6.1)</a> into system <a href="output-feedback.html#eq:meta-observer-zeta">(6.57)</a>
<span class="math display">\[
L_f T(x) = F(T(x),u,h(x,u)), \quad h(x,u) = H(T(x),u),
\]</span>
where <span class="math inline">\(L_f T(x)\)</span> is the Lie derivative of <span class="math inline">\(T(x)\)</span> along <span class="math inline">\(f\)</span>
<span class="math display">\[
L_f T(x) = \lim_{\tau \rightarrow 0} \frac{ T(X(x,t;t+\tau;u))  - T(x)}{\tau}.
\]</span></p></li>
</ol>
<p>Then, there exists a uniformly continuous function <span class="math inline">\(\mathcal{T}:\mathbb{R}^p \rightarrow \mathbb{R}^{n}\)</span> such that
<span class="math display">\[
\mathcal{T}(T(x)) = x, \quad \forall x \in \Omega,
\]</span>
and <span class="math inline">\((\mathcal{F},\mathcal{T})\)</span> is an observer for system <a href="output-feedback.html#eq:output-feedback-system">(6.1)</a> initialized in <span class="math inline">\(\mathcal{X}_0\)</span>.</p>
</div>
</div>
<p>Theorem <a href="output-feedback.html#thm:observerdesignmeta">6.1</a> and Corollary <a href="output-feedback.html#cor:observerdesignmetafixedT">6.7</a> suggest the following general observer design strategy:</p>
<ol style="list-style-type: decimal">
<li><p>Find an injective coordinate transformation <span class="math inline">\(T_u\)</span> (that may be time-varying and also dependent on <span class="math inline">\(u\)</span>) that transforms the original system <a href="output-feedback.html#eq:output-feedback-system">(6.1)</a> with coordinate <span class="math inline">\(x\)</span> into a new system <a href="output-feedback.html#eq:meta-observer-zeta">(6.57)</a> with coordinate <span class="math inline">\(\xi\)</span></p></li>
<li><p>Design an observer <a href="output-feedback.html#eq:meta-observer-zeta-hat">(6.56)</a>, <span class="math inline">\(\hat{\xi}\)</span>, for the new system</p></li>
<li><p>Compute a left inverse, <span class="math inline">\(\mathcal{T}_u\)</span>, of the transformation <span class="math inline">\(T_u\)</span> to recover a state estimation <span class="math inline">\(\hat{x}\)</span> of the original system.</p></li>
</ol>
<p>The transformed systems <a href="output-feedback.html#eq:meta-observer-zeta">(6.57)</a> are typically referred to as <em>normal forms</em>, or in my opinion, <em>templates</em>.</p>
<p>Of course, the general design strategy is rather conceptual, and in order for it to be practical, we have to answer three questions.</p>
<ul>
<li><p>What templates do we have, what are their associated observers, and what are the conditions for the observers to be asymptotically converging?</p></li>
<li><p>What kinds of (nonlinear) systems can be transformed into the templates, and how to perform the transformation?</p></li>
<li><p>How to invert the coordinate transformation? Is it analytical or does it require numerical approximation?</p></li>
</ul>
<p>In the following sections, we will study several representative normal forms and answer the above questions. Before presenting the results, let us first introduce several notions of observability.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:observability" class="definition"><strong>Definition 6.2  (Observability) </strong></span>Consider an open subset <span class="math inline">\(\mathcal{L}\)</span> of the state space <span class="math inline">\(\mathbb{X} \subseteq \mathbb{R}^n\)</span> of system <a href="output-feedback.html#eq:output-feedback-system">(6.1)</a>. The system <a href="output-feedback.html#eq:output-feedback-system">(6.1)</a> is said to be</p>
<ul>
<li><p><strong>Distinguishable</strong> on <span class="math inline">\(\mathcal{L}\)</span> for some input <span class="math inline">\(u(t)\)</span>, if for all <span class="math inline">\((x_a,x_b) \in \mathcal{L} \times \mathcal{L}\)</span>,
<span class="math display">\[
y_{x_a,u}(t) = y_{x_b,u}(t), \forall t \in [0,\min\left\{\sigma^+_{\mathbb{X}}(x_a;u), \sigma^+_{\mathbb{X}}(x_b;u) \right\}] \Longrightarrow x_a = x_b
\]</span></p></li>
<li><p><strong>Instantaneously distinguishable</strong> on <span class="math inline">\(\mathcal{L}\)</span> for some input <span class="math inline">\(u(t)\)</span>, if for all <span class="math inline">\((x_a,x_b) \in \mathcal{L} \times \mathcal{L}\)</span>, and for all <span class="math inline">\(\bar{t} \in (0, \min\left\{\sigma^+_{\mathbb{X}}(x_a;u), \sigma^+_{\mathbb{X}}(x_b;u) \right\})\)</span>,
<span class="math display">\[
y_{x_a,u}(t) = y_{x_b,u}(t), \forall t \in [0,\bar{t}) \Longrightarrow x_a = x_b
\]</span></p></li>
<li><p><strong>Uniformly observable</strong> on <span class="math inline">\(\mathcal{L}\)</span> if it is distinguishable on <span class="math inline">\(\mathcal{L}\)</span> for any input <span class="math inline">\(u(t)\)</span> (not only for <span class="math inline">\(u \in \mathcal{U}\)</span>)</p></li>
<li><p><strong>Uniformly instantaneously observable</strong> on <span class="math inline">\(\mathcal{L}\)</span> if it is instantaneously observable on <span class="math inline">\(\mathcal{L}\)</span> for any input <span class="math inline">\(u(t)\)</span> (not only for <span class="math inline">\(u \in \mathcal{U}\)</span>).</p></li>
</ul>
<p>Moreover, let <span class="math inline">\(\mathcal{X}\)</span> be a subset of <span class="math inline">\(\mathbb{X}\)</span> such that <span class="math inline">\(\mathrm{cl}(\mathcal{X})\)</span>, i.e., the closure of <span class="math inline">\(\mathcal{X}\)</span>, is contained in <span class="math inline">\(\mathcal{L}\)</span>. Then the system <a href="output-feedback.html#eq:output-feedback-system">(6.1)</a> is said to be</p>
<ul>
<li><strong>Backward <span class="math inline">\(\mathcal{L}\)</span>-distinguishable on <span class="math inline">\(\mathcal{X}\)</span></strong> for some input <span class="math inline">\(u(t)\)</span>, if for any <span class="math inline">\((x_a,x_b) \in \mathcal{X} \times \mathcal{X}\)</span> such that <span class="math inline">\(x_a \neq x_b\)</span>, there exists <span class="math inline">\(t \in (\max\left\{ \sigma^{-}_{\mathcal{L}}(x_a;u), \sigma^{-}_{\mathcal{L}}(x_b;u) \right\},0]\)</span> such that <span class="math inline">\(y_{x_a,u}(t) \neq y_{x_b,u}(t)\)</span>, or in words similar to the definition of distinguishable on <span class="math inline">\(\mathcal{L}\)</span>, for all <span class="math inline">\((x_a,x_b) \in \mathcal{X} \times \mathcal{X}\)</span>
<span class="math display">\[
y_{x_a,u}(t) = y_{x_b,u}(t), \forall t \in (\max\left\{\sigma^{-}_{\mathcal{L}}(x_a;u), \sigma^{-}_{\mathcal{L}}(x_b;u) \right\},0] \Longrightarrow x_a = x_b.
\]</span></li>
</ul>
</div>
</div>
</div>
<div id="luenberger-template" class="section level3 hasAnchor" number="6.5.2">
<h3><span class="header-section-number">6.5.2</span> Luenberger Template<a href="output-feedback.html#luenberger-template" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider an instance of the normal form <a href="output-feedback.html#eq:meta-observer-zeta">(6.57)</a> as follows:
<span class="math display" id="eq:Luenberger-linear-template">\[\begin{equation}
\dot{\xi} = A \xi + B(u,y), \quad y = C \xi,
\tag{6.60}
\end{equation}\]</span>
where <span class="math inline">\(A,C\)</span> are constant matrices, and <span class="math inline">\(B(u,y)\)</span> can depend nonlinearly on <span class="math inline">\(u\)</span> and <span class="math inline">\(y\)</span>.</p>
<p>For this template, we have the well-known Luenberger observer.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:LuenbergerLinear" class="theorem"><strong>Theorem 6.2  (Luenberger Observer) </strong></span>If the pair <span class="math inline">\((A,C)\)</span> is detectable (see Theorem <a href="app-lti-system-theory.html#thm:ltidetectable">C.9</a>), then there exists a matrix <span class="math inline">\(K\)</span> such that <span class="math inline">\(A-KC\)</span> is Hurwitz and the system
<span class="math display" id="eq:Luenberger-Linear">\[\begin{equation}
\dot{\hat{\xi}} = A \hat{\xi} + B(u,y) + K(y - C \hat{\xi})
\tag{6.61}
\end{equation}\]</span>
is an observer for <a href="output-feedback.html#eq:Luenberger-linear-template">(6.60)</a>.</p>
</div>
</div>
<div class="proofbox">
<div class="proof">
<p><span id="unlabeled-div-22" class="proof"><em>Proof</em>. </span>Define <span class="math inline">\(e(t) = \xi(t)  - \hat{\xi}(t)\)</span>. In that case,
<span class="math display" id="eq:Luenberger-error">\[\begin{equation}
    \dot{e}(t) = [A - KC] e(t)
    \tag{6.62}
\end{equation}\]</span></p>
<p>Solving <a href="output-feedback.html#eq:Luenberger-error">(6.62)</a>, we obtain</p>
<p><span class="math display">\[\begin{equation}
    e(t) = \mathrm{exp}[(A - KC)t] e(0)
\end{equation}\]</span></p>
<p>Then, if the real components of the eigenvalues of <span class="math inline">\(A - KC\)</span> are strictly negative (i.e., <span class="math inline">\(A - KC\)</span> is Hurwitz), then <span class="math inline">\(e(t) \rightarrow 0\)</span> as <span class="math inline">\(t \rightarrow \infty\)</span>, independent of the initial error <span class="math inline">\(e(0) = \xi(0) - \hat{\xi}(0)\)</span>. From Theorem <a href="app-lti-system-theory.html#thm:ltidetectable">C.9</a>, we know that <span class="math inline">\((A,C)\)</span> being detectable implies the existence of <span class="math inline">\(K\)</span> such that <span class="math inline">\(A - KC\)</span> is Hurwitz.</p>
<p>If one is further interested in estimating the convergence rate of the Luenberger observer, then one can use the result from Corollary <a href="app-lti-system-theory.html#cor:bestconvergencerate">C.1</a>. Particularly, one can solve the Lyapunov equation
<span class="math display">\[
(A - KC)^T P + P (A - KC) = - I
\]</span>
to obtain <span class="math inline">\(P\)</span>. Then the convergence rate of <span class="math inline">\(\Vert e \Vert\)</span> towards zero is <span class="math inline">\(\frac{0.5}{\lambda_{\max}(P)}\)</span>.</p>
</div>
</div>
<p>The Luenberger observer is an elegant result in observer design (and even in control theory) that has far-reaching impact. In my opinion, the essence of observer design is twofold: (i) to simulate the dynamics when the state estimation is correct, and (ii) to correct the state estimation from observation when it is off. These two pieces of ideas are evident in <a href="output-feedback.html#eq:Luenberger-Linear">(6.61)</a>: the observer is a copy of the original dynamics (<span class="math inline">\(A \hat{\xi} + B(u,y)\)</span>) plus a feedback correction from the difference between the imagined observation <span class="math inline">\(C\hat{\xi}\)</span> and the true observation <span class="math inline">\(y\)</span>.</p>
<p>You may think the Luenberger template is restricting because it requires the system to be linear (up to the only nonlinearly in <span class="math inline">\(B(u,y)\)</span>). However, it turns out the Luenberger template is already quite useful, as I will show in the following pendulum example.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:pendulumLuenberger" class="example"><strong>Example 6.3  (Luenberger Observer for A Simple Pendulum) </strong></span>Consider a simple pendulum dynamics model
<span class="math display" id="eq:kbobserver-pendulum">\[\begin{equation}
x = \begin{bmatrix}
\theta \\ \dot{\theta}
\end{bmatrix}, \quad
\dot{x} = \begin{bmatrix}
\dot{\theta} \\
- \frac{1}{ml^2} (b \dot{\theta} + mgl \sin \theta)
\end{bmatrix} +
\begin{bmatrix}
0 \\
\frac{1}{ml^2}
\end{bmatrix} u, \quad y = \theta,
\tag{6.63}
\end{equation}\]</span>
where <span class="math inline">\(\theta\)</span> the angular position of the pendulum from the vertical line, <span class="math inline">\(m &gt; 0\)</span> the mass of the pendulum, <span class="math inline">\(l &gt; 0\)</span> the length, <span class="math inline">\(g\)</span> the gravitational constant, <span class="math inline">\(b &gt; 0\)</span> the dampling coefficient, and <span class="math inline">\(u\)</span> the control input (torque).</p>
<p>We assume we can only observe the angular position of the pendulum in <a href="output-feedback.html#eq:kbobserver-pendulum">(6.63)</a>, e.g., using a camera, but not the angular velocity. Our goal is to construct an observer that can provide a full state estimation.</p>
<p>We first note that the pendulum dynamics <a href="output-feedback.html#eq:kbobserver-pendulum">(6.63)</a> can actually be written in the (linear) Luenberger template <a href="output-feedback.html#eq:Luenberger-linear-template">(6.60)</a> as<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a>
<span class="math display" id="eq:pendulum-Luenberger-Linear">\[\begin{equation}
\begin{split}
\dot{x} &amp; = \underbrace{\begin{bmatrix}
0 &amp; 1 \\
0 &amp; - \frac{b}{ml^2}
\end{bmatrix}}_{=:A} x +
\underbrace{\begin{bmatrix}
0 \\
\frac{u - mgl \sin \theta }{ml^2}
\end{bmatrix}}_{=:B(u,y)} \\
y &amp; = \underbrace{\begin{bmatrix}
1 &amp; 0
\end{bmatrix}}_{=:C} x
\end{split}.
\tag{6.64}
\end{equation}\]</span></p>
<p>In order for us to use the Luenberger observer, we need to check if the pair <span class="math inline">\((A,C)\)</span> is detectable. We can easily find the eigenvalues and eigenvectors of <span class="math inline">\(A\)</span>:
<span class="math display">\[
A \begin{bmatrix}
1 \\ 0
\end{bmatrix} = 0,\quad
A \begin{bmatrix}
- \frac{ml^2}{b} \\ 1
\end{bmatrix} = \begin{bmatrix}
1 \\ - \frac{b}{ml^2}
\end{bmatrix}
= - \frac{b}{ml^2} \begin{bmatrix}
- \frac{ml^2}{b} \\ 1 \end{bmatrix}.
\]</span>
The first eigenvalue has real part equal to <span class="math inline">\(0\)</span>. However,
<span class="math display">\[
C \begin{bmatrix}
1 \\ 0
\end{bmatrix} = 1 \neq 0.
\]</span>
According to Theorem <a href="app-lti-system-theory.html#thm:ltidetectable">C.9</a>, we conclude <span class="math inline">\((A,C)\)</span> is detectable. In fact, the pair <span class="math inline">\((A,C)\)</span> is more than just detectable, it is indeed observable (according to Theorem <a href="app-lti-system-theory.html#thm:ltiobservable">C.7</a>). Therefore, the poles of <span class="math inline">\(A - KC\)</span> can be arbitrarily placed.</p>
<p><strong>Finding <span class="math inline">\(K\)</span></strong>. Now we need to find <span class="math inline">\(K\)</span>. An easy choice of <span class="math inline">\(K\)</span> is
<span class="math display">\[
K = \begin{bmatrix} k \\ 0 \end{bmatrix}, \quad A - KC =
\begin{bmatrix}
- k &amp; 1 \\ 0 &amp; - \frac{b}{ml^2}
\end{bmatrix}.
\]</span>
With <span class="math inline">\(k &gt; 0\)</span>, we know <span class="math inline">\(A- KC\)</span> is guaranteed to be Hurwitz (the two eigenvalues of <span class="math inline">\(A-KC\)</span> are <span class="math inline">\(-k\)</span> and <span class="math inline">\(-b/ml^2\)</span>), and we have obtained an observer!</p>
<p>We can also estimate the convergence rate of this observer. Let us use <span class="math inline">\(m=1,g=9.8,l=1,b=0.1\)</span> as parameters of the pendulm dynamics. According to Theorem <a href="output-feedback.html#thm:LuenbergerLinear">6.2</a>, we solve the Lyapunov equation
<span class="math display">\[
(A - KC)^T P + P(A - KC) = -I
\]</span>
and <span class="math inline">\(\gamma = \frac{0.5}{\lambda_{\max}(P)}\)</span> will be our best estimate of the convergence rate (of <span class="math inline">\(\Vert e \Vert = \Vert \hat{x} - x \Vert\)</span> towards zero).</p>
<p>Table <a href="output-feedback.html#tab:pendulumLuenbergerRate">6.1</a> below shows the convergence rates computed for different values of <span class="math inline">\(k\)</span>. We can see that as <span class="math inline">\(k\)</span> is increased, the convergence rate estimation is also increased. However, it appears that <span class="math inline">\(0.1\)</span> is the best convergence rate we can achieve, regardless of how large <span class="math inline">\(k\)</span> is.</p>
<table>
<caption><span id="tab:pendulumLuenbergerRate">Table 6.1: </span> Convergence rate estimation of the Luenberger observer for a simple pendulm.</caption>
<colgroup>
<col width="15%" />
<col width="13%" />
<col width="15%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(k\)</span></th>
<th align="center"><span class="math inline">\(0.1\)</span></th>
<th align="center"><span class="math inline">\(1\)</span></th>
<th align="center"><span class="math inline">\(10\)</span></th>
<th align="center"><span class="math inline">\(100\)</span></th>
<th align="center"><span class="math inline">\(1000\)</span></th>
<th align="center"><span class="math inline">\(10000\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\gamma\)</span></td>
<td align="center"><span class="math inline">\(0.0019\)</span></td>
<td align="center"><span class="math inline">\(0.0523\)</span></td>
<td align="center"><span class="math inline">\(0.0990\)</span></td>
<td align="center"><span class="math inline">\(0.1000\)</span></td>
<td align="center"><span class="math inline">\(0.1000\)</span></td>
<td align="center"><span class="math inline">\(0.1000\)</span></td>
</tr>
</tbody>
</table>
<p><strong>Optimal <span class="math inline">\(K\)</span></strong>. Is it true that <span class="math inline">\(0.1\)</span> is the best convergence rate, or in other words, what is the best <span class="math inline">\(K\)</span> that maximizes the convergence rate <span class="math inline">\(\gamma\)</span>?</p>
<p>A natural way (and my favorite way) to answer this question is to formulate an optimization problem.
<span class="math display" id="eq:pendulumLuenbergerMaxgammaNonCVX">\[\begin{equation}
\begin{split}
\min_{P,K} &amp; \quad \lambda_{\max}(P) \\
\text{subject to} &amp; \quad (A - KC)^T P + P (A - KC) = -I \\
&amp; \quad P \succeq 0
\end{split}
\tag{6.65}
\end{equation}\]</span>
The above formulation seeks the best possible <span class="math inline">\(K\)</span> that minimizes <span class="math inline">\(\lambda_{\max}(P)\)</span> which, according to <span class="math inline">\(\gamma = 0.5 / \lambda_{\max}(P)\)</span>, also maximizes <span class="math inline">\(\gamma\)</span>.</p>
<p>However, problem <a href="output-feedback.html#eq:pendulumLuenbergerMaxgammaNonCVX">(6.65)</a> is not a convex formulation due to the bilinear term <span class="math inline">\(PK\)</span>. Nevertheless, via a simple change of variable <span class="math inline">\(H = PK\)</span>, we arrive at the following convex formulation
<span class="math display" id="eq:pendulumLuenbergerMaxgammaCVX">\[\begin{equation}
\begin{split}
\min_{P,H} &amp; \quad \lambda_{\max}(P) \\
\text{subject to} &amp; \quad A^T P - C^T H^T + PA - H C = - I \\
&amp; \quad P \succeq 0
\end{split}
\tag{6.66}
\end{equation}\]</span>
Problem <a href="output-feedback.html#eq:pendulumLuenbergerMaxgammaCVX">(6.66)</a> is a semidefinite programming problem (SDP), that can be modeled and solved by off-the-shelf tools. We can recover <span class="math inline">\(K = P^{-1} H\)</span> from <a href="output-feedback.html#eq:pendulumLuenbergerMaxgammaCVX">(6.66)</a> after it is solved.</p>
<p>Interestingly, solving problem <a href="output-feedback.html#eq:pendulumLuenbergerMaxgammaCVX">(6.66)</a> verifies that the minimum <span class="math inline">\(\lambda_{\max}(P)\)</span> is <span class="math inline">\(5\)</span> and the maximum converge rate is <span class="math inline">\(0.1\)</span>. An optimal solution of <a href="output-feedback.html#eq:pendulumLuenbergerMaxgammaCVX">(6.66)</a> is
<span class="math display">\[
P^\star = \begin{bmatrix}
2.4923 &amp; 0 \\ 0 &amp; 5 \end{bmatrix}, \quad
K^\star = \begin{bmatrix}
0.2006 \\ 0.4985 \end{bmatrix}.
\]</span>
You should check out the Matlab code of this example <a href="https://github.com/ComputationalRobotics/OptimalControlEstimation-Examples/blob/main/pendulum_luenberger.m">here</a>.</p>
</div>
</div>
</div>
<div id="state-affine-template" class="section level3 hasAnchor" number="6.5.3">
<h3><span class="header-section-number">6.5.3</span> State-affine Template<a href="output-feedback.html#state-affine-template" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider an instance of the normal form <a href="output-feedback.html#eq:meta-observer-zeta">(6.57)</a> where the dynamics is linear in <span class="math inline">\(\xi\)</span>, but the coefficients are time-varying and dependent on the input and output
<span class="math display" id="eq:state-affine-template">\[\begin{equation}
\dot{\xi} = A(u,y) \xi + B(u,y), \quad y = C(u) \xi.
\tag{6.67}
\end{equation}\]</span>
The difference between the state-affine template <a href="output-feedback.html#eq:state-affine-template">(6.67)</a> and the Luenberger template <a href="output-feedback.html#eq:Luenberger-linear-template">(6.60)</a> is that the linear matrices <span class="math inline">\(A,C\)</span> are allowed to depend nonlinearly on the input <span class="math inline">\((u,y)\)</span>.</p>
<p>Kalman and Bucy originally proposed an observer for linear time-varying systems <span class="citation">(<a href="#ref-kalman61-new">Rudolph E. Kalman and Bucy 1961</a>)</span>. The result is later extened by <span class="citation">(<a href="#ref-besanccon96ejc-observer">Besanon, Bornard, and Hammouri 1996</a>)</span> and <span class="citation">(<a href="#ref-hammouri90cdc-observer">Hammouri and Leon Morales 1990</a>)</span> to deal with coefficient matrices dependent on the control. The following theorem is a direct extension of the result from <span class="citation">(<a href="#ref-besanccon96ejc-observer">Besanon, Bornard, and Hammouri 1996</a>)</span> and <span class="citation">(<a href="#ref-hammouri90cdc-observer">Hammouri and Leon Morales 1990</a>)</span> by considering <span class="math inline">\((u,y)\)</span> as an augmented control input.</p>
<p>Before presenting the theorem, we need to introduce the following terminology.</p>
<div class="definitionbox">
<div class="definition">
<p><span id="def:lineartimevarying" class="definition"><strong>Definition 6.3  (Linear Time-Varying System) </strong></span>For a linear time-varying system of the form
<span class="math display" id="eq:linear-time-varying">\[\begin{equation}
\dot{\chi} = A(\nu) \chi, \quad y = C(\nu) \chi,
\tag{6.68}
\end{equation}\]</span>
with input <span class="math inline">\(\nu\)</span> and output <span class="math inline">\(y\)</span>, we define</p>
<ul>
<li><p>the <em>transition matrix</em> <span class="math inline">\(\Psi_\nu\)</span> as the unique solution to
<span class="math display">\[
\Psi_\nu (t,t) = I, \quad \frac{\partial \Psi_\nu}{\partial \tau}(\tau,t) = A(\nu(\tau)) \Psi_\nu (\tau, t).
\]</span>
Note that the transition matrix is used to express the solution to <a href="output-feedback.html#eq:linear-time-varying">(6.68)</a> because it satisfies
<span class="math display">\[
\chi(\chi_0,t_0;t;\nu) = \Psi_\nu (t,t_0) \chi_0.
\]</span></p></li>
<li><p>the <em>observability grammian</em> as
<span class="math display">\[
\Gamma_\nu (t_0,t_1) = \int_{t_0}^{t_1} \Psi_\nu (\tau,t_0)^T C(\nu(\tau))^T C(\nu(\tau)) \Psi_\nu (\tau,t_0) d\tau.
\]</span></p></li>
<li><p>the <em>backward observability grammian</em> as
<span class="math display">\[
\Gamma_\nu^b (t_0,t_1) = \int_{t_0}^{t_1} \Psi_\nu (\tau,t_1)^T C(\nu(\tau))^T C(\nu(\tau)) \Psi_\nu (\tau,t_1) d\tau.
\]</span></p></li>
</ul>
</div>
</div>
<p>We now introduce the Kalman-Bucy Observer for the state-affine template <a href="output-feedback.html#eq:state-affine-template">(6.67)</a>.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:kalmanbucystateaffine" class="theorem"><strong>Theorem 6.3  (Kalman-Bucy Observer) </strong></span>Let <span class="math inline">\(y_{\xi_0,u}(t) = C(u(t)) \Xi (\xi_0;t;u)\)</span> be the output of system <a href="output-feedback.html#eq:state-affine-template">(6.67)</a> at time <span class="math inline">\(t\)</span> with initialization <span class="math inline">\(\xi_0\)</span> and control <span class="math inline">\(u\)</span>. Suppose the control <span class="math inline">\(u\)</span> satisfies</p>
<ul>
<li><p>For any <span class="math inline">\(\xi_0\)</span>, <span class="math inline">\(t \mapsto A(u(t),y_{\xi_0,u}(t))\)</span> is bounded by <span class="math inline">\(A_{\max}\)</span></p></li>
<li><p>For any <span class="math inline">\(\xi_0\)</span>, the augmented input <span class="math inline">\(\nu = (u,y_{\xi_0,u})\)</span> is <em>regularly persistent</em> for the dynamics
<span class="math display" id="eq:kbobserver-auxilarydynamics">\[\begin{equation}
\dot{\chi} = A(\nu) \chi , \quad y = C(\nu) \chi
\tag{6.69}
\end{equation}\]</span>
uniformly with respect to <span class="math inline">\(\xi_0\)</span>. That is, there exist strictly positive numbers <span class="math inline">\(t_0,\bar{t}\)</span>, and <span class="math inline">\(\alpha\)</span> such that for any <span class="math inline">\(\xi_0\)</span> and any time <span class="math inline">\(t \geq t_0 \geq \bar{t}\)</span>,
<span class="math display">\[
\Gamma_v^b (t-\bar{t}, t) \succeq \alpha I,
\]</span>
where <span class="math inline">\(\Gamma_v^b\)</span> is the <em>backward observability grammian</em> associated with system <a href="output-feedback.html#eq:kbobserver-auxilarydynamics">(6.69)</a>.</p></li>
</ul>
<p>Then, given any positive definite matrix <span class="math inline">\(P_0\)</span>, there exist <span class="math inline">\(\alpha_1,\alpha_2 &gt; 0\)</span> such that for any <span class="math inline">\(\lambda \geq 2 A_{\max}\)</span> and any <span class="math inline">\(\xi_0 \in \mathbb{R}^p\)</span>, the matrix differential equation
<span class="math display" id="eq:kbobserver-matrixdifferential">\[\begin{equation}
\dot{P} = -\lambda P - A(u,y)^T P - P A(u,y) + C(u)^T C(u)
\tag{6.70}
\end{equation}\]</span>
initialized at <span class="math inline">\(P(0) = P_0\)</span> admits a unique solution satisfying <span class="math inline">\(P(t)=P(t)^T\)</span> and
<span class="math display">\[
\alpha_2 I \succeq P(t) \succeq \alpha_1 I.
\]</span>
Moreover, the system
<span class="math display" id="eq:kbobserver-observer">\[\begin{equation}
\dot{\hat{\xi}} = A(u,y) \hat{\xi} + B(u,y) + K (y - C(u)\hat{\xi})
\tag{6.71}
\end{equation}\]</span>
with a time-varying gain matrix
<span class="math display" id="eq:kbobserver-gain">\[\begin{equation}
K = P^{-1} C(u)^T
\tag{6.72}
\end{equation}\]</span>
is an observer for the state-affine system <a href="output-feedback.html#eq:state-affine-template">(6.67)</a>.</p>
</div>
</div>
<p>Let us work out an example of the Kalman-Bucy Observer for nonlinear systems.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:pendulumkbobserver" class="example"><strong>Example 6.4  (Kalman-Bucy Observer for A Simple Pendulum) </strong></span>Let us reconsider the pendulum dynamics <a href="output-feedback.html#eq:kbobserver-pendulum">(6.63)</a> but this time try to design a Kalman-Bucy observer.</p>
<p>We first write the pendulum dynamics in a new coordinate system so that it is in the state-affine normal form <a href="output-feedback.html#eq:state-affine-template">(6.67)</a>. We choose <span class="math inline">\(\xi = [\mathfrak{s},\mathfrak{c},\dot{\theta}]^T\)</span> with <span class="math inline">\(\mathfrak{s} = \sin \theta\)</span> and <span class="math inline">\(\mathfrak{c} = \cos \theta\)</span>. Clearly, we will be able to observe <span class="math inline">\(y = [\mathfrak{s},\mathfrak{c}]^T\)</span> in this new coordinate. The state-affine normal form of the pendulum dynamics reads
<span class="math display" id="eq:pendulum-state-affine">\[\begin{equation}
\begin{split}
\dot{\xi} = \begin{bmatrix}
\mathfrak{c} \dot{\theta} \\
- \mathfrak{s} \dot{\theta} \\
- \frac{1}{ml^2} (b \dot{\theta} + mgl \mathfrak{s} ) +  \frac{1}{ml^2} u
\end{bmatrix} &amp; =
\underbrace{\begin{bmatrix}
0 &amp; 0 &amp; \mathfrak{c} \\
0 &amp; 0 &amp; -\mathfrak{s} \\
0 &amp; 0 &amp; -\frac{b}{ml^2}
\end{bmatrix}}_{=:A(u,y)} \xi +
\underbrace{\begin{bmatrix}
0 \\ 0 \\ \frac{u - mgl \mathfrak{s}}{ml^2}
\end{bmatrix}}_{=:B(u,y)} \\
y &amp; = \underbrace{\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0
\end{bmatrix}}_{=:C(u)} \xi
\end{split}.
\tag{6.73}
\end{equation}\]</span>
Note that <span class="math inline">\(C(u)\)</span> is in fact time-invariant, and <span class="math inline">\(B(u,y)\)</span> only depends on <span class="math inline">\(u\)</span>; but we adopt the same notation as the general state-affine template <a href="output-feedback.html#eq:state-affine-template">(6.67)</a>.</p>
<p>In order to use the Kalman-Bucy observer in Theorem <a href="output-feedback.html#thm:kalmanbucystateaffine">6.3</a>, we need to verify the boundedness of <span class="math inline">\(A(u,y)\)</span>, and the regular persistence of <a href="output-feedback.html#eq:kbobserver-auxilarydynamics">(6.69)</a>.</p>
<p><strong>Boundedness of <span class="math inline">\(A(u,y)\)</span></strong>. We can easily show the boundedness of <span class="math inline">\(A(u,y)\)</span> by writing
<span class="math display">\[
\Vert A(u,y) \xi \Vert = \Vert \xi_3 (\mathfrak{c} - \mathfrak{s} - b/ml^2) \Vert  \leq |\xi_3| \sqrt{3} \sqrt{\mathfrak{c}^2 + \mathfrak{s}^2 + b^2 / m^2 l^4} \leq \Vert \xi \Vert \sqrt{3 + 3b^2 / m^2 l^4}.
\]</span>
Therefore, we can take <span class="math inline">\(A_{\max} = \sqrt{3 + 3b^2 / m^2 l^4}\)</span>.
<!-- <span style="color:red">Does the $A_{\max}$ in Theorem \@ref(thm:kalmanbucystateaffine) refer to the bound in operator norm?</span> --></p>
<p><strong>Regular persistence</strong>. We write the backward observability grammian of system <a href="output-feedback.html#eq:kbobserver-auxilarydynamics">(6.69)</a>
<span class="math display">\[
\Gamma_\nu^b(t - \bar{t},t) = \int_{t - \bar{t}}^t \Psi_\nu(\tau,t)^T C^T C \Psi_\nu (\tau, t) d \tau = \int_{t - \bar{t}}^t \Psi_\nu(\tau,t)^T \underbrace{\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0
\end{bmatrix}}_{=:\tilde{C}}
\Psi_\nu (\tau, t) d \tau.
\]</span>
<span class="math inline">\(\Gamma_\nu^b(t - \bar{t},t) \succeq \alpha I\)</span> if and only if
<span class="math display">\[
w^T \Gamma_\nu^b(t - \bar{t},t) w \geq \alpha, \quad \forall w \in \mathbb{R}^3, \Vert w \Vert = 1.
\]</span>
With this, we develop <span class="math inline">\(w^T \Gamma_\nu^b(t - \bar{t},t) w\)</span>
<span class="math display" id="eq:pendulm-regular-persistence-1">\[\begin{equation}
\begin{split}
w^T \Gamma_\nu^b(t - \bar{t},t) w &amp;= \int_{t - \bar{t}}^t s^T \tilde{C} s d\tau, \\
&amp; = \int_{t - \bar{t}}^t \left( s_1^2 + s_2^2 \right) d\tau, \quad s = \Psi_\nu (\tau, t) w
\end{split}
\tag{6.74}
\end{equation}\]</span>
and observe that <span class="math inline">\(s = \Psi_\nu (\tau,t) w\)</span> is equivalent to
<span class="math display">\[
w = (\Psi_\nu (\tau,t))^{-1} s = \Psi_\nu (t,\tau) s,
\]</span>
that is, <span class="math inline">\(w\)</span> is the solution of <span class="math inline">\(\dot{\xi} = A(\nu) \xi\)</span> at time <span class="math inline">\(t\)</span> with initial condition <span class="math inline">\(s\)</span> at time <span class="math inline">\(\tau \leq t\)</span>. Equivalently, this is saying <span class="math inline">\(s\)</span> is the initial condition of <span class="math inline">\(\dot{\xi} = A(\nu) \xi\)</span> at time <span class="math inline">\(\tau \leq t\)</span> such that its solution at time <span class="math inline">\(t\)</span> is <span class="math inline">\(w\)</span>. Note that from <a href="output-feedback.html#eq:pendulm-regular-persistence-1">(6.74)</a> it is clearly that <span class="math inline">\(\int_{t - \bar{t}}^t \left( s_1^2 + s_2^2 \right) d\tau \geq 0\)</span>, and <span class="math inline">\(\int_{t - \bar{t}}^t \left( s_1^2 + s_2^2 \right) d\tau = 0\)</span> if and only if <span class="math inline">\(s_1^2 + s_2^2 = 0\)</span>, or equivalently <span class="math inline">\(s_1 = s_2 = 0\)</span> for any <span class="math inline">\(\tau \in [t - \bar{t}, t]\)</span>.</p>
<p>We then take a closer look at the system <span class="math inline">\(\dot{\xi} = A(\nu) \xi\)</span>:
<span class="math display" id="eq:pendulm-state-affine-auxiliarysystem">\[\begin{equation}
\begin{split}
\dot{\xi}_1 &amp;= \mathfrak{c} \xi_3 \\
\dot{\xi}_2 &amp;= -\mathfrak{s} \xi_3 \\
\dot{\xi}_3 &amp;= - \frac{b}{ml^2} \xi_3.
\end{split}
\tag{6.75}
\end{equation}\]</span></p>
<p>If the solution of <span class="math inline">\(\xi_3\)</span> at time <span class="math inline">\(t\)</span> is <span class="math inline">\(w_3\)</span>, then
<span class="math display">\[
\xi_3(\tau) = w_3 e^{\frac{b}{ml^2}(t - \tau)}, \quad \tau \leq t.
\]</span>
We can now claim it is impossible that <span class="math inline">\(s_1 = s_2 = 0\)</span> at any time <span class="math inline">\(\tau \in [t - \bar{t}, t]\)</span>.</p>
<p>We can show this by contradiction. First of all, <span class="math inline">\(s_1 = s_2 = 0\)</span> at <span class="math inline">\(\tau = t\)</span> implies <span class="math inline">\(w_1 = w_2 = 0\)</span> and hence <span class="math inline">\(w_3 = \pm 1\)</span>. This implies <span class="math inline">\(\xi_3 \neq 0\)</span> for any <span class="math inline">\(\tau \in [t - \bar{t}, t]\)</span>. Then, <span class="math inline">\(s_1 = 0, \forall \tau \in [t - \bar{t}, t]\)</span> implies <span class="math inline">\(\dot{\xi}_1 = 0\)</span> which, due to <span class="math inline">\(\xi_3 \neq 0\)</span>, implies <span class="math inline">\(\mathfrak{c} = 0\)</span> for all <span class="math inline">\(\tau\)</span>. Similarly, <span class="math inline">\(s_2 = 0, \forall \tau \in [t - \bar{t}, t]\)</span> implies <span class="math inline">\(\dot{\xi}_2 = 0\)</span> and <span class="math inline">\(\mathfrak{s} = 0\)</span>. This creates a contradiction because <span class="math inline">\(\mathfrak{c}^2 + \mathfrak{s}^2 = 1\)</span> and <span class="math inline">\(\mathfrak{c}, \mathfrak{s}\)</span> cannot be simultaneously zero.</p>
<p>The above reasoning proves that the backward observability Grammian is positive definite, which is, however, still insufficient for the Kalman-Bucy observer. We need a stronger uniformly positive definite condition on <span class="math inline">\(\Gamma_\nu^b\)</span>, i.e., to find <span class="math inline">\(t_0, \bar{t}\)</span> and <span class="math inline">\(\alpha&gt;0\)</span> so that <span class="math inline">\(\Gamma_\nu^b(t-\bar{t},t) \succeq \alpha I\)</span> for all <span class="math inline">\(t \geq t_0\)</span>.</p>
<p>If the control <span class="math inline">\(u\)</span> is unbounded, then sadly, one can show that the uniform positive definite condition fails to hold, as left by you to show in the following exercise.</p>
<div class="exercise">
<p><span id="exr:kbobserverpendulumcounterexample" class="exercise"><strong>Exercise 6.1  (Counterexample for Kalman-Bucy Observer) </strong></span>Show that, if the control <span class="math inline">\(u\)</span> is unbounded, then for any <span class="math inline">\(\alpha &gt; 0\)</span>, <span class="math inline">\(t_0 \geq \bar{t} &gt; 0\)</span>, there exists <span class="math inline">\(t \geq t_0\)</span> such that <span class="math inline">\(\Gamma_\nu^b(t - \bar{t},t) \prec \alpha I\)</span>. (Hint: consider a controller that spins the pendulum faster and faster such that in time <span class="math inline">\(\bar{t}\)</span> it has rotated <span class="math inline">\(2k\pi\)</span>, in this case the angular velocity becomes unobservable because we are not sure how many rounds the pendulum has rotated.)</p>
</div>
<p>Fortunately, if the control <span class="math inline">\(u\)</span> is bounded, then we can prove the uniform positive define condition holds for <span class="math inline">\(\Gamma_\nu^b(t - \bar{t},t)\)</span>. The following proof is given by <a href="https://scholar.harvard.edu/weiyuli/home">Weiyu Li</a>.</p>
<p>Without loss of generality, let <span class="math inline">\(\frac{b}{ml^2} = 1\)</span>. Assume <span class="math inline">\(u\)</span> is bounded such that the third entry of <span class="math inline">\(B(u,y)\)</span> in <a href="output-feedback.html#eq:pendulum-state-affine">(6.73)</a> is bounded by <span class="math inline">\(\beta &gt; 0\)</span>
<span class="math display">\[
\left| \frac{u - mgl \mathfrak{s}}{ml^2} \right| \leq \beta.
\]</span>
Assuming the initial velocity of the pendulum is <span class="math inline">\(\dot{\theta}(0) = \dot{\theta}_0\)</span>, we know <span class="math inline">\(\dot{\theta}(t)\)</span> is bounded by
<span class="math display">\[
\dot{\theta}(t) \in \left[ c_1(1-\beta)e^{-t} - \beta  , c_2(1-\beta)e^{-t} + \beta \right],
\]</span>
where <span class="math inline">\(c_1,c_2\)</span> are constants chosen to satisfy the initial condition. Clearly, for all <span class="math inline">\(t &gt; 0\)</span>, we see <span class="math inline">\(\dot{\theta}(t)\)</span> is bounded, and hence we know <span class="math inline">\(\dot{\mathfrak{c}}\)</span> and <span class="math inline">\(\dot{\mathfrak{s}}\)</span> are bounded (due to <span class="math inline">\(\mathfrak{c}\)</span> and <span class="math inline">\(\mathfrak{s}\)</span> are bounded). Intuitively, what we have just shown says that when the control is bounded, the measurements <span class="math inline">\(\mathfrak{c}\)</span> and <span class="math inline">\(\mathfrak{s}\)</span> will have bounded time derivatives. (This will help us analyze the auxiliary system <a href="output-feedback.html#eq:pendulm-state-affine-auxiliarysystem">(6.75)</a>.)</p>
<p>Now back to checking regular persistence of the auxilary system <a href="output-feedback.html#eq:pendulm-state-affine-auxiliarysystem">(6.75)</a>. We will discuss two cases: (1) <span class="math inline">\(w_3^2 &gt; 1 - \delta\)</span>, and (2) <span class="math inline">\(w_3^2 \leq 1 - \delta\)</span>, for some constant <span class="math inline">\(\delta &lt; 0.5\)</span> determined later.</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(w_3^2 &gt; 1 - \delta &gt; 0.5\)</span>. In this case we have <span class="math inline">\(w_1^2 + w_2^2 = 1 - w_3^2 &lt; \delta\)</span>, and hence <span class="math inline">\(w_1^2 &lt; \delta\)</span>, <span class="math inline">\(w_2^2 &lt; \delta\)</span>. On the other hand, from <a href="output-feedback.html#eq:pendulm-state-affine-auxiliarysystem">(6.75)</a> we have
<span class="math display">\[
\dot{\xi}_1^2(\tau) + \dot{\xi}_2^2(\tau) = \xi_3^2 = w_3^2 e^{2 (t - \tau)} &gt; w_3^2 &gt; 1 - \delta, \quad \forall \tau &lt; t.
\]</span>
Without loss of generality assume <span class="math inline">\(\dot{\xi}_1(t)^2 &gt; (1-\delta)/2\)</span>. As <span class="math inline">\(\dot{\xi}_1 = \mathfrak{c} \xi_3\)</span> and both <span class="math inline">\(\mathfrak{c}\)</span> and <span class="math inline">\(\xi_3\)</span> have bounded derivatives, we know <span class="math inline">\(\dot{\xi}_1\)</span> will not change sign for some duration <span class="math inline">\(T\)</span> that is independent from the choice of <span class="math inline">\(\delta\)</span> (because the time derivatives of <span class="math inline">\(\mathfrak{c}\)</span> and <span class="math inline">\(\xi_3\)</span> do not depend on <span class="math inline">\(\delta\)</span>). That is <span class="math inline">\(|\dot{\xi}_1| &gt; \sqrt{(1-\delta)/2} &gt; 1/2\)</span> for <span class="math inline">\(\tau \in [t - T,t]\)</span>. Consequently,
<span class="math display">\[
|\xi_1(t - \tau)| &gt; \frac{1}{2} \tau - |w_1| &gt; \frac{1}{2} \tau - \sqrt{\delta}, \quad \tau \in [0,T].
\]</span>
Choosing <span class="math inline">\(\delta\)</span> small enough, we have <span class="math inline">\(|\xi_1(t - \tau)| &gt; 0.25 \tau\)</span> for <span class="math inline">\(\tau \in [0.5T,T]\)</span>. Then we have
<span class="math display">\[
\Gamma_\nu^b(t - T, t) \succ [(0.25 \times 0.5 T)^2 \times 0.5T]I.
\]</span></p></li>
<li><p><span class="math inline">\(w_3^2 \leq 1-\delta\)</span>. In this case <span class="math inline">\(w_1^2 + w_2^2 = 1 - w_3^2 \geq \delta\)</span>, and at least one of <span class="math inline">\(w_1\)</span> and <span class="math inline">\(w_2\)</span> has absolute value larger than <span class="math inline">\(\sqrt{\delta/2}\)</span>. Because the derivatives of <span class="math inline">\(\xi_1\)</span> and <span class="math inline">\(\xi_2\)</span> are both bounded, we know <span class="math inline">\(\xi_1\)</span> and <span class="math inline">\(\xi_2\)</span> will remain large for some constant time. Thus there is a uniform lower bound.</p></li>
</ol>
<p>The intuition of the above proof is simple: when <span class="math inline">\(\xi_1\)</span> and/or <span class="math inline">\(\xi_2\)</span> already have large absolute value (case 2), we can find a time window such that <span class="math inline">\(\xi_1\)</span> and/or <span class="math inline">\(\xi_2\)</span> remain large in that time window; when <span class="math inline">\(\xi_1\)</span> and/or <span class="math inline">\(\xi_2\)</span> are small (case 1), using the observation that their time derivatives are large (because <span class="math inline">\(w_3\)</span> is large), together with the fact that these derivatives remain large (because the derivative of these derivatives are bounded), we can also find a time window that <span class="math inline">\(\xi_1\)</span> and/or <span class="math inline">\(\xi_2\)</span> are large (back in time). Therefore, the backward observability Grammian is uniformly positive definite.</p>
<!-- Therefore, there must exist $\alpha > 0$ such that $\Gamma_\nu^b (t - \bar{t},t) \succeq \alpha I$. -->
<!-- On the other hand,
$$
\frac{d}{d\tau}\left( \xi_1^2 + \xi_2^2 \right) = 2 \xi_1 \dot{\xi}_1 + 2 \xi_2 \dot{\xi}_2 = 2 \xi_3 \left(\mathfrak{c} \xi_1 - 2 \mathfrak{s}\xi_2 \right).
$$

This implies
$$
\xi_3^2 \leq w_3^2 e^{\frac{2b}{ml^2} \bar{t}}, \quad \forall t - \bar{t} \leq z \leq t. 
$$

On the other hand,
\begin{align}
(\dot{\xi}_1)^2 + (\dot{\xi}_2)^2 = (\mathfrak{c}^2 + \mathfrak{s}^2) \xi_3^2 \leq w_3^2 e^{\frac{2b}{ml^2} \bar{t}}, \quad \forall t - \bar{t} \leq z \leq t.
\end{align} -->
</div>
</div>
</div>
<div id="kazantzis-kravaris-luenberger-kkl-template" class="section level3 hasAnchor" number="6.5.4">
<h3><span class="header-section-number">6.5.4</span> Kazantzis-Kravaris-Luenberger (KKL) Template<a href="output-feedback.html#kazantzis-kravaris-luenberger-kkl-template" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In Luenbergers original paper about observer design for linear systems <span class="citation">(<a href="#ref-luenberger64-observer">Luenberger 1964</a>)</span>, the goal was to transform a linear system
<span class="math display">\[
\dot{x} = F x, \quad y = C x
\]</span>
into a Hurwitz form
<span class="math display" id="eq:kkl-history-dynamics">\[\begin{equation}
\dot{\xi} = A \xi + B y
\tag{6.76}
\end{equation}\]</span>
with <span class="math inline">\(A\)</span> a Hurwitz (stable) matrix. If such a transformation is available, then the following system
<span class="math display">\[
\dot{\hat{\xi}} = A \hat{\xi} + B y,
\]</span>
which is nothing but a copy of the dynamics <a href="output-feedback.html#eq:kkl-history-dynamics">(6.76)</a>, is in fact an observer. This is because the error <span class="math inline">\(e = \hat{\xi} - \xi\)</span> evolves as
<span class="math display">\[
\dot{e} = A e,
\]</span>
which implies that <span class="math inline">\(e\)</span> tends to zero regardless of the initial error <span class="math inline">\(e(0)\)</span>. Luenberger proved that when <span class="math inline">\((F,C)\)</span> is observable, a stationary transformation <span class="math inline">\(\xi = T x\)</span> with <span class="math inline">\(p = n\)</span>, i.e., <span class="math inline">\(T \in \mathbb{R}^{n\times n}\)</span>, always exists and is unique, for any matrix <span class="math inline">\(A\)</span> that is Hurwitz and <span class="math inline">\((A,B)\)</span> that is controllable. This is based on the fact that
<span class="math display">\[\begin{align}
(A T + B C) x =A \xi + B y =\dot{\xi} = T \dot{x} = TF x, \forall x \\
\Longleftrightarrow AT + BC = TF,
\end{align}\]</span>
known as the Sylvester equation, admits a unique and invertible solution <span class="math inline">\(T\)</span>.</p>
<p>A natural extension of Luenbergers original idea is to find a transformation that converts the nonlinear system <a href="output-feedback.html#eq:output-feedback-system">(6.1)</a> into the following form
<span class="math display" id="eq:kkl-template">\[\begin{equation}
\dot{\xi} = A \xi + B(u,y), \quad y = H(\xi,u),
\tag{6.77}
\end{equation}\]</span>
with <span class="math inline">\(A\)</span> a Hurwitz matrix (but <span class="math inline">\(H\)</span> can be nonlinear, as opposed to the Luenberger template in Theorem <a href="output-feedback.html#thm:LuenbergerLinear">6.2</a>). If such a transformation can be found, then we can design a similar observer that copies the dynamics <a href="output-feedback.html#eq:kkl-template">(6.77)</a>
<span class="math display" id="eq:kkl-observer">\[\begin{equation}
\dot{\hat{\xi}} = A \hat{\xi} + B(u,y).
\tag{6.78}
\end{equation}\]</span>
We refer to such a nonlinear Luenberger template the Kazantzis-Kravaris-Luenberger (KKL) template, due to the seminal work <span class="citation">(<a href="#ref-kazantzis98scl-kkl">Kazantzis and Kravaris 1998</a>)</span>.</p>
<p>The KKL template, once found, is nice in the sense that (i) the observer <a href="output-feedback.html#eq:kkl-observer">(6.78)</a> is a simple copy of the dynamics and also very easy to implement (as opposed to the Kalman-Bucy observer); and (ii) checking if the matrix <span class="math inline">\(A\)</span> is Hurwitz is easy, at least when <span class="math inline">\(A\)</span> has reasonable size, (e.g., compared to checking the regular persistence condition in the state-affine template in Theorem <a href="output-feedback.html#thm:kalmanbucystateaffine">6.3</a>).</p>
<p>However, the KKL template is difficult to realize in the sense that (i) what kind of nonlinear systems can be converted to <a href="output-feedback.html#eq:kkl-template">(6.77)</a>, and (ii) for those systems, how do we find the coordinate transformation?</p>
<p>Recent works have leveraged deep learning to learn the coordinate transformation, for example in <span class="citation">(<a href="#ref-janny21cdc-deepkkl">Janny et al. 2021</a>)</span>, <span class="citation">(<a href="#ref-niazi23lacc-earning">Niazi et al. 2023</a>)</span>, <span class="citation">(<a href="#ref-miao23ll4dc-earning">Miao and Gatsis 2023</a>)</span>. Before hammering the problem with deep learning, let us look at the fundamentals of the KKL observer.</p>
<div id="autonomous-systems-1" class="section level4 hasAnchor" number="6.5.4.1">
<h4><span class="header-section-number">6.5.4.1</span> Autonomous Systems<a href="output-feedback.html#autonomous-systems-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Consider the autonomous version of system <a href="output-feedback.html#eq:output-feedback-system">(6.1)</a> without control
<span class="math display" id="eq:kkl-autonomous-system">\[\begin{equation}
\dot{x} = f(x), \quad y = h(x),
\tag{6.79}
\end{equation}\]</span>
where <span class="math inline">\(x \in \mathbb{X} \subseteq \mathbb{R}^n, y \in \mathbb{Y} \subseteq \mathbb{R}^d\)</span>.</p>
<p>The following result, established by <span class="citation">(<a href="#ref-andrieu06sicopt-kkl">Andrieu and Praly 2006</a>)</span>, states that the KKL observer exists under mild conditions.</p>
<div class="theorembox">
<div class="theorem">
<p><span id="thm:kklautonomous" class="theorem"><strong>Theorem 6.4  (KKL Observer for Autonomous Systems) </strong></span>Assum <span class="math inline">\(\mathcal{X}\)</span> and <span class="math inline">\(\mathcal{L}\)</span> are open bounded sets in <span class="math inline">\(\mathbb{X}\)</span> (the state space) such that <span class="math inline">\(\mathrm{cl}(\mathcal{X})\)</span> is contained in <span class="math inline">\(\mathcal{L}\)</span> and the system <a href="output-feedback.html#eq:kkl-autonomous-system">(6.79)</a> is backward <span class="math inline">\(\mathcal{L}\)</span>-distinguishable on <span class="math inline">\(\mathcal{X}\)</span> (cf.Definition <a href="output-feedback.html#def:observability">6.2</a>). Then there exists a strictly positive number <span class="math inline">\(\gamma\)</span> and a set <span class="math inline">\(\mathcal{S}\)</span> of zero Lebesgue measure in <span class="math inline">\(\mathbb{C}^{n+1}\)</span> such that denoting <span class="math inline">\(\Omega = \{ \lambda \in \mathbb{C} \mid \mathrm{Re}(\lambda) &lt; - \gamma \}\)</span>, for any <span class="math inline">\((\lambda_1,\dots,\lambda_{n+1}) \in \Omega^{n+1} \backslash \mathcal{S}\)</span>, there exists a function <span class="math inline">\(T: \mathbb{R}^n \rightarrow \mathbb{R}^{(n+1)d}\)</span> uniformly injective on <span class="math inline">\(\mathcal{X}\)</span> satisfying
<span class="math display">\[
L_f T(x) = A T(x) + B(h(x))
\]</span>
with
<span class="math display">\[\begin{align}
A = \tilde{A} \otimes I_d, \quad B(y) = (\tilde{B} \otimes I_d ) y \\
\tilde{A} = \begin{bmatrix}
\lambda_1 &amp; &amp; \\
&amp; \ddots &amp; \\
&amp; &amp; \lambda_{n+1} \end{bmatrix}
\quad \tilde{B} = \begin{bmatrix}
1 \\ \vdots \\ 1 \end{bmatrix}.
\end{align}\]</span>
Moreover, if <span class="math inline">\(\mathcal{X}\)</span> is backward invariant, then <span class="math inline">\(T\)</span> is unique and defined by
<span class="math display" id="eq:kkl-autonomous-T">\[\begin{equation}
T(x) = \int_{-\infty}^0 e^{-A\tau} B(h(X(x,\tau))) d\tau.
\tag{6.80}
\end{equation}\]</span></p>
</div>
</div>
<div class="remark">
<p><span id="unlabeled-div-23" class="remark"><em>Remark</em>. </span>The function <span class="math inline">\(T\)</span> in Theorem <a href="output-feedback.html#thm:kklautonomous">6.4</a> takes complex numbers. To simulate the observer
<span class="math display">\[
\dot{\hat{\xi}} = A \hat{\xi} + B(y),
\]</span>
one needs to implement in real numbers, for each <span class="math inline">\(\lambda_i\)</span> and <span class="math inline">\(j \in [d]\)</span>
<span class="math display">\[
\dot{\hat{\xi}}_{\lambda_i,j} =
\begin{bmatrix}
- \mathrm{Re}(\lambda_i) &amp; - \mathrm{Im}(\lambda_i) \\
\mathrm{Im}(\lambda_i) &amp; - \mathrm{Re}(\lambda_i)
\end{bmatrix} \hat{\xi}_{\lambda_i,j} + \begin{bmatrix} y_j \\ 0 \end{bmatrix}.   
\]</span>
Therefore, the dimension of the observer is <span class="math inline">\(2 \times d (n+1)\)</span>.</p>
</div>
<p>Theorem <a href="output-feedback.html#thm:kklautonomous">6.4</a> states that as long as the system <a href="output-feedback.html#eq:kkl-autonomous-system">(6.79)</a> is backward distinguishable, then there exists a stationary transformation <span class="math inline">\(T\)</span> that can transform the system to a new coordinate system <span class="math inline">\(\xi\)</span> such that the dynamics in <span class="math inline">\(\xi\)</span> is Hurwitz. A closer look at the structure of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> reveals that the coordinate transformation needs to satisfy <span class="math inline">\(n+1\)</span> differential equations of the form
<span class="math display">\[
\frac{\partial T_{\lambda}}{\partial x}(x) \dot{x} = \lambda T_{\lambda} (x) + y
\]</span>
where each <span class="math inline">\(T_{\lambda}\)</span> transforms the state <span class="math inline">\(x\)</span> into a new coordinate having the same dimension of <span class="math inline">\(y\)</span>. Clearly, if <span class="math inline">\(T = (T_\lambda)\)</span>, i.e., there is a single <span class="math inline">\(\lambda\)</span>, then <span class="math inline">\(T\)</span> is not uniformly injective (as the dimension of <span class="math inline">\(\xi\)</span> is <span class="math inline">\(d &lt; n\)</span>). Consequently, by choosing
<span class="math display">\[
T = (T_{\lambda_1},\dots,T_{\lambda_{n+1}}),
\]</span>
the uniform injectivity of <span class="math inline">\(T\)</span> is ensured.</p>
<p>However, the difficulty lies in the computation of <span class="math inline">\(T\)</span> (and <span class="math inline">\(T_\lambda\)</span>), let alone its inverse (that recovers <span class="math inline">\(x\)</span> from <span class="math inline">\(\xi\)</span>). Even though <span class="math inline">\(\mathcal{X}\)</span> is backward invariant, the formulation <a href="output-feedback.html#eq:kkl-autonomous-T">(6.80)</a> is difficult to compute. I tried very hard to find a coordinate transformation <span class="math inline">\(T\)</span> that can convert the non-controlled pendulum dynamics into the KKL form but did not succeed. <strong>You should let me know if you were able to find one!</strong> Nevertheless, the following example shows you the flavor of how such a transformation may look like for a different system.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:kklOscillator" class="example"><strong>Example 6.5  (KKL Observer for an Oscillator with Unknown Frequency) </strong></span>Consider a harmonic oscillator with unknown frequency
<span class="math display">\[
\begin{cases}
\dot{x}_1 = x_2 \\
\dot{x}_2 = - x_1 x_3 \\
\dot{x}_3 = 0
\end{cases}, \quad y = x_1
\]</span>
Consider the coordinate transformation
<span class="math display">\[
T_{\lambda_i} (x) = \frac{\lambda_i x_1 - x_2}{\lambda_i^2 + x_3}, \quad \lambda_i &gt; 0, i=1,\dots,p.
\]</span>
We have
<span class="math display">\[\begin{align}
\frac{\partial T_{\lambda_i}(x)}{\partial x} \dot{x} &amp;= \left\langle \begin{bmatrix}
\frac{\lambda_i}{\lambda_i^2 + x_3} \\
\frac{-1 }{\lambda_i^2 + x_3} \\
\frac{x_2 - \lambda_i x_1}{(\lambda_i^2 + x_3)^2}
\end{bmatrix}, \begin{bmatrix}
x_2 \\ -x_1 x_3 \\ 0 \end{bmatrix}
\right \rangle = \frac{\lambda_i x_2 + x_1 x_3}{\lambda_i^2 + x_3} \\
-\lambda_i T_{\lambda_i}(x) + y &amp;= \frac{-\lambda_i^2 x_1 + \lambda_i x_2 + x_1 \lambda_i^2 + x_1 x_3}{\lambda_i^2 + x_3} = \frac{\lambda_i x_2 + x_1 x_3}{\lambda_i^2 + x_3}
\end{align}\]</span>
Therefore, with
<span class="math display">\[
\xi = T(x) = [T_{\lambda_1}(x), T_{\lambda_2}(x),\dots,T_{\lambda_p}(x)]^T,
\]</span>
we have
<span class="math display">\[
\dot{\xi} = \underbrace{\begin{bmatrix}
- \lambda_1 &amp; &amp; \\
&amp; \ddots &amp; \\
&amp; &amp; -\lambda_p \end{bmatrix}}_{A} \xi + \begin{bmatrix}1 \\ \vdots \\ 1 \end{bmatrix} y
\]</span>
with <span class="math inline">\(A\)</span> clearly Hurwitz.</p>
<p>With some extra arguments (cf.Section 8.1.1 in <span class="citation">(<a href="#ref-bernard19book-observer">Bernard 2019</a>)</span>), one can see that the transformation <span class="math inline">\(T\)</span> is injective with <span class="math inline">\(p \geq 4\)</span> distinct <span class="math inline">\(\lambda_i\)</span>s. Therefore, this is a valid KKL observer.</p>
<p>The final issue that one needs to think about is, since the observer is estimating <span class="math inline">\(\hat{\xi}\)</span>, how to recover <span class="math inline">\(\hat{x}\)</span>? In this example, there is actually no analytical formula for recovering <span class="math inline">\(\hat{x}\)</span> from <span class="math inline">\(\hat{\xi}\)</span>. In this case, one approach is to solve the following optimization problem
<span class="math display">\[
\hat{x} = \arg\min_{x} \Vert \hat{\xi} - T(x) \Vert^2,
\]</span>
which may be quite expensive.</p>
<p>A more general treatment is given in Section 8.2.2 in <span class="citation">(<a href="#ref-bernard19book-observer">Bernard 2019</a>)</span>.</p>
</div>
</div>
</div>
<div id="controlled-systems-1" class="section level4 hasAnchor" number="6.5.4.2">
<h4><span class="header-section-number">6.5.4.2</span> Controlled Systems<a href="output-feedback.html#controlled-systems-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
</div>
</div>
<div id="triangular-template" class="section level3 hasAnchor" number="6.5.5">
<h3><span class="header-section-number">6.5.5</span> Triangular Template<a href="output-feedback.html#triangular-template" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="design-with-convex-optimization" class="section level3 hasAnchor" number="6.5.6">
<h3><span class="header-section-number">6.5.6</span> Design with Convex Optimization<a href="output-feedback.html#design-with-convex-optimization" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider a nonlinear system
<span class="math display" id="eq:observerdesignconvex">\[\begin{equation}
\dot{x} = f(x) + \psi(u,y), \quad y = Cx
\tag{6.81}
\end{equation}\]</span>
where <span class="math inline">\(x \in \mathbb{X} \subseteq \mathbb{R}^n\)</span>, <span class="math inline">\(y \in \mathbb{R}^d\)</span>, <span class="math inline">\(C\)</span> a constant matrix, and <span class="math inline">\(\psi(u,y)\)</span> a nonlinear function. We assume that <span class="math inline">\(f(x)\)</span> is a polynomial vector map (i.e., each entry of <span class="math inline">\(f\)</span> is a polynomial function in <span class="math inline">\(x\)</span>). Certainly the formulation in <a href="output-feedback.html#eq:observerdesignconvex">(6.81)</a> is not as general as <a href="output-feedback.html#eq:output-feedback-system">(6.1)</a>, but it is general enough to include many examples in robotics.</p>
<p>Recall that I said the essence of observer design is to (i) simulate the dynamics when the state estimation is correct, and (ii) to correct the state estimation from observation when it is off. Therefore, we wish to design an observer for <a href="output-feedback.html#eq:observerdesignconvex">(6.81)</a> in the following form
<span class="math display" id="eq:sos-observer">\[\begin{equation}
\dot{\hat{x}} = \underbrace{f(\hat{x}) + \psi(u,y)}_{\text{dynamics simulation}} + \underbrace{K(y - \hat{y},y)(C \hat{x} - y)}_{\text{feedback correction}},
\tag{6.82}
\end{equation}\]</span>
where, compared to the Luenberger observer <a href="output-feedback.html#eq:Luenberger-Linear">(6.61)</a>, we allow the gain matrix <span class="math inline">\(K\)</span> to be nonlinear functions of the true observation <span class="math inline">\(y\)</span> and the estimated observation <span class="math inline">\(\hat{y}\)</span>.</p>
<p>With the observer <a href="output-feedback.html#eq:sos-observer">(6.82)</a>, the dynamics on the estimation error <span class="math inline">\(e = \hat{x} - x\)</span> becomes
<span class="math display">\[
\dot{e} = f(x + e) - f(x) + K(Ce,Cx)C e.
\]</span></p>
<p>If we can find a Lyapunov-like function <span class="math inline">\(V(e)\)</span> so that <span class="math inline">\(V(e)\)</span> is positive definite and <span class="math inline">\(\dot{V}(e)\)</span> is negative definite, then Lyapunov stability theorem <a href="stability.html#thm:lyapunovglobalstability">5.3</a> tells us that <span class="math inline">\(e=0\)</span> is asymptotically stable. Because we do not know the gain matrix <span class="math inline">\(K\)</span> either, we need to jointly search for <span class="math inline">\(V\)</span> and <span class="math inline">\(K\)</span> (that are polynomials). Mathematically, this is
<span class="math display" id="eq:sos-observer-nonconvex">\[\begin{equation}
\begin{split}
\text{find} &amp; \quad V, K \\
\text{subject to} &amp; \quad V(0) = 0, \quad V(e) &gt; 0, \forall e \neq 0 \\
&amp; \quad \dot{V}(e) = \frac{\partial V}{\partial e} \left( f(x + e) - f(x) + K(Ce,Cx)C e \right) &lt; 0, \forall e \neq 0, \forall x \in \mathbb{X} \\
&amp; \quad V(e) \geq \epsilon \Vert e \Vert^2, \forall e
\end{split}
\tag{6.83}
\end{equation}\]</span>
where the last constraint is added to make sure <span class="math inline">\(V(e)\)</span> is radially unbounded. Furthermore, if we replace the second constraint by <span class="math inline">\(\dot{V}(e) \leq - \lambda V(e)\)</span>, then we can guarantee <span class="math inline">\(V(e)\)</span> converges to zero exponentially.</p>
<p>Problem <a href="output-feedback.html#eq:sos-observer-nonconvex">(6.83)</a>, however, is not a convex optimization problem, due to the term <span class="math inline">\(\frac{\partial V}{\partial e} K\)</span> being bilinear in the coefficients of <span class="math inline">\(V\)</span> and <span class="math inline">\(K\)</span>. Nevertheless, as shown in <span class="citation">(<a href="#ref-ebenbauer05cdc-polynomial">Ebenbauer, Renz, and Allgower 2005</a>)</span>, we can use a reparameterization trick to formulate a stronger version of <a href="output-feedback.html#eq:sos-observer-nonconvex">(6.83)</a> as follows.
<span class="math display" id="eq:sos-observer-convex-formulation">\[\begin{equation}
\begin{split}
\text{find} &amp; \quad V, Q(Ce), M(Ce,Cx) \\
\text{subject to} &amp; \quad V(0) = 0, \quad V(e) &gt; 0, \forall e \neq 0 \\
&amp; \quad \frac{\partial V}{\partial e} = e^T Q(Ce), \quad Q(Ce) \succ 0 \\
&amp; \quad e^T Q(Ce) \left( f(x + e) - f(x) \right) + e^T M(Ce,Cx) C e &lt; 0, \forall e \neq 0, \forall x \in \mathbb{X} \\
&amp; \quad V(e) \geq \epsilon \Vert e \Vert^2, \forall e
\end{split}
\tag{6.84}
\end{equation}\]</span>
Clearly, if we can solve problem <a href="output-feedback.html#eq:sos-observer-convex-formulation">(6.84)</a>, then
<span class="math display">\[
K = Q(Ce)^{-1} M(Ce,Cx)
\]</span>
is the right gain matrix for the formulation <a href="output-feedback.html#eq:sos-observer-nonconvex">(6.83)</a>.</p>
<p>Let us bring this idea to action in our pendulum example.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:pendulumobserverconvex" class="example"><strong>Example 6.6  (Pendulum Observer with Convex Optimization) </strong></span>With <span class="math inline">\(x = [\mathfrak{s}, \mathfrak{c}, \dot{\theta}]^T\)</span> (<span class="math inline">\(\mathfrak{s} = \sin \theta, \mathfrak{c} = \cos \theta\)</span>), we can write the pendulum dynamics as
<span class="math display">\[
\dot{x} = \underbrace{\begin{bmatrix}
\mathfrak{c} \dot{\theta} \\
- \mathfrak{s} \dot{\theta} \\
- \frac{b}{ml^2} \dot{\theta}
\end{bmatrix}}_{=:f(x)} + \underbrace{\begin{bmatrix}
0 \\ 0 \\ \frac{u - mgl \mathfrak{s}}{ml^2} \end{bmatrix}}_{=: \psi(u,y)}, \quad y =
\underbrace{\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \end{bmatrix}}_{=:C} x
\]</span>
Clearly <span class="math inline">\(f(x)\)</span> is a polynomial. Solving the convex optimization problem <a href="output-feedback.html#eq:sos-observer-convex-formulation">(6.84)</a>, we obtain a solution
<span class="math display">\[
V(e) = 0.5954 e_1^2 + 0.5954 e_2^2 + 0.9431 e_3^2
\]</span>
<span class="math display">\[
Q(Ce) = \begin{bmatrix}
0.4603 e_2^2 + 1.1909 &amp; -0.4603 e_1 e_2 &amp; 0 \\
-0.4603 e_1 e_2 &amp; 0.4603 e_1^2 + 1.1909 &amp; 0 \\
0 &amp; 0 &amp; 1.8863 \end{bmatrix}
\]</span>
<span class="math display">\[
M(Ce,Cx) = \begin{bmatrix}
\substack{-2.0878 e_1^2 - 0.8667 e_2^2 - \\ 0.4588 (y_1^2 + y_2^2) - 0.4885} &amp; - 0.8667 e_1 e_2 \\
- 0.8667 e_1 e_2 &amp; \substack{-0.8667 e_1^2 - 2.0878 e_2^2 - \\ 0.4588 (y_1^2 + y_2^2) - 0.4885} \\
-1.1909 y_2 &amp; 1.1909 y_1
\end{bmatrix}
\]</span></p>
<p>Simulating this observer, we verify that the observer is in fact exponentially converging, as shown in Fig. <a href="output-feedback.html#fig:sos-observer-pendulum-simulation">6.4</a>.</p>
<p>The Matlab code for formulating and solving the convex optimization <a href="output-feedback.html#eq:sos-observer-convex-formulation">(6.84)</a> can be found <a href="https://github.com/ComputationalRobotics/OptimalControlEstimation-Examples/blob/main/pendulum_sos_observer.m">here</a>. The code for simulating the observer can be found <a href="https://github.com/ComputationalRobotics/OptimalControlEstimation-Examples/blob/main/pendulum_sos_observer_simulation.m">here</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sos-observer-pendulum-simulation"></span>
<img src="images/pendulum-simulation-sos-observer.png" alt="Simulation of the pendulum observer design from convex optimization" width="80%" />
<p class="caption">
Figure 6.4: Simulation of the pendulum observer design from convex optimization
</p>
</div>
</div>
</div>
</div>
</div>
<div id="observer-feedback" class="section level2 hasAnchor" number="6.6">
<h2><span class="header-section-number">6.6</span> Observer Feedback<a href="output-feedback.html#observer-feedback" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now that we have good ways to design a state observer, we will see how we can use the observer for feedback control.</p>
<div class="examplebox">
<div class="example">
<p><span id="exm:pendulumLuenbergerFeedback" class="example"><strong>Example 6.7  (Pendulum Stabilization with A Luenberger Observer) </strong></span>In Example <a href="output-feedback.html#exm:pendulumLuenberger">6.3</a>, we have written the dynamics of a pendulum, and the dynamics of a Luenberger observer as
<span class="math display">\[\begin{align}
\dot{x} &amp;= A x + B(u,y) \\
\dot{\hat{x}} &amp;= A \hat{x} + B(u,y) + KC (x - \hat{x})
\end{align}\]</span>
We wish to understand (so we can optimize) the behavior of this system under certain control input <span class="math inline">\(u\)</span>. To do so, let us denote <span class="math inline">\(e = \hat{x} - x\)</span>, and write the above dynamics as
<span class="math display">\[\begin{align}
\dot{x} &amp;= A x + B(u,Cx) \\
\dot{e} &amp; = (A - KC) e
\end{align}\]</span>
Denoting <span class="math inline">\(z = [x,e]^T\)</span>, we have the augmented dynamics
<span class="math display">\[
\dot{z} = \underbrace{\begin{bmatrix} A &amp; 0 \\ 0 &amp; A - KC \end{bmatrix}}_{=:F} z + \underbrace{\begin{bmatrix} B(u,Dz) \\ 0 \end{bmatrix}}_{=:G(z,u)}
\]</span>
We want to stabilize the system at <span class="math inline">\(z_0 = [\pi,0,0,0]^T\)</span> (the upright position) subject to control bounds <span class="math inline">\(u \in \mathbb{U} = [-u_{\max},u_{\max}]\)</span>.</p>
<p>We need to find a control Lyapunov function (CLF), <span class="math inline">\(V(z)\)</span>, that satisfies the following constraints:
<span class="math display">\[
    V(z_0) = 0
\]</span>
<span class="math display">\[
    V(z) &gt; 0 \quad \forall z \in \{z: V(z) &lt; \rho, z \neq z_0 \}
\]</span>
<span class="math display">\[
    \inf_{u \in \mathbb{U}} [L_F V(z) + L_G V(z)] \leq 0 \quad \forall z \in \mathcal{Z}
\]</span></p>
<p>where <span class="math inline">\(L_F V\)</span> and <span class="math inline">\(L_G V\)</span> are the Lie derivatives of <span class="math inline">\(V\)</span> along <span class="math inline">\(F\)</span> and <span class="math inline">\(G(z,u)\)</span>, respectively. <span class="math inline">\(\mathcal{Z}\)</span> is the set of all possible augmented states. The CLF will define the set of admissible control inputs <span class="math inline">\(U\)</span>.
<span class="math display">\[
    U = \{ u: L_f V(z) + L_g V(z)u \leq 0 \}
\]</span>
To find the smallest-magnitude control input such that <span class="math inline">\(u \in K\)</span>, we may use a quadratic program:</p>
<p><span class="math display">\[
    \min_{u \in \mathcal{U}} ||u||^2
\]</span>
<span class="math display">\[
\mathrm{s.t.} \quad L_f V(z) + L_g V(z)u \leq -c V(z)
\]</span></p>
<p>where <span class="math inline">\(c\)</span> is some positive constant. The challenge now is in choosing a suitable <span class="math inline">\(V(z)\)</span>.</p>
<!-- \inf_{u \in \mathcalU}
-->
<!-- Our controller has access to the observation $y$ (recall this is $\theta$) and the estimated state $\hat{x}$. Let us try a controller of the following form
$$
u = mgl \sin \theta - G \hat{x} = mgl \sin \theta - G (x + e).
$$
This leads to the dynamics 
\begin{align}
\dot{x} & = A x - \frac{1}{ml^2} G (x + e) = \left( A - \frac{1}{ml^2}G \right)x - \frac{1}{ml^2} G e \\
\dot{e} & = (A - KC)e
\end{align} -->
</div>
</div>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-andrieu06sicopt-kkl" class="csl-entry">
Andrieu, Vincent, and Laurent Praly. 2006. <span>On the Existence of a KazantzisKravaris/Luenberger Observer.</span> <em>SIAM Journal on Control and Optimization</em> 45 (2): 43256.
</div>
<div id="ref-astolfi03tac-immersion" class="csl-entry">
Astolfi, Alessandro, and Romeo Ortega. 2003. <span>Immersion and Invariance: A New Tool for Stabilization and Adaptive Control of Nonlinear Systems.</span> <em>IEEE Transactions on Automatic Control</em> 48 (4): 590606.
</div>
<div id="ref-bernard19book-observer" class="csl-entry">
Bernard, Pauline. 2019. <em>Observer Design for Nonlinear Systems</em>. Vol. 479. Springer.
</div>
<div id="ref-bernard22arc-observer" class="csl-entry">
Bernard, Pauline, Vincent Andrieu, and Daniele Astolfi. 2022. <span>Observer Design for Continuous-Time Dynamical Systems.</span> <em>Annual Reviews in Control</em>.
</div>
<div id="ref-besanccon96ejc-observer" class="csl-entry">
Besanon, Gildas, Guy Bornard, and Hassan Hammouri. 1996. <span>Observer Synthesis for a Class of Nonlinear Control Systems.</span> <em>European Journal of Control</em> 2 (3): 17692.
</div>
<div id="ref-ebenbauer05cdc-polynomial" class="csl-entry">
Ebenbauer, Christian, Jonathan Renz, and F Allgower. 2005. <span>Polynomial Feedback and Observer Design Using Nonquadratic Lyapunov Functions.</span> In <em>Proceedings of the 44th IEEE Conference on Decision and Control</em>, 758792. IEEE.
</div>
<div id="ref-hammouri90cdc-observer" class="csl-entry">
Hammouri, Hassan, and Jesus de Leon Morales. 1990. <span>Observer Synthesis for State-Affine Systems.</span> In <em>29th IEEE Conference on Decision and Control</em>, 78485. IEEE.
</div>
<div id="ref-janny21cdc-deepkkl" class="csl-entry">
Janny, Steeven, Vincent Andrieu, Madiha Nadri, and Christian Wolf. 2021. <span>Deep Kkl: Data-Driven Output Prediction for Non-Linear Systems.</span> In <em>2021 60th IEEE Conference on Decision and Control (CDC)</em>, 437681. IEEE.
</div>
<div id="ref-kalman61-new" class="csl-entry">
Kalman, Rudolph E, and Richard S Bucy. 1961. <span>New Results in Linear Filtering and Prediction Theory.</span>
</div>
<div id="ref-kalman60new" class="csl-entry">
Kalman, Rudolph Emil. 1960. <span>A New Approach to Linear Filtering and Prediction Problems.</span>
</div>
<div id="ref-karagiannis05cdc-nonlinear" class="csl-entry">
Karagiannis, Dimitrios, and Alessandro Astolfi. 2005. <span>Nonlinear Observer Design Using Invariant Manifolds and Applications.</span> In <em>Proceedings of the 44th IEEE Conference on Decision and Control</em>, 777580. IEEE.
</div>
<div id="ref-kazantzis98scl-kkl" class="csl-entry">
Kazantzis, Nikolaos, and Costas Kravaris. 1998. <span>Nonlinear Observer Design Using Lyapunovs Auxiliary Theorem.</span> <em>Systems &amp; Control Letters</em> 34 (5): 24147.
</div>
<div id="ref-luenberger64-observer" class="csl-entry">
Luenberger, David G. 1964. <span>Observing the State of a Linear System.</span> <em>IEEE Transactions on Military Electronics</em> 8 (2): 7480.
</div>
<div id="ref-miao23ll4dc-earning" class="csl-entry">
Miao, Keyan, and Konstantinos Gatsis. 2023. <span>Learning Robust State Observers Using Neural ODEs.</span> In <em>Learning for Dynamics and Control Conference</em>, 20819. PMLR.
</div>
<div id="ref-niazi23lacc-earning" class="csl-entry">
Niazi, Muhammad Umar B, John Cao, Xudong Sun, Amritam Das, and Karl Henrik Johansson. 2023. <span>Learning-Based Design of Luenberger Observers for Autonomous Nonlinear Systems.</span> In <em>2023 American Control Conference (ACC)</em>, 304855. IEEE.
</div>
<div id="ref-reif99tac-stochastic" class="csl-entry">
Reif, Konrad, Stefan Gunther, Engin Yaz, and Rolf Unbehauen. 1999. <span>Stochastic Stability of the Discrete-Time Extended Kalman Filter.</span> <em>IEEE Transactions on Automatic Control</em> 44 (4): 71428.
</div>
<div id="ref-thrun05book-probabilistic" class="csl-entry">
Thrun, S, W Burgard, and D Fox. 2005. <span>Probabilistic Robotics.</span> MIT Press.
</div>
<div id="ref-van04-sigma" class="csl-entry">
Van Der Merwe, Rudolph. 2004. <em>Sigma-Point Kalman Filters for Probabilistic Inference in Dynamic State-Space Models</em>. Oregon Health &amp; Science University.
</div>
<div id="ref-yang13tac-feedback" class="csl-entry">
Yang, Tao, Prashant G Mehta, and Sean P Meyn. 2013. <span>Feedback Particle Filter.</span> <em>IEEE Transactions on Automatic Control</em> 58 (10): 246580.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="8">
<li id="fn8"><p>We say any solution because there may be several solutions to the observer <a href="output-feedback.html#eq:observer-definition-1">(6.52)</a> due to <span class="math inline">\(\mathcal{F}\)</span> only being continuous. This is not a problem as long as any such solution satisfies the required convergence property.<a href="output-feedback.html#fnref8" class="footnote-back"></a></p></li>
<li id="fn9"><p>The time dependence of <span class="math inline">\(\mathcal{T}_u\)</span> enables us to cover the case where the knowledge of the <span class="math inline">\(u\)</span> and <span class="math inline">\(y_{x_0,u}\)</span> is used to construct the estimate from the observer state. In particular, using the output sometimes can reduce the dimension of the observer state (and thus alleviate the computations), thus obtaining a reduced-order observer. For example, see <span class="citation">(<a href="#ref-karagiannis05cdc-nonlinear">Karagiannis and Astolfi 2005</a>)</span> and <span class="citation">(<a href="#ref-astolfi03tac-immersion">Astolfi and Ortega 2003</a>)</span>.<a href="output-feedback.html#fnref9" class="footnote-back"></a></p></li>
<li id="fn10"><p>A function <span class="math inline">\(\rho: \mathbb{R}_+ \rightarrow \mathbb{R}_+\)</span> is a <span class="math inline">\(\mathcal{K}\)</span> function if <span class="math inline">\(\rho(0) = 0\)</span>, <span class="math inline">\(\rho\)</span> is continuous, and <span class="math inline">\(\rho\)</span> is increasing.<a href="output-feedback.html#fnref10" class="footnote-back"></a></p></li>
<li id="fn11"><p>An injective function is a function <span class="math inline">\(f\)</span> that maps distinct elements of its domain to distinct elements. That is, <span class="math inline">\(f(x_a) = f(x_b)\)</span> implies <span class="math inline">\(x_a = x_b\)</span>, or equivalently, <span class="math inline">\(x_a \neq x_b\)</span> implies <span class="math inline">\(f(x_a) \neq f(x_b)\)</span>.<a href="output-feedback.html#fnref11" class="footnote-back"></a></p></li>
<li id="fn12"><p>I have to say I was a bit surprised when I arrived at this formulation.<a href="output-feedback.html#fnref12" class="footnote-back"></a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="stability.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="geometric-vision.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/hankyang94/OptimalControlEstimation/blob/main/06-output-feedback.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["optimal-control-estimation.pdf"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
