<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Adaptive Control | Optimal Control and Estimation</title>
  <meta name="description" content="Lecture notes for Harvard ES/AM 158 Introduction to Optimal Control and Estimation." />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Adaptive Control | Optimal Control and Estimation" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Lecture notes for Harvard ES/AM 158 Introduction to Optimal Control and Estimation." />
  <meta name="github-repo" content="hankyang94/OptimalControlEstimation" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Adaptive Control | Optimal Control and Estimation" />
  
  <meta name="twitter:description" content="Lecture notes for Harvard ES/AM 158 Introduction to Optimal Control and Estimation." />
  

<meta name="author" content="Heng Yang" />


<meta name="date" content="2025-03-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="geometric-vision.html"/>
<link rel="next" href="psets.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Optimal Control and Estimation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="formulation.html"><a href="formulation.html"><i class="fa fa-check"></i><b>1</b> The Optimal Control Formulation</a>
<ul>
<li class="chapter" data-level="1.1" data-path="formulation.html"><a href="formulation.html#the-basic-problem"><i class="fa fa-check"></i><b>1.1</b> The Basic Problem</a></li>
<li class="chapter" data-level="1.2" data-path="formulation.html"><a href="formulation.html#dynamic-programming-and-principle-of-optimality"><i class="fa fa-check"></i><b>1.2</b> Dynamic Programming and Principle of Optimality</a></li>
<li class="chapter" data-level="1.3" data-path="formulation.html"><a href="formulation.html#infinite-horizon"><i class="fa fa-check"></i><b>1.3</b> Infinite-horizon Formulation</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="exactdp.html"><a href="exactdp.html"><i class="fa fa-check"></i><b>2</b> Exact Dynamic Programming</a>
<ul>
<li class="chapter" data-level="2.1" data-path="exactdp.html"><a href="exactdp.html#lqr"><i class="fa fa-check"></i><b>2.1</b> Linear Quadratic Regulator</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="exactdp.html"><a href="exactdp.html#infinite-horizon-lqr"><i class="fa fa-check"></i><b>2.1.1</b> Infinite-Horizon LQR</a></li>
<li class="chapter" data-level="2.1.2" data-path="exactdp.html"><a href="exactdp.html#lqr-with-constraints"><i class="fa fa-check"></i><b>2.1.2</b> LQR with Constraints</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="exactdp.html"><a href="exactdp.html#mdp-exact-dp"><i class="fa fa-check"></i><b>2.2</b> Markov Decision Process</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="exactdp.html"><a href="exactdp.html#bellman-optimality-equations"><i class="fa fa-check"></i><b>2.2.1</b> Bellman Optimality Equations</a></li>
<li class="chapter" data-level="2.2.2" data-path="exactdp.html"><a href="exactdp.html#value-iteration"><i class="fa fa-check"></i><b>2.2.2</b> Value Iteration</a></li>
<li class="chapter" data-level="2.2.3" data-path="exactdp.html"><a href="exactdp.html#value-iteration-with-barycentric-interpolation"><i class="fa fa-check"></i><b>2.2.3</b> Value Iteration with Barycentric Interpolation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="approximatedp.html"><a href="approximatedp.html"><i class="fa fa-check"></i><b>3</b> Approximate Optimal Control</a>
<ul>
<li class="chapter" data-level="3.1" data-path="approximatedp.html"><a href="approximatedp.html#fitted-value-iteration"><i class="fa fa-check"></i><b>3.1</b> Fitted Value Iteration</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="approximatedp.html"><a href="approximatedp.html#linear-features"><i class="fa fa-check"></i><b>3.1.1</b> Linear Features</a></li>
<li class="chapter" data-level="3.1.2" data-path="approximatedp.html"><a href="approximatedp.html#neural-network-features"><i class="fa fa-check"></i><b>3.1.2</b> Neural Network Features</a></li>
<li class="chapter" data-level="3.1.3" data-path="approximatedp.html"><a href="approximatedp.html#fitted-q-value-iteration"><i class="fa fa-check"></i><b>3.1.3</b> Fitted Q-value Iteration</a></li>
<li class="chapter" data-level="3.1.4" data-path="approximatedp.html"><a href="approximatedp.html#deep-q-network"><i class="fa fa-check"></i><b>3.1.4</b> Deep Q Network</a></li>
<li class="chapter" data-level="3.1.5" data-path="approximatedp.html"><a href="approximatedp.html#deep-shallow"><i class="fa fa-check"></i><b>3.1.5</b> Deep + Shallow</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="approximatedp.html"><a href="approximatedp.html#trajectory-optimization"><i class="fa fa-check"></i><b>3.2</b> Trajectory Optimization</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="approximatedp.html"><a href="approximatedp.html#direct-single-shooting"><i class="fa fa-check"></i><b>3.2.1</b> Direct Single Shooting</a></li>
<li class="chapter" data-level="3.2.2" data-path="approximatedp.html"><a href="approximatedp.html#direct-multiple-shooting"><i class="fa fa-check"></i><b>3.2.2</b> Direct Multiple Shooting</a></li>
<li class="chapter" data-level="3.2.3" data-path="approximatedp.html"><a href="approximatedp.html#direct-collocation"><i class="fa fa-check"></i><b>3.2.3</b> Direct Collocation</a></li>
<li class="chapter" data-level="3.2.4" data-path="approximatedp.html"><a href="approximatedp.html#direct-orthogonal-collocation"><i class="fa fa-check"></i><b>3.2.4</b> Direct Orthogonal Collocation</a></li>
<li class="chapter" data-level="3.2.5" data-path="approximatedp.html"><a href="approximatedp.html#failure-of-open-loop-control"><i class="fa fa-check"></i><b>3.2.5</b> Failure of Open-Loop Control</a></li>
<li class="chapter" data-level="3.2.6" data-path="approximatedp.html"><a href="approximatedp.html#lqr-trajectory-tracking"><i class="fa fa-check"></i><b>3.2.6</b> LQR Trajectory Tracking</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="approximatedp.html"><a href="approximatedp.html#model-predictive-control"><i class="fa fa-check"></i><b>3.3</b> Model Predictive Control</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="approximatedp.html"><a href="approximatedp.html#turn-trajectory-optimization-into-feedback-control"><i class="fa fa-check"></i><b>3.3.1</b> Turn Trajectory Optimization into Feedback Control</a></li>
<li class="chapter" data-level="3.3.2" data-path="approximatedp.html"><a href="approximatedp.html#controllability-reachability-and-invariance"><i class="fa fa-check"></i><b>3.3.2</b> Controllability, Reachability, and Invariance</a></li>
<li class="chapter" data-level="3.3.3" data-path="approximatedp.html"><a href="approximatedp.html#basic-formulation-for-linear-systems"><i class="fa fa-check"></i><b>3.3.3</b> Basic Formulation for Linear Systems</a></li>
<li class="chapter" data-level="3.3.4" data-path="approximatedp.html"><a href="approximatedp.html#persistent-feasibility"><i class="fa fa-check"></i><b>3.3.4</b> Persistent Feasibility</a></li>
<li class="chapter" data-level="3.3.5" data-path="approximatedp.html"><a href="approximatedp.html#mpc-stability"><i class="fa fa-check"></i><b>3.3.5</b> Stability</a></li>
<li class="chapter" data-level="3.3.6" data-path="approximatedp.html"><a href="approximatedp.html#explicit-mpc"><i class="fa fa-check"></i><b>3.3.6</b> Explicit MPC</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="approximatedp.html"><a href="approximatedp.html#policy-gradient"><i class="fa fa-check"></i><b>3.4</b> Policy Gradient</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html"><i class="fa fa-check"></i><b>4</b> Continuous-time Optimal Control</a>
<ul>
<li class="chapter" data-level="4.1" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#the-basic-problem-1"><i class="fa fa-check"></i><b>4.1</b> The Basic Problem</a></li>
<li class="chapter" data-level="4.2" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#the-hamilton-jacobi-bellman-equation"><i class="fa fa-check"></i><b>4.2</b> The Hamilton-Jacobi-Bellman Equation</a></li>
<li class="chapter" data-level="4.3" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#linear-quadratic-regulator"><i class="fa fa-check"></i><b>4.3</b> Linear Quadratic Regulator</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#lqr-trajectory-tracking-1"><i class="fa fa-check"></i><b>4.3.1</b> LQR Trajectory Tracking</a></li>
<li class="chapter" data-level="4.3.2" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#lqr-trajectory-stabilization"><i class="fa fa-check"></i><b>4.3.2</b> LQR Trajectory Stabilization</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#the-pontryagin-minimum-principle"><i class="fa fa-check"></i><b>4.4</b> The Pontryagin Minimum Principle</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#numerical-solution-of-the-tpbvp"><i class="fa fa-check"></i><b>4.4.1</b> Numerical Solution of the TPBVP</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#infinite-horizon-problems"><i class="fa fa-check"></i><b>4.5</b> Infinite-Horizon Problems</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#continuous-time-infinite-horizon-lqr"><i class="fa fa-check"></i><b>4.5.1</b> Infinite-Horizon LQR</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="continuous-time-optimal-control.html"><a href="continuous-time-optimal-control.html#viscosity-solution"><i class="fa fa-check"></i><b>4.6</b> Viscosity Solution</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="stability.html"><a href="stability.html"><i class="fa fa-check"></i><b>5</b> Stability Analysis</a>
<ul>
<li class="chapter" data-level="5.1" data-path="stability.html"><a href="stability.html#autonomous-systems"><i class="fa fa-check"></i><b>5.1</b> Autonomous Systems</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="stability.html"><a href="stability.html#concepts-of-stability"><i class="fa fa-check"></i><b>5.1.1</b> Concepts of Stability</a></li>
<li class="chapter" data-level="5.1.2" data-path="stability.html"><a href="stability.html#stability-by-linearization"><i class="fa fa-check"></i><b>5.1.2</b> Stability by Linearization</a></li>
<li class="chapter" data-level="5.1.3" data-path="stability.html"><a href="stability.html#lyapunov-analysis"><i class="fa fa-check"></i><b>5.1.3</b> Lyapunov Analysis</a></li>
<li class="chapter" data-level="5.1.4" data-path="stability.html"><a href="stability.html#invariant-set-theorem"><i class="fa fa-check"></i><b>5.1.4</b> Invariant Set Theorem</a></li>
<li class="chapter" data-level="5.1.5" data-path="stability.html"><a href="stability.html#computing-lyapunov-certificates"><i class="fa fa-check"></i><b>5.1.5</b> Computing Lyapunov Certificates</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="stability.html"><a href="stability.html#controlled-systems"><i class="fa fa-check"></i><b>5.2</b> Controlled Systems</a></li>
<li class="chapter" data-level="5.3" data-path="stability.html"><a href="stability.html#non-autonomous-systems"><i class="fa fa-check"></i><b>5.3</b> Non-autonomous Systems</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="output-feedback.html"><a href="output-feedback.html"><i class="fa fa-check"></i><b>6</b> Output Feedback</a>
<ul>
<li class="chapter" data-level="6.1" data-path="output-feedback.html"><a href="output-feedback.html#least-squares-estimation"><i class="fa fa-check"></i><b>6.1</b> Least-Squares Estimation</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="output-feedback.html"><a href="output-feedback.html#linear-least-squares-estimation"><i class="fa fa-check"></i><b>6.1.1</b> Linear Least-Squares Estimation</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="output-feedback.html"><a href="output-feedback.html#kalman-filter"><i class="fa fa-check"></i><b>6.2</b> Kalman Filter</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="output-feedback.html"><a href="output-feedback.html#steady-state-kalman-filter"><i class="fa fa-check"></i><b>6.2.1</b> Steady-State Kalman Filter</a></li>
<li class="chapter" data-level="6.2.2" data-path="output-feedback.html"><a href="output-feedback.html#continuous-time-kalman-filter"><i class="fa fa-check"></i><b>6.2.2</b> Continuous-time Kalman Filter</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="output-feedback.html"><a href="output-feedback.html#linear-quadratic-gaussian-control"><i class="fa fa-check"></i><b>6.3</b> Linear Quadratic Gaussian Control</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="output-feedback.html"><a href="output-feedback.html#steady-state-lqg"><i class="fa fa-check"></i><b>6.3.1</b> Steady-state LQG</a></li>
<li class="chapter" data-level="6.3.2" data-path="output-feedback.html"><a href="output-feedback.html#continuous-time-lqg"><i class="fa fa-check"></i><b>6.3.2</b> Continuous-time LQG</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="output-feedback.html"><a href="output-feedback.html#nonlinear-filtering"><i class="fa fa-check"></i><b>6.4</b> Nonlinear Filtering</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="output-feedback.html"><a href="output-feedback.html#extended-kalman-filter"><i class="fa fa-check"></i><b>6.4.1</b> Extended Kalman Filter</a></li>
<li class="chapter" data-level="6.4.2" data-path="output-feedback.html"><a href="output-feedback.html#unscented-kalman-filter"><i class="fa fa-check"></i><b>6.4.2</b> Unscented Kalman Filter</a></li>
<li class="chapter" data-level="6.4.3" data-path="output-feedback.html"><a href="output-feedback.html#particle-filter"><i class="fa fa-check"></i><b>6.4.3</b> Particle Filter</a></li>
<li class="chapter" data-level="6.4.4" data-path="output-feedback.html"><a href="output-feedback.html#feedback-particle-filter"><i class="fa fa-check"></i><b>6.4.4</b> Feedback Particle Filter</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="output-feedback.html"><a href="output-feedback.html#state-observer"><i class="fa fa-check"></i><b>6.5</b> State Observer</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="output-feedback.html"><a href="output-feedback.html#general-design-strategy"><i class="fa fa-check"></i><b>6.5.1</b> General Design Strategy</a></li>
<li class="chapter" data-level="6.5.2" data-path="output-feedback.html"><a href="output-feedback.html#luenberger-template"><i class="fa fa-check"></i><b>6.5.2</b> Luenberger Template</a></li>
<li class="chapter" data-level="6.5.3" data-path="output-feedback.html"><a href="output-feedback.html#state-affine-template"><i class="fa fa-check"></i><b>6.5.3</b> State-affine Template</a></li>
<li class="chapter" data-level="6.5.4" data-path="output-feedback.html"><a href="output-feedback.html#kazantzis-kravaris-luenberger-kkl-template"><i class="fa fa-check"></i><b>6.5.4</b> Kazantzis-Kravaris-Luenberger (KKL) Template</a></li>
<li class="chapter" data-level="6.5.5" data-path="output-feedback.html"><a href="output-feedback.html#triangular-template"><i class="fa fa-check"></i><b>6.5.5</b> Triangular Template</a></li>
<li class="chapter" data-level="6.5.6" data-path="output-feedback.html"><a href="output-feedback.html#design-with-convex-optimization"><i class="fa fa-check"></i><b>6.5.6</b> Design with Convex Optimization</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="output-feedback.html"><a href="output-feedback.html#observer-feedback"><i class="fa fa-check"></i><b>6.6</b> Observer Feedback</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="geometric-vision.html"><a href="geometric-vision.html"><i class="fa fa-check"></i><b>7</b> Geometric Vision</a>
<ul>
<li class="chapter" data-level="7.1" data-path="geometric-vision.html"><a href="geometric-vision.html#d-rotations-and-poses"><i class="fa fa-check"></i><b>7.1</b> 3D Rotations and Poses</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="geometric-vision.html"><a href="geometric-vision.html#rotation-matrices"><i class="fa fa-check"></i><b>7.1.1</b> Rotation matrices</a></li>
<li class="chapter" data-level="7.1.2" data-path="geometric-vision.html"><a href="geometric-vision.html#coordinate-frame"><i class="fa fa-check"></i><b>7.1.2</b> Coordinate Frame</a></li>
<li class="chapter" data-level="7.1.3" data-path="geometric-vision.html"><a href="geometric-vision.html#representations-of-the-rotations"><i class="fa fa-check"></i><b>7.1.3</b> Representations of the rotations</a></li>
<li class="chapter" data-level="7.1.4" data-path="geometric-vision.html"><a href="geometric-vision.html#miscellaneous-topics-on-rotations"><i class="fa fa-check"></i><b>7.1.4</b> Miscellaneous topics on rotations</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="geometric-vision.html"><a href="geometric-vision.html#the-pinhole-camera-model"><i class="fa fa-check"></i><b>7.2</b> The Pinhole Camera Model</a></li>
<li class="chapter" data-level="7.3" data-path="geometric-vision.html"><a href="geometric-vision.html#camera-pose-estimation"><i class="fa fa-check"></i><b>7.3</b> Camera Pose Estimation</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="geometric-vision.html"><a href="geometric-vision.html#the-p3p-problem"><i class="fa fa-check"></i><b>7.3.1</b> The P3P Problem</a></li>
<li class="chapter" data-level="7.3.2" data-path="geometric-vision.html"><a href="geometric-vision.html#the-pnp-problem"><i class="fa fa-check"></i><b>7.3.2</b> The PnP Problem</a></li>
<li class="chapter" data-level="7.3.3" data-path="geometric-vision.html"><a href="geometric-vision.html#global-optimality"><i class="fa fa-check"></i><b>7.3.3</b> Global Optimality</a></li>
<li class="chapter" data-level="7.3.4" data-path="geometric-vision.html"><a href="geometric-vision.html#handling-outliers"><i class="fa fa-check"></i><b>7.3.4</b> Handling Outliers</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="geometric-vision.html"><a href="geometric-vision.html#point-cloud-registration"><i class="fa fa-check"></i><b>7.4</b> Point Cloud Registration</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html"><i class="fa fa-check"></i><b>8</b> Adaptive Control</a>
<ul>
<li class="chapter" data-level="8.1" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html#model-reference-adaptive-control"><i class="fa fa-check"></i><b>8.1</b> Model-Reference Adaptive Control</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html#first-order-systems"><i class="fa fa-check"></i><b>8.1.1</b> First-Order Systems</a></li>
<li class="chapter" data-level="8.1.2" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html#high-order-systems"><i class="fa fa-check"></i><b>8.1.2</b> High-Order Systems</a></li>
<li class="chapter" data-level="8.1.3" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html#robotic-manipulator"><i class="fa fa-check"></i><b>8.1.3</b> Robotic Manipulator</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="adaptivecontrol.html"><a href="adaptivecontrol.html#certainty-equivalent-adaptive-control"><i class="fa fa-check"></i><b>8.2</b> Certainty-Equivalent Adaptive Control</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="psets.html"><a href="psets.html"><i class="fa fa-check"></i><b>9</b> Problem Sets</a></li>
<li class="chapter" data-level="" data-path="acknowledgement.html"><a href="acknowledgement.html"><i class="fa fa-check"></i>Acknowledgement</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html"><i class="fa fa-check"></i><b>A</b> Linear Algebra and Differential Equations</a>
<ul>
<li class="chapter" data-level="A.1" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html#linear-algebra"><i class="fa fa-check"></i><b>A.1</b> Linear Algebra</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html#matrix-exponential"><i class="fa fa-check"></i><b>A.1.1</b> Matrix Exponential</a></li>
<li class="chapter" data-level="A.1.2" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html#gradients"><i class="fa fa-check"></i><b>A.1.2</b> Gradients</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html#solving-an-ordinary-differential-equation"><i class="fa fa-check"></i><b>A.2</b> Solving an Ordinary Differential Equation</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html#separation-of-variables"><i class="fa fa-check"></i><b>A.2.1</b> Separation of Variables</a></li>
<li class="chapter" data-level="A.2.2" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html#first-order-linear-ode"><i class="fa fa-check"></i><b>A.2.2</b> First-order Linear ODE</a></li>
<li class="chapter" data-level="A.2.3" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html#gronwall-inequality"><i class="fa fa-check"></i><b>A.2.3</b> Gronwall Inequality</a></li>
<li class="chapter" data-level="A.2.4" data-path="linear-algebra-and-differential-equations.html"><a href="linear-algebra-and-differential-equations.html#matlab"><i class="fa fa-check"></i><b>A.2.4</b> Matlab</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="appconvex.html"><a href="appconvex.html"><i class="fa fa-check"></i><b>B</b> Convex Analysis and Optimization</a>
<ul>
<li class="chapter" data-level="B.1" data-path="appconvex.html"><a href="appconvex.html#appconvex-theory"><i class="fa fa-check"></i><b>B.1</b> Theory</a>
<ul>
<li class="chapter" data-level="B.1.1" data-path="appconvex.html"><a href="appconvex.html#sets"><i class="fa fa-check"></i><b>B.1.1</b> Sets</a></li>
<li class="chapter" data-level="B.1.2" data-path="appconvex.html"><a href="appconvex.html#appconvex-theory-convexfunction"><i class="fa fa-check"></i><b>B.1.2</b> Convex function</a></li>
<li class="chapter" data-level="B.1.3" data-path="appconvex.html"><a href="appconvex.html#lagrange-dual"><i class="fa fa-check"></i><b>B.1.3</b> Lagrange dual</a></li>
<li class="chapter" data-level="B.1.4" data-path="appconvex.html"><a href="appconvex.html#appconvex-theory-kkt"><i class="fa fa-check"></i><b>B.1.4</b> KKT condition</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="appconvex.html"><a href="appconvex.html#appconvex-practice"><i class="fa fa-check"></i><b>B.2</b> Practice</a>
<ul>
<li class="chapter" data-level="B.2.1" data-path="appconvex.html"><a href="appconvex.html#cvx-introduction"><i class="fa fa-check"></i><b>B.2.1</b> CVX Introduction</a></li>
<li class="chapter" data-level="B.2.2" data-path="appconvex.html"><a href="appconvex.html#linear-programming-lp"><i class="fa fa-check"></i><b>B.2.2</b> Linear Programming (LP)</a></li>
<li class="chapter" data-level="B.2.3" data-path="appconvex.html"><a href="appconvex.html#quadratic-programming-qp"><i class="fa fa-check"></i><b>B.2.3</b> Quadratic Programming (QP)</a></li>
<li class="chapter" data-level="B.2.4" data-path="appconvex.html"><a href="appconvex.html#quadratically-constrained-quadratic-programming-qcqp"><i class="fa fa-check"></i><b>B.2.4</b> Quadratically Constrained Quadratic Programming (QCQP)</a></li>
<li class="chapter" data-level="B.2.5" data-path="appconvex.html"><a href="appconvex.html#second-order-cone-programming-socp"><i class="fa fa-check"></i><b>B.2.5</b> Second-Order Cone Programming (SOCP)</a></li>
<li class="chapter" data-level="B.2.6" data-path="appconvex.html"><a href="appconvex.html#semidefinite-programming-sdp"><i class="fa fa-check"></i><b>B.2.6</b> Semidefinite Programming (SDP)</a></li>
<li class="chapter" data-level="B.2.7" data-path="appconvex.html"><a href="appconvex.html#cvxpy-introduction-and-examples"><i class="fa fa-check"></i><b>B.2.7</b> CVXPY Introduction and Examples</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html"><i class="fa fa-check"></i><b>C</b> Linear System Theory</a>
<ul>
<li class="chapter" data-level="C.1" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#app-lti-stability"><i class="fa fa-check"></i><b>C.1</b> Stability</a>
<ul>
<li class="chapter" data-level="C.1.1" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#app-lti-stability-ct"><i class="fa fa-check"></i><b>C.1.1</b> Continuous-Time Stability</a></li>
<li class="chapter" data-level="C.1.2" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#app-lti-stability-dt"><i class="fa fa-check"></i><b>C.1.2</b> Discrete-Time Stability</a></li>
<li class="chapter" data-level="C.1.3" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#lyapunov-analysis-1"><i class="fa fa-check"></i><b>C.1.3</b> Lyapunov Analysis</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#app-lti-controllable-observable"><i class="fa fa-check"></i><b>C.2</b> Controllability and Observability</a>
<ul>
<li class="chapter" data-level="C.2.1" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#cayley-hamilton-theorem"><i class="fa fa-check"></i><b>C.2.1</b> Cayley-Hamilton Theorem</a></li>
<li class="chapter" data-level="C.2.2" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#equivalent-statements-for-controllability"><i class="fa fa-check"></i><b>C.2.2</b> Equivalent Statements for Controllability</a></li>
<li class="chapter" data-level="C.2.3" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#duality"><i class="fa fa-check"></i><b>C.2.3</b> Duality</a></li>
<li class="chapter" data-level="C.2.4" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#equivalent-statements-for-observability"><i class="fa fa-check"></i><b>C.2.4</b> Equivalent Statements for Observability</a></li>
</ul></li>
<li class="chapter" data-level="C.3" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#stabilizability-and-detectability"><i class="fa fa-check"></i><b>C.3</b> Stabilizability And Detectability</a>
<ul>
<li class="chapter" data-level="C.3.1" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#equivalent-statements-for-stabilizability"><i class="fa fa-check"></i><b>C.3.1</b> Equivalent Statements for Stabilizability</a></li>
<li class="chapter" data-level="C.3.2" data-path="app-lti-system-theory.html"><a href="app-lti-system-theory.html#equivalent-statements-for-detectability"><i class="fa fa-check"></i><b>C.3.2</b> Equivalent Statements for Detectability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="algebraic-techniques-and-sum-of-squares.html"><a href="algebraic-techniques-and-sum-of-squares.html"><i class="fa fa-check"></i><b>D</b> Algebraic Techniques and Sum-of-Squares</a>
<ul>
<li class="chapter" data-level="D.1" data-path="algebraic-techniques-and-sum-of-squares.html"><a href="algebraic-techniques-and-sum-of-squares.html#algebra"><i class="fa fa-check"></i><b>D.1</b> Algebra</a>
<ul>
<li class="chapter" data-level="D.1.1" data-path="algebraic-techniques-and-sum-of-squares.html"><a href="algebraic-techniques-and-sum-of-squares.html#polynomials"><i class="fa fa-check"></i><b>D.1.1</b> Polynomials</a></li>
<li class="chapter" data-level="D.1.2" data-path="algebraic-techniques-and-sum-of-squares.html"><a href="algebraic-techniques-and-sum-of-squares.html#representation-of-nonnegative-polynomial-univariate-case"><i class="fa fa-check"></i><b>D.1.2</b> Representation of nonnegative polynomial: Univariate case</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="E" data-path="the-kalman-yakubovich-lemma.html"><a href="the-kalman-yakubovich-lemma.html"><i class="fa fa-check"></i><b>E</b> The Kalman-Yakubovich Lemma</a></li>
<li class="chapter" data-level="F" data-path="feedbacklinearization.html"><a href="feedbacklinearization.html"><i class="fa fa-check"></i><b>F</b> Feedback Linearization</a></li>
<li class="chapter" data-level="G" data-path="slidingcontrol.html"><a href="slidingcontrol.html"><i class="fa fa-check"></i><b>G</b> Sliding Control</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Optimal Control and Estimation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="adaptivecontrol" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> Adaptive Control<a href="adaptivecontrol.html#adaptivecontrol" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="model-reference-adaptive-control" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Model-Reference Adaptive Control<a href="adaptivecontrol.html#model-reference-adaptive-control" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Basic flow for designing an adaptive controller</p>
<ol style="list-style-type: decimal">
<li><p>Design a control law with variable parameters</p></li>
<li><p>Design an adaptation law for adjusting the control parameters</p></li>
<li><p>Analyze the convergence of the closed-loop system</p></li>
</ol>
<p>The control law design at the first step typically requires the designer to know what a good controller is if the true parameters were actually known, e.g., from feedback linearization (Appendix <a href="feedbacklinearization.html#feedbacklinearization">F</a>), sliding control (Appendix <a href="slidingcontrol.html#slidingcontrol">G</a>) etc.</p>
<p>The design of the adaptation law typically comes from analyzing the dynamics of the tracking error, which as we will see often appears in the form of Lemma <a href="adaptivecontrol.html#lem:adaptivecontrolbasic">8.1</a>.</p>
<p>The convergence of the closed-loop system is usually analyzed with the help of a Lyapunov-like function introduced in Chapter <a href="stability.html#stability">5</a>.</p>
<div class="lemma">
<p><span id="lem:adaptivecontrolbasic" class="lemma"><strong>Lemma 8.1  (Basic Lemma) </strong></span>Let two signals <span class="math inline">\(e(t)\)</span> and <span class="math inline">\(\phi(t)\)</span> be related by
<span class="math display" id="eq:acbasiclemmaephi">\[\begin{equation}
e(t) = H(p)[k \phi(t)^T v(t)]
\tag{8.1}
\end{equation}\]</span>
where <span class="math inline">\(e(t)\)</span> a scalar output signal, <span class="math inline">\(H(p)\)</span> a strictly positive real (SPR) transfer function, <span class="math inline">\(k\)</span> an unknown real number with known sign, <span class="math inline">\(\phi(t) \in \mathbb{R}^m\)</span> a control signal, and <span class="math inline">\(v(t) \in \mathbb{R}^m\)</span> a measurable input signal.</p>
<p>If the control signal <span class="math inline">\(\phi(t)\)</span> satisfies
<span class="math display" id="eq:acbasiclemmaphilaw">\[\begin{equation}
\dot{\phi}(t) = - \mathrm{sgn}(k) \gamma e(t) v(t)
\tag{8.2}
\end{equation}\]</span>
with <span class="math inline">\(\gamma &gt; 0\)</span> a positive constant, then <span class="math inline">\(e(t)\)</span> and <span class="math inline">\(\phi(t)\)</span> are globally bounded. Moreover, if <span class="math inline">\(v(t)\)</span> is bounded, then
<span class="math display">\[
\lim_{t \rightarrow \infty} e(t) = 0.
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-27" class="proof"><em>Proof</em>. </span>Let the state-space representation of <a href="adaptivecontrol.html#eq:acbasiclemmaephi">(8.1)</a> be
<span class="math display" id="eq:acbasiclemmastatespace">\[\begin{equation}
\dot{x} = A x + b [k \phi^T v], \quad e = c^T x.
\tag{8.3}
\end{equation}\]</span>
Since <span class="math inline">\(H(p)\)</span> is SPR, it follows from the Kalman-Yakubovich Lemma <a href="the-kalman-yakubovich-lemma.html#lem:KalmanYakubovich">E.1</a> that there exist <span class="math inline">\(P,Q \succ 0\)</span> such that
<span class="math display">\[
A^T P + P A = -Q, \quad Pb = c.
\]</span>
Let
<span class="math display">\[
V(x,\phi) = x^T P x + \frac{|k|}{\gamma} \phi^T \phi,
\]</span>
clearly <span class="math inline">\(V\)</span> is positive definite (i.e., <span class="math inline">\(V(0,0)=0\)</span>, and <span class="math inline">\(V(x,\phi) &gt; 0\)</span> for all <span class="math inline">\(x \neq 0, \phi \neq 0\)</span>). The time derivative of <span class="math inline">\(V\)</span> along the trajectory defined by <a href="adaptivecontrol.html#eq:acbasiclemmastatespace">(8.3)</a> with <span class="math inline">\(\phi\)</span> chosen as in <a href="adaptivecontrol.html#eq:acbasiclemmaphilaw">(8.2)</a> is
<span class="math display">\[\begin{align}
\dot{V} &amp; = \frac{\partial V}{\partial x} \dot{x} + \frac{\partial V}{\partial \phi} \dot{\phi} \\
&amp;= x^T (PA + A^T P) x + 2 x^T P b (k \phi^T v) + \frac{2|k|}{\gamma} \phi^T (- \mathrm{sgn}(k) \gamma e v) \\
&amp; = - x^T Q x + 2 (x^T c)(k\phi^T v) - 2 \phi^T (e v) \\
&amp; = - x^T Q x \leq 0.
\end{align}\]</span>
As a result, we know <span class="math inline">\(x\)</span> and <span class="math inline">\(\phi\)</span> must be bounded (<span class="math inline">\(V(x(t),\phi(t)) \leq V(x(0),\phi(0))\)</span> is bounded). Since <span class="math inline">\(e = c^T x\)</span>, we know <span class="math inline">\(e\)</span> must be bounded as well.</p>
<p>If the input signal <span class="math inline">\(v\)</span> is also bounded, then <span class="math inline">\(\dot{x}\)</span> is bounded as seen from <a href="adaptivecontrol.html#eq:acbasiclemmastatespace">(8.3)</a>. Because <span class="math inline">\(\ddot{V} = -2x^T Q \dot{x}\)</span> is now bounded, we know <span class="math inline">\(\dot{V}\)</span> is uniformly continuous. Therefore, by Barbalat’s stability certificate (Theorem <a href="stability.html#thm:BarbalatStability">5.7</a>), we know <span class="math inline">\(\dot{V}\)</span> tends to zero as <span class="math inline">\(t\)</span> tends to infinity, which implies <span class="math inline">\(\lim_{t \rightarrow \infty} x(t) = 0\)</span> and hence <span class="math inline">\(\lim_{t \rightarrow \infty} e(t) = 0\)</span>.</p>
</div>
<div id="first-order-systems" class="section level3 hasAnchor" number="8.1.1">
<h3><span class="header-section-number">8.1.1</span> First-Order Systems<a href="adaptivecontrol.html#first-order-systems" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<!-- ### Linear Systems  -->
<p>Consider the first-order single-input single-output (SISO) system
<span class="math display" id="eq:ac-first-linear">\[\begin{equation}
\dot{x} = - a x + b u
\tag{8.4}
\end{equation}\]</span>
where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are unknown groundtruth parameters. However, we do assume that the sign of <span class="math inline">\(b\)</span> is known. <span style="color:red">What if the sign of <span class="math inline">\(b\)</span> is unknown too?</span></p>
<p>Let <span class="math inline">\(r(t)\)</span> be a reference trajectory, e.g., a step function or a sinusoidal function, and <span class="math inline">\(x_d(t)\)</span> be a desired system trajectory that tracks the reference
<span class="math display" id="eq:ac-first-linear-desired">\[\begin{equation}
\dot{x}_d = - a_d x_d + b_d r(t),
\tag{8.5}
\end{equation}\]</span>
where <span class="math inline">\(a_d,b_d &gt; 0\)</span> are user-defined constants. Note that the transfer function from <span class="math inline">\(r\)</span> to <span class="math inline">\(x_d\)</span> is
<span class="math display">\[
x_d = \frac{b_d}{p + a_d} r
\]</span>
and the system is stable. <span style="color:red">Review basics of transfer function.</span></p>
<p>The goal of adaptive control is to design a control law and an adaptation law such that the tracking error of the system <span class="math inline">\(x(t) - x_d(t)\)</span> converges to zero.</p>
<p><strong>Control law</strong>. We design the control law as
<span class="math display" id="eq:ac-first-linear-control">\[\begin{equation}
u = \hat{a}_r(t) r + \hat{a}_x(t) x
\tag{8.6}
\end{equation}\]</span>
where <span class="math inline">\(\hat{a}_r(t)\)</span> and <span class="math inline">\(\hat{a}_x(t)\)</span> are time-varying feedback gains that we wish to adapt. The closed-loop dynamics of system <a href="adaptivecontrol.html#eq:ac-first-linear">(8.4)</a> with the controller <a href="adaptivecontrol.html#eq:ac-first-linear-control">(8.6)</a> is
<span class="math display">\[
\dot{x} = - a x + b (\hat{a}_r r + \hat{a}_x x) = - (a - b \hat{a}_x) x + b \hat{a}_r r.
\]</span>
With the equation above,
the reason for choosing the control law <a href="adaptivecontrol.html#eq:ac-first-linear-control">(8.6)</a> is clear: if the system parameters <span class="math inline">\((a,b)\)</span> were known, then choosing
<span class="math display" id="eq:ac-first-linear-optimal-gain">\[\begin{equation}
a_r^\star = \frac{b_d}{b}, \quad a_x^\star = \frac{a - a_d}{b}
\tag{8.7}
\end{equation}\]</span>
leads to the closed-loop dynamics <span class="math inline">\(\dot{x} = - a_d x + b_d r\)</span> that is exactly what we want in <a href="adaptivecontrol.html#eq:ac-first-linear-desired">(8.5)</a>.</p>
<p>However, in adaptive control, since the true parameters <span class="math inline">\((a,b)\)</span> are not revealed to the control designer, an adaptation law is needed to dynamically adjust the gains <span class="math inline">\(\hat{a}_r\)</span> and <span class="math inline">\(\hat{a}_x\)</span> based on the tracking error <span class="math inline">\(x(t) - x_d(t)\)</span>.</p>
<p><strong>Adaptation law</strong>. Let <span class="math inline">\(e(t) = x(t) - x_d(t)\)</span> be the tracking error, and we develop its time derivative
<span class="math display" id="eq:ac-first-linear-error-dynamics">\[\begin{align}
\dot{e} &amp;= \dot{x} - \dot{x}_d \\
        &amp;= - a_d (x - x_d) + (a_d - a + b\hat{a}_x)x + (b \hat{a}_r - b_d) r \\
        &amp; = - a_d e + b\underbrace{(\hat{a}_x - \hat{a}_x^\star)}_{=:\tilde{a}_x} x + b \underbrace{(\hat{a}_r - \hat{a}_r^\star )}_{=:\tilde{a}_r} r \\
        &amp; = - a_d e + b (\tilde{a}_x x + \tilde{a}_r r) \tag{8.8}
\end{align}\]</span>
where <span class="math inline">\(\tilde{a}_x\)</span> and <span class="math inline">\(\tilde{a}_r\)</span> are the gain errors w.r.t. the optimal gains in <a href="adaptivecontrol.html#eq:ac-first-linear-optimal-gain">(8.7)</a> if the true parameters were known. The error dynamics <a href="adaptivecontrol.html#eq:ac-first-linear-error-dynamics">(8.8)</a> is equivalent to the following transfer function
<span class="math display" id="eq:ac-first-linear-error-dynamics-transfer">\[\begin{equation}
e = \frac{1}{p + a_d} b(\tilde{a}_x x + \tilde{a}_r r) = \frac{1}{p + a_d} \left(b
\begin{bmatrix} \tilde{a}_x \\ \tilde{a}_r \end{bmatrix}^T
\begin{bmatrix} x \\ r \end{bmatrix}
\right),
\tag{8.9}
\end{equation}\]</span>
which is in the form of <a href="adaptivecontrol.html#eq:acbasiclemmaephi">(8.1)</a>. Therefore, we choose the adaptation law
<span class="math display" id="eq:ac-first-linear-adaptation-law">\[\begin{equation}
\begin{bmatrix} \dot{\tilde{a}}_x \\ \dot{\tilde{a}}_r \end{bmatrix} = - \mathrm{sgn}(b) \gamma e \begin{bmatrix} x \\ r \end{bmatrix}.
\tag{8.10}
\end{equation}\]</span></p>
<p><strong>Tracking convergence</strong>. With the control law <a href="adaptivecontrol.html#eq:ac-first-linear-control">(8.6)</a> and the adaptation law <a href="adaptivecontrol.html#eq:ac-first-linear-adaptation-law">(8.10)</a>, we can prove that the tracking error converges to zero, using Lemma <a href="adaptivecontrol.html#lem:adaptivecontrolbasic">8.1</a>. With <span class="math inline">\(\tilde{a}=[\tilde{a}_x, \tilde{a}_r]^T\)</span>, let
<span class="math display" id="eq:ac-first-linear-lyapunov">\[\begin{equation}
V(e,\tilde{a}) = e^2 + \frac{|b|}{\gamma} \tilde{a}^T \tilde{a}
\tag{8.11}
\end{equation}\]</span>
be a positive definite Lyapunov function candidate with time derivative
<span class="math display">\[
\dot{V} = - 2a_d e^2 \leq 0.
\]</span>
Clearly, <span class="math inline">\(e\)</span> and <span class="math inline">\(\tilde{a}\)</span> are both bounded. Assuming the reference trajectory <span class="math inline">\(r\)</span> is bounded, we know <span class="math inline">\(x_d\)</span> is bounded (due to <a href="adaptivecontrol.html#eq:ac-first-linear-desired">(8.5)</a>) and hence <span class="math inline">\(x\)</span> is bounded (due to <span class="math inline">\(e = x - x_d\)</span> being bounded). Consequently, from the error dynamics <a href="adaptivecontrol.html#eq:ac-first-linear-error-dynamics">(8.8)</a> we know <span class="math inline">\(\dot{e}\)</span> is bounded, which implies <span class="math inline">\(\ddot{V} = -4a_d e \dot{e}\)</span> is bounded and <span class="math inline">\(\dot{V}\)</span> is uniformly continuous. By Barbalat’s stability certificate <a href="stability.html#thm:BarbalatStability">5.7</a>, we conlude <span class="math inline">\(e(t) \rightarrow 0\)</span> as <span class="math inline">\(t \rightarrow \infty\)</span>.</p>
<p>It is always better to combine mathematical analysis with intuitive understanding. Can you explain intuitively why the adaptation law <a href="adaptivecontrol.html#eq:ac-first-linear-adaptation-law">(8.10)</a> makes sense? (Hint: think about how the control should react to a negative/positive tracking error.)</p>
<p><strong>Parameter convergence</strong>. We have shown the control law <a href="adaptivecontrol.html#eq:ac-first-linear-control">(8.6)</a> and the adaptation law <a href="adaptivecontrol.html#eq:ac-first-linear-adaptation-law">(8.10)</a> guarantee to track the reference trajectory. However, is it guaranteed that the gains of the controller <a href="adaptivecontrol.html#eq:ac-first-linear-control">(8.6)</a> also converge to the optimal gains in <a href="adaptivecontrol.html#eq:ac-first-linear-optimal-gain">(8.7)</a>?</p>
<p>We will now show that the answer is indefinite and it depends on the reference trajectory <span class="math inline">\(r(t)\)</span>. Because the tracking error <span class="math inline">\(e\)</span> converges to zero, and <span class="math inline">\(e\)</span> is the output of a stable filter <a href="adaptivecontrol.html#eq:ac-first-linear-error-dynamics-transfer">(8.9)</a>, we know the input <span class="math inline">\(b(\tilde{a}_x x + \tilde{a}_r r)\)</span> must also converge to zero. On the other hand, the adaptation law <a href="adaptivecontrol.html#eq:ac-first-linear-adaptation-law">(8.10)</a> shows that both <span class="math inline">\(\dot{\tilde{a}}_x\)</span> and <span class="math inline">\(\dot{\tilde{a}}_r\)</span> converge to zero (due to <span class="math inline">\(e\)</span> converging to zero and <span class="math inline">\(x\)</span>, <span class="math inline">\(r\)</span> being bounded). As a result, we know <span class="math inline">\(\tilde{a} = [\tilde{a}_x,\tilde{a}_r]^T\)</span> converges to a constant that satisfies
<span class="math display" id="eq:ac-first-linear-parameter-equation">\[\begin{equation}
v^T \tilde{a} = 0, \quad v = \begin{bmatrix} x \\ r \end{bmatrix},
\tag{8.12}
\end{equation}\]</span>
which is a single linear equation of <span class="math inline">\(\tilde{a}\)</span> with time-varying coeffients.</p>
<ul>
<li><p><strong>Constant reference: no guaranteed convergence</strong>. Suppose <span class="math inline">\(r(t) \equiv r_0 \neq 0\)</span> for all <span class="math inline">\(t\)</span>. From <a href="adaptivecontrol.html#eq:ac-first-linear-desired">(8.5)</a> we know <span class="math inline">\(x = x_d = \alpha r_0\)</span> when <span class="math inline">\(t \rightarrow \infty\)</span>, where <span class="math inline">\(\alpha\)</span> is the constant DC gain of the stable filter. Therefore, the linear equation <a href="adaptivecontrol.html#eq:ac-first-linear-parameter-equation">(8.12)</a> reduces to
<span class="math display">\[
\alpha \tilde{a}_x + \tilde{a}_r  = 0.
\]</span>
This implies that <span class="math inline">\(\tilde{a}\)</span> does not necessarily converge to zero. In fact, it converges to a straight line in the parameter space.</p></li>
<li><p><strong>Persistent excitation: guaranteed convergence</strong>. However, when the signal <span class="math inline">\(v\)</span> satisfies the so-called <em>persistent excitation</em> condition, which states that for any <span class="math inline">\(t\)</span>, there exists <span class="math inline">\(T, \beta &gt; 0\)</span> such that
<span class="math display" id="eq:ac-first-linear-persistent-excitation">\[\begin{equation}
\int_{t}^{t+T} v v^T d\tau \geq \beta I,
\tag{8.13}
\end{equation}\]</span>
then <span class="math inline">\(\tilde{a}\)</span> is guaranteed to converge to zero. To see this, we multiply <a href="adaptivecontrol.html#eq:ac-first-linear-parameter-equation">(8.12)</a> by <span class="math inline">\(v\)</span> and integrate it from <span class="math inline">\(t\)</span> to <span class="math inline">\(t+T\)</span>, which gives rise to
<span class="math display">\[
\left( \int_{t}^{t+T} vv^T d\tau \right) \tilde{a} = 0.
\]</span>
By the persistent excitation condition <a href="adaptivecontrol.html#eq:ac-first-linear-persistent-excitation">(8.13)</a>, we infer that <span class="math inline">\(\tilde{a} = 0\)</span> is the only solution.</p></li>
</ul>
<p>It remains to understand under what conditions of the reference trajectory <span class="math inline">\(r(t)\)</span> can we guarantee the persistent excitation of <span class="math inline">\(v\)</span>. We leave it as an exercise for the reader to show, if <span class="math inline">\(r(t)\)</span> contains at least one sinusoidal component, then the persistent excitation condition of <span class="math inline">\(v\)</span> is guaranteed.</p>
<!-- ### Nonlinear Systems  -->
<div class="exercise">
<p><span id="exr:adaptivecontrolfirstordernonlinearsystem" class="exercise"><strong>Exercise 8.1  (Extension to Nonlinear Systems) </strong></span>Design a control law and an adaptation law for the following system
<span class="math display">\[
\dot{x} = - a x - c f(x) + b u
\]</span>
with unknown true parameters <span class="math inline">\((a,b,c)\)</span> (assume the sign of <span class="math inline">\(b\)</span> is known) and known nonlinearity <span class="math inline">\(f(x)\)</span> to track a reference trajectory <span class="math inline">\(r(t)\)</span>. Analyze the convergence of tracking error and parameter estimation error.</p>
</div>
</div>
<div id="high-order-systems" class="section level3 hasAnchor" number="8.1.2">
<h3><span class="header-section-number">8.1.2</span> High-Order Systems<a href="adaptivecontrol.html#high-order-systems" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider an <span class="math inline">\(n\)</span>-th order nonlinear system
<span class="math display" id="eq:ac-singleinput-nonlinear">\[\begin{equation}
q^{(n)} + \sum_{i=1}^n \alpha_i f_i(x,t) = bu
\tag{8.14}
\end{equation}\]</span>
where <span class="math inline">\(x=[q,\dot{q},\ddot{q},\dots,q^{(n-1)}]^T\)</span> is the state of the system, <span class="math inline">\(f_i\)</span>’s are known nonlinearities, <span class="math inline">\((\alpha_1,\dots,\alpha_n,b)\)</span> are unknown parameters of the system (with <span class="math inline">\(\mathrm{sgn}(b)\)</span> known).</p>
<p>The goal of adaptive control is to control the system <a href="adaptivecontrol.html#eq:ac-singleinput-nonlinear">(8.14)</a> trajectory to follow a desired trajectory <span class="math inline">\(q_d(t)\)</span> despite no knowing the true parameters.</p>
<p>To facilitate the derivation of the adaptive controller, let us divide both sides of <a href="adaptivecontrol.html#eq:ac-singleinput-nonlinear">(8.14)</a> by <span class="math inline">\(b\)</span>
<span class="math display" id="eq:ac-singleinput-nonlinear-equivalent">\[\begin{equation}
h q^{(n)} + \sum_{i=1}^n a_i f_i(x,t) = u
\tag{8.15}
\end{equation}\]</span>
where <span class="math inline">\(h = 1 / b\)</span> and <span class="math inline">\(a_i = \alpha_i / b\)</span>.</p>
<p><strong>Control law</strong>. Recall that the choice of the control law is tyically inspired by the control design if the true system parameters were known. We will borrow ideas from sliding control (Appendix <a href="slidingcontrol.html#slidingcontrol">G</a>).</p>
<ul>
<li><p><strong>Known parameters</strong>. Let <span class="math inline">\(e = q(t) - q_d(t)\)</span> be the tracking error, and define the following combined error
<span class="math display">\[
s = e^{(n-1)} + \lambda_{n-2} e^{(n-2)} + \dots + \lambda_0 e = \Delta(p) e
\]</span>
where <span class="math inline">\(\Delta(p) = p^{n-1} + \lambda_{n-2} p^{(n-2)} + \dots + \lambda_0\)</span> is a stable polynomial with user-chosen coeffients <span class="math inline">\(\lambda_0,\dots,\lambda_{n-2}\)</span>. The rationale for defining the combined error <span class="math inline">\(s\)</span> is that the convergence of <span class="math inline">\(e\)</span> to zero can be guaranteed by the convergence of <span class="math inline">\(s\)</span> to zero (when <span class="math inline">\(\Delta(p)\)</span> is stable).
Note that <span class="math inline">\(s\)</span> can be equivalently written as
<span class="math display">\[\begin{align}
s &amp; = (q^{(n-1)} - q_d^{(n-1)}) + \lambda_{n-2} e^{(n-2)} + \dots + \lambda_0 e \\
&amp; = q^{(n-1)} - \underbrace{ \left( q_d^{(n-1)} - \lambda_{n-2} e^{(n-2)} - \dots - \lambda_0 e  \right) }_{q_r^{(n-1)}}.
\end{align}\]</span>
Now consider the control law
<span class="math display" id="eq:ac-singleinput-nonlinear-control-law-knownparam">\[\begin{equation}
u = h q_r^{(n)} - ks + \sum_{i=1}^n a_i f_i(x,t)
\tag{8.16}
\end{equation}\]</span>
where
<span class="math display">\[
q_r^{(n)} = q_d^{(n)} - \lambda_{n-2} e^{(n-1)} - \dots - \lambda_0 \dot{e}
\]</span>
and <span class="math inline">\(k\)</span> is a design constant that has the same sign as <span class="math inline">\(h\)</span>. This choice of control, plugged into the system dynamics <a href="adaptivecontrol.html#eq:ac-singleinput-nonlinear-equivalent">(8.15)</a>, leads to
<span class="math display">\[\begin{align}
h q^{(n)} + \sum_{i=1}^n a_i f_i(x,t) = h q_r^{(n)} - ks + \sum_{i=1}^n a_i f_i(x,t) \Longleftrightarrow \\
h \left( q^{(n)} - q_r^{(n)} \right) + ks = 0 \Longleftrightarrow \\
h \dot{s} + ks = 0,
\end{align}\]</span>
which guarantees the exponential convergence of <span class="math inline">\(s\)</span> to zero (note that <span class="math inline">\(h\)</span> and <span class="math inline">\(k\)</span> have the same sign), and hence the convergence of <span class="math inline">\(e\)</span> to zero.</p></li>
<li><p><strong>Unknown parameters</strong>. Inspired by the control law with known parameters in <a href="adaptivecontrol.html#eq:ac-singleinput-nonlinear-control-law-knownparam">(8.16)</a>, we design the adapative control law as
<span class="math display" id="eq:ac-singleinput-nonlinear-control-law-unknownparam">\[\begin{equation}
u = \hat{h} q_r^{(n)} - ks + \sum_{i=1}^n \hat{a}_i f_i(x,t),
\tag{8.17}
\end{equation}\]</span>
where the time-varying gains <span class="math inline">\(\hat{h},\hat{a}_1,\dots,\hat{a}_n\)</span> will be adjusted by an adaptation law.</p></li>
</ul>
<p><strong>Adaptation law</strong>. Inserting the adapative control law <a href="adaptivecontrol.html#eq:ac-singleinput-nonlinear-control-law-unknownparam">(8.17)</a> into the system dynamics <a href="adaptivecontrol.html#eq:ac-singleinput-nonlinear-equivalent">(8.15)</a>, we obtain
<span class="math display" id="eq:ac-singleinput-nonlinear-error-dynamics">\[\begin{align}
h \dot{s} + ks = \tilde{h} q_r^{(n)} + \sum_{i=1}^n \tilde{a}_i f_i (x,t) \Longleftrightarrow \\
s = \frac{1}{p + k/h} \frac{1}{h} \underbrace{ \left(
    \begin{bmatrix} \tilde{h} \\ \tilde{a}_1 \\ \vdots \\ \tilde{a}_n \end{bmatrix}^T
    \begin{bmatrix} q_r^{(n)} \\ f_1(x,t) \\ \vdots \\ f_n(x,t) \end{bmatrix}
    \right)}_{=:\phi^T v}
\tag{8.18}
\end{align}\]</span>
where <span class="math inline">\(\tilde{h} = \hat{h} - h\)</span> and <span class="math inline">\(\tilde{a}_i = \hat{a}_i - a_i,i=1,\dots,n\)</span>. Again, <a href="adaptivecontrol.html#eq:ac-singleinput-nonlinear-error-dynamics">(8.18)</a> is in the familiar form of <a href="adaptivecontrol.html#eq:acbasiclemmaephi">(8.1)</a>, which naturally leads to the following adaptation law with <span class="math inline">\(\gamma &gt; 0\)</span> a chosen constant
<span class="math display" id="eq:ac-singleinput-nonlinear-adaptation-law">\[\begin{equation}
\dot{\phi} = \begin{bmatrix} \dot{\tilde{h}} \\ \dot{\tilde{a}}_1 \\ \vdots \\ \dot{\tilde{a}}_n \end{bmatrix} = - \mathrm{sgn}(h) \gamma s \begin{bmatrix} q_r^{(n)} \\ f_1(x,t) \\ \vdots \\ f_n(x,t) \end{bmatrix}.
\tag{8.19}
\end{equation}\]</span></p>
<p><strong>Tracking and parameter convergence</strong>. With the following Lyapunov function
<span class="math display" id="eq:ac-singleinput-nonlinear-lyapunov">\[\begin{equation}
V(s,\phi) = |h| s^2 + \frac{1}{\gamma} \phi^T \phi, \quad \dot{V}(s,\phi) -2|k| s^2,
\tag{8.20}
\end{equation}\]</span>
the global convergence of <span class="math inline">\(s\)</span> to zero can be easily shown. For parameter convergence, it is easy to see that when <span class="math inline">\(v\)</span> satisfies the persistent excitation condition, we have that <span class="math inline">\(\phi\)</span> converges to zero. (However, the relationship between the reference trajectory <span class="math inline">\(q_d(t)\)</span> and the persistent excitation of <span class="math inline">\(v\)</span> becomes nontrivial due to the nonlinearities <span class="math inline">\(f_i\)</span>.)</p>
</div>
<div id="robotic-manipulator" class="section level3 hasAnchor" number="8.1.3">
<h3><span class="header-section-number">8.1.3</span> Robotic Manipulator<a href="adaptivecontrol.html#robotic-manipulator" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>So far our focus has been on systems with a single input (<span class="math inline">\(u \in \mathbb{R}\)</span>). In the following, we will show that similar techniques can be applied to adapative control of systems with multiple inputs, particularly, trajectory control of a robotic manipulator.</p>
<p>Let <span class="math inline">\(q \in \mathbb{R}^n\)</span> be the joint angles of a multi-link robotic arm, and <span class="math inline">\(\dot{q} \in \mathbb{R}^n\)</span> be the joint velocities. The dynamics of a robotic manipulator reads
<span class="math display" id="eq:ac-mrac-manipulator-dynamics">\[\begin{equation}
H(q) \ddot{q} + C(q,\dot{q})\dot{q} + g(q) = \tau,
\tag{8.21}
\end{equation}\]</span>
where <span class="math inline">\(H(q) \in \mathbb{S}^{n}_{++}\)</span> is the manipulator inertia matrix (that is positive definite), <span class="math inline">\(C(q,\dot{q})\dot{q}\)</span> is a vector of centripetal and Coriolis torques (with <span class="math inline">\(C(q,\dot{q}) \in \mathbb{R}^{n \times n}\)</span>), and <span class="math inline">\(g(q)\)</span> denotes gravitational torques.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:planar-two-link"></span>
<img src="images/drawme.png" alt="Planar two-link manipulator" width="60%" />
<p class="caption">
Figure 8.1: Planar two-link manipulator
</p>
</div>
<div class="examplebox">
<div class="example">
<p><span id="exm:planartwolinkmanipulator" class="example"><strong>Example 8.1  (Planar Two-link Manipulator) </strong></span>The dynamics of a planar two-link manipulator in Fig. <a href="adaptivecontrol.html#fig:planar-two-link">8.1</a> is
<span class="math display" id="eq:ac-mrac-manipulator-dynamics-planartwolink">\[\begin{equation}
\begin{bmatrix} H_{11} &amp; H_{12} \\ H_{21} &amp; H_{22} \end{bmatrix}
\begin{bmatrix} \ddot{q}_1 \\ \ddot{q}_2 \end{bmatrix}
+
\begin{bmatrix} - h \dot{q}_2 &amp; -h (\dot{q}_1 + \dot{q}_2) \\ h \dot{q}_1 &amp; 0 \end{bmatrix}
\begin{bmatrix} \dot{q}_1 \\ \dot{q}_2 \end{bmatrix}
=
\begin{bmatrix} \tau_1 \\ \tau_2 \end{bmatrix},
\tag{8.22}
\end{equation}\]</span>
where
<span class="math display">\[\begin{align}
H_{11} &amp; = a_1 + 2 a_3 \cos q_2 + 2 a_4 \sin q_2 \\
H_{12} &amp; = H_{21} = a_2 + a_3 \cos q_2 + a_4 \sin q_2 \\
H_{22} &amp;= a_2 \\
h &amp;= a_3 \sin q_2 - a_4 \cos q_2
\end{align}\]</span>
with
<span class="math display">\[\begin{align}
a_1 &amp;= I_1 + m_1 l_{c1}^2 + I_e + m_e l_{ce}^2 + m_e l_1^2 \\
a_2 &amp;= I_e + m_e l_{ce}^2 \\
a_3 &amp;= m_e l_1 l_{ce} \cos \delta_e \\
a_4 &amp;= m_e l_1 l_{ce} \sin \delta_e.
\end{align}\]</span></p>
</div>
</div>
<p>As seen from the above example, the parameters <span class="math inline">\(a\)</span> (which are nonlinear functions of the physical parameters such as mass and length) enter linearly in <span class="math inline">\(H\)</span> and <span class="math inline">\(C\)</span> (<span class="math inline">\(g(q)\)</span> is ignored because the manipulator is on a horizontal plane).</p>
<p>The goal of the control design is to have the manipulator track a desired trajectory <span class="math inline">\(q_d(t)\)</span>.</p>
<p><strong>Known parameters</strong>. When the parameters are known, we follow the sliding control design framework. Let <span class="math inline">\(\tilde{q} = q(t) - q_d(t)\)</span> be the tracking error, and define the combined error
<span class="math display">\[
s = \dot{\tilde{q}} + \Lambda \tilde{q} = \dot{q} - \underbrace{\left( \dot{q}_d - \Lambda \tilde{q} \right)}_{\dot{q}_r}
\]</span>
where <span class="math inline">\(\Lambda \in \mathbb{S}^n_{++}\)</span> is a user-chosen positive definite matrix (in general we want <span class="math inline">\(-\Lambda\)</span> to be Hurwitz). In this case, <span class="math inline">\(s \rightarrow 0\)</span> implies <span class="math inline">\(\tilde{q} \rightarrow 0\)</span> as <span class="math inline">\(t \rightarrow \infty\)</span>. Choosing the control law (coming from feedback linearization Appendix <a href="feedbacklinearization.html#feedbacklinearization">F</a>)
<span class="math display" id="eq:ac-mrac-manipulator-controller-knownparam">\[\begin{equation}
\tau = H \ddot{q}_r - K_D s + C \dot{q} + g(q)
\tag{8.23}
\end{equation}\]</span>
with <span class="math inline">\(K_D \in \mathbb{S}^n_{++}\)</span> positive definite leads to the closed-loop dynamics
<span class="math display">\[
H \dot{s} + K_D s = 0 \Longleftrightarrow \dot{s} = - H^{-1} K_D s.
\]</span>
Because the matrix <span class="math inline">\(H^{-1} K_D\)</span> is the product of two positive definite matrices (recall <span class="math inline">\(H\)</span> is positive definite and so is <span class="math inline">\(H^{-1}\)</span>), it has strictly positive real eigenvalues.<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a> Hence, <span class="math inline">\(- H^{-1} K_D\)</span> is <a href="https://en.wikipedia.org/wiki/Hurwitz_matrix">Hurwitz</a> and <span class="math inline">\(s\)</span> is guaranteed to converge to zero.</p>
<p><strong>Control law</strong>. A closer look at the controller <a href="adaptivecontrol.html#eq:ac-mrac-manipulator-controller-knownparam">(8.23)</a> allows us to write it in the following form
<span class="math display">\[\begin{align}
\tau &amp;= H \ddot{q}_r + C(s + \dot{q}_r) + g(q) - K_D s  \\
&amp;= H \ddot{q}_r + C \dot{q}_r + g(q) + (C - K_D) s \\
&amp;= Y (q,\dot{q},\dot{q}_r,\ddot{q}_r) a + (C - K_D) s
\end{align}\]</span>
where <span class="math inline">\(a \in \mathbb{R}^m\)</span> contains all the parameters and <span class="math inline">\(Y \in \mathbb{R}^{n \times m}\)</span> is the matrix that collects all the coeffients of <span class="math inline">\(a\)</span> in <span class="math inline">\(H \ddot{q}_r + C \dot{q}_r + g(q)\)</span>. As a result, we design the adapative control law to be
<span class="math display" id="eq:ac-mrac-manipulator-controller-unknownparam">\[\begin{equation}
\tau = Y \hat{a} - K_D s,
\tag{8.24}
\end{equation}\]</span>
with <span class="math inline">\(\hat{a}\)</span> the time-varying parameter that we wish to adapt. Note that here we have done something strange: the adapative control law does not exactly follow the controller <a href="adaptivecontrol.html#eq:ac-mrac-manipulator-controller-knownparam">(8.23)</a> in the known-parameter case.<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a> We first separated <span class="math inline">\(s\)</span> from <span class="math inline">\(\dot{q}\)</span> and wrote <span class="math inline">\(Ya = H \ddot{q}_r + C \dot{q}_r + g\)</span> instead of <span class="math inline">\(Ya = H \ddot{q}_r + C \dot{q} + g\)</span>; then we dropped the “<span class="math inline">\(C\)</span>” matrix in front of <span class="math inline">\(s\)</span> in the adapative control law. The reason for doing this will soon become clear when we analyze the tracking convergence.</p>
<p><strong>Adaptation law and tracking convergence</strong>.
Recall that the key of adapative control is to design a control law and an adaptation law such that global converge of the tracking error <span class="math inline">\(s\)</span> can be guaranteed by a Lyapunov function. Looking at the previous Lyapunov functions in <a href="adaptivecontrol.html#eq:ac-first-linear-lyapunov">(8.11)</a> and <a href="adaptivecontrol.html#eq:ac-singleinput-nonlinear-lyapunov">(8.20)</a>, we see that they both contain a positive definite term in the tracking error <span class="math inline">\(s\)</span> (or <span class="math inline">\(e\)</span> if in first-order systems) and another positive definite term in the parameter error <span class="math inline">\(\tilde{a}\)</span>. This hints us that we may try a Lyapunov candidate function of the following form
<span class="math display" id="eq:ac-mrac-manipulator-controller-unknownparam-lyapunov">\[\begin{equation}
V = \frac{1}{2} \left( s^T H s + \tilde{a} \Gamma^{-1} \tilde{a} \right),
\tag{8.25}
\end{equation}\]</span>
where <span class="math inline">\(\Gamma \in \mathbb{S}^m_{++}\)</span> is a constant positive definite matrix, and <span class="math inline">\(\tilde{a} = \hat{a} - a\)</span> is the parameter error.</p>
<p>The next step would be to derive the time derivative of <span class="math inline">\(V\)</span>, which, as we can expect, will contain a term that involves <span class="math inline">\(\dot{H}\)</span> and complicates our analysis. Fortunately, the following lemma will help us.</p>
<div class="lemma">
<p><span id="lem:skewsymmetricmanipulator" class="lemma"><strong>Lemma 8.2  </strong></span>For the manipulator dynamics <a href="adaptivecontrol.html#eq:ac-mrac-manipulator-dynamics">(8.21)</a>, there exists a way to define <span class="math inline">\(C\)</span> such that <span class="math inline">\(\dot{H} - 2C\)</span> is skew-symmetric.</p>
</div>
<div class="proof">
<p><span id="unlabeled-div-28" class="proof"><em>Proof</em>. </span>See Section 9.1, page 399-402 in <span class="citation">(<a href="#ref-slotine91book-applied">Slotine, Li, et al. 1991</a>)</span>. You should also check if this is true for the planar two-link manipulator dynamics in Example <a href="adaptivecontrol.html#exm:planartwolinkmanipulator">8.1</a>.</p>
</div>
<p>With Lemma <a href="adaptivecontrol.html#lem:skewsymmetricmanipulator">8.2</a>, the time derivative of <span class="math inline">\(V\)</span> in <a href="adaptivecontrol.html#eq:ac-mrac-manipulator-controller-unknownparam-lyapunov">(8.25)</a> reads
<span class="math display" id="eq:ac-mrac-manipulator-controller-unknownparam-lyapunov-derivative" id="eq:ac-mrac-manipulator-controller-unknownparam-lyapunov-derivative-3" id="eq:ac-mrac-manipulator-controller-unknownparam-lyapunov-derivative-2" id="eq:ac-mrac-manipulator-controller-unknownparam-lyapunov-derivative-1">\[\begin{align}
\dot{V} &amp; = s^T H \dot{s} + \frac{1}{2} s^T \dot{H} s + \tilde{a}^T \Gamma^{-1} \dot{\tilde{a}} \\
&amp;= s^T (H \ddot{q} - H \ddot{q}_r) + \frac{1}{2} s^T \dot{H} s + \tilde{a}^T \Gamma^{-1} \dot{\tilde{a}} \\
&amp;=
s^T (\tau - C \dot{q} - g - H \ddot{q}_r ) + \frac{1}{2} s^T \dot{H} s + \tilde{a}^T \Gamma^{-1} \dot{\tilde{a}} \tag{8.26} \\
&amp;= s^T (\tau - H \ddot{q}_r - C (s + \dot{q}_r) - g) + \frac{1}{2} s^T \dot{H} s + \tilde{a}^T \Gamma^{-1} \dot{\tilde{a}} \\
&amp;= s^T (\tau - H \ddot{q}_r - C \dot{q}_r - g) + \frac{1}{2} s^T (\dot{H}- 2C)s + \tilde{a}^T \Gamma^{-1} \dot{\tilde{a}} \tag{8.27}\\
&amp;= s^T (\tau - H \ddot{q}_r - C \dot{q}_r - g) + \tilde{a}^T \Gamma^{-1} \dot{\tilde{a}} \\
&amp;=s^T(Y\hat{a} - K_D s - Ya) + \tilde{a}^T \Gamma^{-1} \dot{\tilde{a}} \tag{8.28}\\
&amp;=s^T Y \tilde{a} + \tilde{a}^T \Gamma^{-1} \dot{\tilde{a}} - s^T K_D s \tag{8.29},
\end{align}\]</span>
where we used the manipulator dynamics <a href="adaptivecontrol.html#eq:ac-mrac-manipulator-dynamics">(8.21)</a> to rewrite <span class="math inline">\(H\ddot{q}\)</span> in <a href="adaptivecontrol.html#eq:ac-mrac-manipulator-controller-unknownparam-lyapunov-derivative-1">(8.26)</a>, used <span class="math inline">\(\dot{H} - 2C\)</span> is skew-symmetric in <a href="adaptivecontrol.html#eq:ac-mrac-manipulator-controller-unknownparam-lyapunov-derivative-2">(8.27)</a>, invoked the adapative control law <a href="adaptivecontrol.html#eq:ac-mrac-manipulator-controller-unknownparam">(8.24)</a> and reused <span class="math inline">\(Ya = H \ddot{q}_r + C \dot{q}_r + g(q)\)</span> in <a href="adaptivecontrol.html#eq:ac-mrac-manipulator-controller-unknownparam-lyapunov-derivative-3">(8.28)</a>. The derivation above explains why the choice of the control law in <a href="adaptivecontrol.html#eq:ac-mrac-manipulator-controller-unknownparam">(8.24)</a> did not exactly follow its counterpart when the parameters are known: we need to use <span class="math inline">\(s^T Cs\)</span> to cancel <span class="math inline">\(\frac{1}{2} s^T \dot{H} s\)</span> in <a href="adaptivecontrol.html#eq:ac-mrac-manipulator-controller-unknownparam-lyapunov-derivative-2">(8.27)</a>.</p>
<p>We then wonder if we can design <span class="math inline">\(\dot{\tilde{a}}\)</span> such that <span class="math inline">\(\dot{V}\)</span> in <a href="adaptivecontrol.html#eq:ac-mrac-manipulator-controller-unknownparam-lyapunov-derivative">(8.29)</a> is negative semidefinie? This turns out to be straightforward with the adaptation law
<span class="math display" id="eq:ac-mrac-manipulator-controller-unknownparam-adaptation-law">\[\begin{equation}
\dot{\tilde{a}} = -\Gamma Y^T s,
\tag{8.30}
\end{equation}\]</span>
to make <span class="math inline">\(s^T Y \tilde{a} + \tilde{a}^T \Gamma^{-1} \dot{\tilde{a}}\)</span> vanish and so
<span class="math display">\[
\dot{V} = - s^T K_D s \leq 0.
\]</span></p>
<p>We are not done yet. To show <span class="math inline">\(s\)</span> converges to zero (which is implied by <span class="math inline">\(\dot{V}\)</span> converges to zero), by Barbalat’s stability certificate <a href="stability.html#thm:BarbalatStability">5.7</a>, it suffices to show
<span class="math display">\[
\ddot{V} = -2 s^T K_D \dot{s}
\]</span>
is bounded. We already know <span class="math inline">\(s\)</span> and <span class="math inline">\(\tilde{a}\)</span> are bounded, due to the fact that <span class="math inline">\(V\)</span> in <a href="adaptivecontrol.html#eq:ac-mrac-manipulator-controller-unknownparam-lyapunov">(8.25)</a> is bounded. Therefore, we only need to show <span class="math inline">\(\dot{s}\)</span> is bounded. To do so, we plug the adapative control law <a href="adaptivecontrol.html#eq:ac-mrac-manipulator-controller-unknownparam">(8.24)</a> into the manipulator dynamics <a href="adaptivecontrol.html#eq:ac-mrac-manipulator-dynamics">(8.21)</a> and obtain
<span class="math display">\[
H \dot{s} + (C + K_D) s = Y\tilde{a},
\]</span>
which implies the boundedness of <span class="math inline">\(\dot{s}\)</span> (note that <span class="math inline">\(H\)</span> is uniformly positive definite, i.e., <span class="math inline">\(H \succeq \alpha I\)</span> for some <span class="math inline">\(\alpha &gt; 0\)</span>). This concludes the analysis of the tracking convergence <span class="math inline">\(s \rightarrow 0\)</span> as <span class="math inline">\(t \rightarrow \infty\)</span>.</p>
<!-- With the adapative control law \@ref(eq:ac-mrac-manipulator-controller-unknownparam), the closed-loop dynamics becomes 
\begin{align}
H \ddot{q} + C \dot{q} + g(q) = \tau = Y \hat{a} - K_D s \Longleftrightarrow \\
H \ddot{q} + C \dot{q} + g(q) = Y(\hat{a} - a) + Y a - K_D s \Longleftrightarrow \\
H \ddot{q} + C \dot{q} + g(q) = Y \tilde{a} - K_D s + \underbrace{(H \ddot{q}_r + C \dot{q} + g(q))}_{\text{recall this is }Ya} \Longleftrightarrow \\
H \dot{s} + K_D s = Y \tilde{a} (\#eq:ac-mrac-manipulator-controller-unknownparam-error-dynamics)
\end{align}
with $\tilde{a} = \hat{a} - a$ the parameter error. The above equation \@ref(eq:ac-mrac-manipulator-controller-unknownparam-error-dynamics), however, no longer has the familiar form \@ref(eq:acbasiclemmaephi). How do we design the adaptation law to ensure tracking convergence?
Let us try the following function as a Lyapunov function candidate
where $\Gamma \in \mathbb{S}^m_{++}$ is a positive definite constant matrix.
To derive the time-derivative of $V$, we need the following lemma. -->
</div>
</div>
<div id="certainty-equivalent-adaptive-control" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Certainty-Equivalent Adaptive Control<a href="adaptivecontrol.html#certainty-equivalent-adaptive-control" class="anchor-section" aria-label="Anchor link to header"></a></h2>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-slotine91book-applied" class="csl-entry">
Slotine, Jean-Jacques E, Weiping Li, et al. 1991. <em>Applied Nonlinear Control</em>. Vol. 199. 1. Prentice hall Englewood Cliffs, NJ.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="13">
<li id="fn13"><p>Consider two positive definite matrices <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, let <span class="math inline">\(B = B^{1/2}B^{1/2}\)</span>. The product <span class="math inline">\(AB\)</span> can be written as <span class="math inline">\(AB = A B^{1/2}B^{1/2} = B^{-1/2} (B^{1/2} A B^{1/2}) B^{1/2}\)</span>. Therefore <span class="math inline">\(AB\)</span> is <a href="https://en.wikipedia.org/wiki/Matrix_similarity">similar</a> to <span class="math inline">\(B^{1/2} A B^{1/2}\)</span> and is positive definite.<a href="adaptivecontrol.html#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>In fact, one can show that the controller <a href="adaptivecontrol.html#eq:ac-mrac-manipulator-controller-unknownparam">(8.24)</a> with known parameters, i.e., <span class="math inline">\(\tau = Y a - K_D s\)</span>, also guarantees the convergence of <span class="math inline">\(s\)</span> towards zero, though it is different from the feedback linearization controller <a href="adaptivecontrol.html#eq:ac-mrac-manipulator-controller-knownparam">(8.23)</a>. Try proving the convergence with a Lyapunov candidate <span class="math inline">\(V = \frac{1}{2}s^T H s\)</span>.<a href="adaptivecontrol.html#fnref14" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="geometric-vision.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="psets.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/hankyang94/OptimalControlEstimation/blob/main/08-adaptivecontrol.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["optimal-control-estimation.pdf"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
