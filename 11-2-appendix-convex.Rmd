# Convex Analysis and Optimization {#appconvex}

## Theory {#appconvex-theory}

### Sets

Convex set is one of the most important concepts in convex optimization. Checking convexity of sets is crucial to determining whether a problem is a convex problem. Here we will present some definitions of some set notations in convex optimization.

::: {.definitionbox}
::: {.definition #affineset name="Affine set"}
  A set $C\subset \mathbb{R}^n$ is affine if the line through any two distinct points in $C$ lies in $C$, i.e., if for any $x_1,x_2 \in C$ and any $\theta \in \mathbb{R}$, we have $\theta x_1 + (1-\theta)x_2 \in C$.
:::
:::

::: {.definitionbox}
::: {.definition #convexset name="Convex set"}
  A set $C\subset \mathbb{R}^n$ is convex if the line segment between any two distinct points in $C$ lies in $C$, i.e., if for any $x_1,x_2 \in C$ and any $\theta \in [0,1]$, we have $\theta x_1 + (1-\theta)x_2 \in C$.
:::
:::

::: {.definitionbox}
::: {.definition #cone name="Cone"}
  A set $C\subset \mathbb{R}^n$ is a cone if for any $x\in C$ and any $\theta\geq 0$, we have $\theta x \in C$.
:::
:::

::: {.definitionbox}
::: {.definition #convexcone name="Convex Cone"}
  A set $C\subset \mathbb{R}^n$ is a convex cone if $C$ is convex and a cone.
:::
:::

Below are some important examples of convex sets:

::: {.definitionbox}
::: {.definition #hyperplane name="Hyperplane"}
  A hyperplane is a set of the form $$\{x|a^Tx = b\}$$
:::
:::

::: {.definitionbox}
::: {.definition #halfspaces name="Halfspaces"}
  A (closed) halfspace is a set of the form $$\{x|a^Tx \leq b\}$$
:::
:::

::: {.definitionbox}
::: {.definition #balls name="Balls"}
  A ball is a set of the form $$B(x,r) = \{y|\|y-x\|_2 \leq r\} = \{x+ru|\|u\|_2\leq 1\}$$
  where $r >0$.
:::
:::

::: {.definitionbox}
::: {.definition #ellipsoids name="Ellipsoids"}
  A ellipsoid is a set of the form $$\mathcal{E} = \{y|(y-x)^TP^{-1}(y-x)\leq 1\}$$
  where $P$ is symmetric and positive definite.
:::
:::

::: {.definitionbox}
::: {.definition #polyhedra name="Polyhedra"}
  A polyhedra is defined as the solution set of a finite number of linear equalities
and inequalities: $$\mathcal{P} = \{x|a_j^Tx\leq b_j, j=1,...,m, c_k^Tx=d_k,k=1,...,p\}$$
:::
:::

::: {.definitionbox}
::: {.definition #normball name="Norm ball"}
  A norm ball $B$ of radius $r$ and a center $x_c$ associated with the norm $\|\cdot\|$ is defined as: $$B = \{x|\|x-x_c\|\leq r\}$$
:::
:::

::: {.definitionbox}
::: {.definition #normcone name="Norm cone"}
  A norm cone $C$ associated with the norm $\|\cdot\|$ is defined as: $$C = \{(x,t)|\|x\|\leq t\}\subset \mathbb{R}^{n+1}$$
:::
:::

Simplexes are important family of polyhedra. Suppose the $k+1$ points $v_0,...,v_k\in \mathbb{R}^n$ are affinely independent, which means $v_1-v_0,...,v_k-v_0$ are linearly independent.

::: {.definitionbox}
::: {.definition #simplex name="Simplex"}
  A simplex $C$ defined by points $v_0,...,v_k$ is: $$C = \textbf{conv}\{v_0,...,v_k\} = \{\theta_0v_0 + ... \theta_kv_k|\theta \succeq 0, \textbf{1}^T\theta = 1\}$$
:::
:::

Extremely important examples of convex sets are positive semidefinite cones:

::: {.definitionbox}
::: {.definition #symmetricmatrices name="Symmetric,positive semidefinite,positive definite matrices"}
  1. Symmetric matrices: $\textbf{S}^n = \{X\in\mathbb{R}^{n\times n}| X=X^T\}$
  2. Symmetric Positive Semidefinite matrices: $\textbf{S}_+^n = \{X\in\textbf{S}^n| X\succeq0\}$
  3. Symmetric Positive definite matrices: $\textbf{S}_{++}^n = \{X\in\textbf{S}^n| X\succ0\}$
:::
:::

In most scenarios, the set we encounter is more complicated. In general it is extermely hard to determine whether a set in convex or not. But if the set is 'generated' by some convex sets, we can easily determine its convexity. So let's focus on operations that preserve convexity:

::: {.theorembox}
::: {.proposition #operationpreserveconvexity}
  Assume $S$ is convex, $S_\alpha,\alpha\in\mathcal{A}$ is a family of convex sets. Following operations on convex sets will preserve convexity:
  
  1. Intersection: $\bigcap_{\alpha\in\mathcal{A}}S_\alpha$ is convex.
  
  2. Image under affine function: A function $f:\mathbb{R}^n\to\mathbb{R}^m$ is affine if it has the form $f(x) = Ax+b$. The image of $S$ under affine function $f$ is convex. I.e. $f(S) = \{f(x)|x\in S\}$ is convex
  
  3. Image under perspective function: We define the perspective function $P:\mathbb{R}^{n+1}$, with domain $\textbf{dom}P = \mathbb{R}^n\times \mathbb{R}_{++}$(where $\mathbb{R}_{++}=\{x\in \mathbb{R}|x>0\}$) as $P(z,t) = z/t$. The image of $S$ under perspective function is convex.
  
  4. Image under linear-fractional function: We define linear fractional function $f:\mathbb{R}^n\to\mathbb{R}^m$ as:$f(x) = (Ax+b)/(c^Tx+d)$ with $\textbf{dom}f = \{x|c^Tx+d>0\|$. The image of $S$ under linear fractional functions is convex.
:::
:::

In some cases, the restrictions of **interior** is too strict. For example, imagine a plane in $\mathbb{R}^3$. The interior of the plane is $\emptyset$. But intuitively many property should be extended to this kind of situation. Because the points in the plane also lies 'inside' the convex set. Thus, we will define **relative interior**. First we will define **affine hull**.

::: {.definitionbox}
::: {.definition #affinehull name="Affine hull"}
  The affine hull of a set $S$ is the smallest affine set that contains $S$, which can be written as:
  $$\text{aff}(S) = \{\sum_{i=1}^k\alpha_ix_i|k>0,x_i\in S,\alpha_i\in\mathbb{R},\sum_{i=1}^k\alpha_i=1\}$$
:::
:::

::: {.definitionbox}
::: {.definition #relint name="Relative Interior"}
  The relative interior of a set $S$ (denoted $\text{relint}(S)$) is defined as its interior within the affine hull of $S$. I.e.
  $$\text{relint}(S):=\{x\in S: \text{there exists } \epsilon>0 \text{ such that }N_\epsilon \cap \text{aff}(S)\subset S\}$$
  where $N_\epsilon(x)$ is a ball of radius $\epsilon$ centered on $x$.
:::
:::

### Convex function {#appconvex-theory-convexfunction}

In this section, let's define convex functions:

::: {.definitionbox}
::: {.definition #defcvxfunc name="Convex function"}
  A function $f:\mathbb{R}^n\to\mathbb{R}$ is **convex** if $\textbf{dom}\ f$ is convex and $\forall x,y\in \textbf{dom}\ f$ and with $\theta \in [0,1]$, we have:$$f(\theta x +(1-\theta)y)\leq \theta f(x) + (1-\theta)f(y)$$
  The function is **strictly convex** if the inequality holds whenever $x\neq y$ and $\theta\in (0,1)$.
:::
:::

If a function is differentiable, it will be easier for us to check its convexity:

::: {.theorembox}
::: {.proposition #decidecvx name="Conditions for Convex function"}

  1.(First order condition) Suppose $f$ is differentiable, then $f$ is convex if and only if $\textbf{dom} f$ is convex and $\forall x,y\in \textbf{dom} f$, $$f(y)\geq f(x) +\nabla f(x)^T(y-x)$$
  2.(Second order conditions) Suppose $f$ is twice differentiable, then $f$ is convex if and only if $\textbf{dom} f$ is convex and $\forall x\in \textbf{dom} f$, $$\nabla^2 f(x) \succeq \textbf{0}$$

:::
:::

For the same purpose, some operations that preserve the convexity of the convex functions are presented here:

::: {.theorembox}
::: {.proposition #preservecvx name="Operations that preserve convexity"}
  Let $f:\mathbb{R}^n\to\mathbb{R}$ be a convex function and $g_1,...,g_n$ be convex functions. The following operations will preserve convexity of the function:
  
  1.(Nonnegative weighted sum): A nonnegative weighted sum of convex functions: $$f = \omega_1f_1 + ... +\omega_mf_m$$
  
  2.(Composition with an affine mapping) Suppose $A\in \mathbb{R}^{n\times m}$ and $b\in \mathbb{R}^n$, then $g(x) = f(Ax+b)$ is convex.
  
  3.(Pointwise maximum and supremum) $g(x) = \max\{g_1(x),...,g_n(x)\}$ is convex. If $h(x,y)$ is convex in $x$ for each $y\in\mathcal{A}$, then $\sup_{y\in\mathcal{A}} h(x,y)$ is also convex in $x$.
  
  4.(Minimization) If $h(x,y)$ is convex in $(x,y)$, and $C$ is a convex nonempty set, then $\inf_{x\in C} h(x,y)$ is convex in $x$.
  
  5.(Perspective of a function) The perspective of $f$ is the function $h:\mathbb{R}^{n+1}\to\mathbb{R}$ defined by: $h(x,t) = tf(x/t)$ with domain $\textbf{dom}\ h=\{(x,t)|x/t\in\textbf{dom} f,t>0\}$. And $h$ is convex.

:::
:::


### Lagrange dual {#lagrangian-dual}

We consider an optimization problem in the standard form (without assuming convexity of anything):
\begin{equation}
\begin{aligned}
p^* = \quad \min_{x} \quad & f_0(x)\\
\textrm{s.t.} \quad & f_i(x)\leq 0\quad i=1...,m\\
  & h_i(x) = 0\quad i=1,...,p   \\
\end{aligned}
\end{equation}

::: {.definitionbox}
::: {.definition #defdualfunc name="Lagrange dual function"}
  The Lagrangian related to the problem above is defined as: $$L(x,\lambda,\nu)=f_0(x)+\sum_{i=1}^m\lambda_if_i(x)+\sum_{i=1}^p\nu_ih_i(x)$$
  The Lagrange dual function is defined as: $$g(\lambda,\nu) = \inf_{x\in\mathcal{D}}L(x,\lambda,\nu)$$
:::
:::

When the Lagrangian is unbounded below in $x$, the dual function takes on the value $-\infty$. Note that since the Lagrange dual function is a pointwise infimum of a family of affine functions of $(\lambda,\nu)$, so it's concave. The Lagrange dual function will give us lower bounds of the optimal value of the original problem: $$g(\lambda,\nu)\leq p^*$$. We can see that, the dual function can give a nontrivial lower bound only when $\lambda\succeq 0$. Thus we can solve the following dual problem to get the best lower bound.

::: {.definitionbox}
::: {.definition #defdualprob name="Lagrange dual problem"}
  The lagrangian dual problem is defined as follows:
  \begin{equation}
  \begin{aligned}
  d^* = \quad \max_{\lambda,\nu} \quad & g(\lambda,\nu)\\
  \textrm{s.t.} \quad & \lambda\succeq 0
  \end{aligned}
  \end{equation}
  This is a convex optimization problem.
:::
:::

We can easily see that $$d^*\leq p^*$$ always hold. This property is called **weak duality**. If $$d^*=p^*$$, it's called **strong duality**. Strong duality does not hold in general, but it usually holfs for convex problems. We can find conditions that guarantee strong duality in convex problems, which are called constrained qualifications. Slater's constraint qualification is a useful one.

::: {.theorembox}
::: {.theorem #slater name="Slater's constraint qualification"}
  Strong duality holds for a convex problem
 \begin{equation}
  \begin{aligned}
  p^* = \quad \min_{x} \quad & f_0(x)\\
  \textrm{s.t.} \quad & f_i(x)\leq 0\quad i=1...,m\\
    & Ax=b   \\
  \end{aligned}
 \end{equation}
  if it is strictly feasible, i.e.
  $$\exists x\in\textbf{relint}\mathcal{D}:\quad f_i(x)<0,\quad i=1...m,\quad Ax=b$$
  And the linear inequalities do not need to hold with strict inequality.
:::
:::

### KKT condition {#appconvex-theory-kkt}
 Note that if strong duality holds, denote $x^*$ to be primal optimal, and $(\lambda^*,\nu^*)$ to be dual optimal. Then:

 
   \begin{equation}
  \begin{aligned}
  f_0(x^*) = g(\lambda^*,\nu^*) = & \inf_x(f_0(x)+\sum_{i=1}^m\lambda_i^*f_i(x)+\sum_{i=1}^p\nu_i^*h_i(x))\\
 \leq & f_0(x^*)+\sum_{i=1}^m\lambda_i^*f_i(x)+\sum_{i=1}^p\nu_i^*h_i(x)\\
 \leq & f_0(x^*)\\
  \end{aligned}
  \end{equation}
  
  from this, combining $\lambda^*\geq 0$ and $f_i(x^*)\leq 0$, we can know that: $\lambda_i^*f_i(x^*)=0\quad i=1\cdots m$. This means for $\lambda_i^*$ and $f_i(x^*)$, one of them must be zero, which is known as complementary slackness).
  
 Thus we arrived at the following four conditions, which are called KKT conditions.
 
::: {.theorembox}
::: {.theorem #KKT name="Karush-Kuhn-Tucker(KKT) Conditions"}
  The following four conditions are called KKT conditions (for a problem with differentiable $f_i,h_i$)
  
  1. Primal feasible: $f_i(x) \leq 0,i,\cdots ,m,\ h_i(x) = 0,i=1,\cdots ,p$
  2. Dual feasible: $\lambda\succeq0$
  3. Complementary slackness: $\lambda_if_i(x)=0,i=1,\cdots,m$
  4. Gradient of Lagrangian with respect to $x$ vanishes:$\nabla f_0(x)+\sum_{i=1}^m\lambda_i\nabla f_i(x)+\sum_{i=1}^p\nu_i\nabla h_i(x) = 0$
:::
:::

From the discussion above, we know that if strong duality holds and $x,\lambda,\nu$ are optimal, then they must satisfy the KKT conditions. 

Also if $x,\lambda,\nu$ satisfy KKT for a convex problem, then they are optimal. However, the converse is not generally true, since KKT condition implies strong duality. If Slater's condition is satisfied, then $x$ is optimal if and only if there exist $\lambda,\nu$ that satisfy KKT conditions. Sometimes, by solving the KKT system, we can derive the closed-form solution of a optimization directly. Also, sometimes we will use the residual of the KKT system as the termination condition.

In general, $f_i,h_i$ may not be differentiable. There are also KKT conditions for them, which will include knowledge of subdifferential and will not be included here.

## Practice {#appconvex-practice}

### CVX Introduction

In the last section, we have learned basic concepts and theorems in convex optimization. In this section, on the other hand, we will introduce you how to model basic convex optimization problems with CVX, an easy-to-use MATLAB package. To install CVX, please refer to this [page](http://cvxr.com/cvx/doc/install.html). Note that every time you what to use the CVX package, you should add it to your MATLAB path. For example, if I install CVX package in the parent directory of my current directory with default directory name `cvx`, the following line should be added before your CVX codes:

```matlab
addpath(genpath("../cvx/"));
```

With CVX, it is incredibly easy for us to define and solve a convex optimization problem. You just need to:

1. define the variables.

2. define the objective function you want to minimize or maximize.

3. define the constraints.

After running your codes, the optimal objective value is stored in the variable `cvx_optval`, and the problem status is stored in the variable `cvx_status` (when your problem is well-defined, this variable's value will be `Solved`). The optimal solutions will be stored in the variables you define. 

Throughout this section, we will study five types of convex optimization problems: linear programming (LP), quadratic programming (QP), (convex) quadratically constrained quadratic programming (QCQP), second-order cone programming (SOCP), and semidefinite programming (SDP). Given two types of optimization problems $A$ and $B$, we say $A < B$ if $A$ can always be converted to $B$ while the inverse is not true. Under this notation, we have
\begin{equation*}
   \text{LP} < \text{QP} < \text{QCQP} < \text{SOCP} < \text{SDP}
\end{equation*}

### Linear Programming (LP)

**Definition.** An LP has the following form:
\begin{equation}
   (\#eq:app-lpdef)
   \begin{aligned}
      \min_{x \in \mathbb{R}^n} & \ c^T x \\
      \text{subject to } & A x \le b  
   \end{aligned}
\end{equation}
where $x$ is the variable, $A \in \mathbb{R}^{m\times n}, b \in \mathbb{R}^m$, and $c \in \mathbb{R}^n$ are the parameters. Note that the constraint $A x \le b$ already incorporates linear equality constraints. To see this, consider the constraint $A' x = b'$, we can reformulate it as $A x \le b$ by
\begin{equation*}
   \begin{bmatrix}
      A' \\ -A'
   \end{bmatrix} x \le \begin{bmatrix}
      b' \\ -b'
   \end{bmatrix}
\end{equation*}

**Example.** Consider the problem of minimizing a linear function $c_1 x_1 + c_2 x_2$ over a rectangle $[-l_1, l_1] \times [-l_2, l_2]$. We can convert it to the standard LP form in \@ref(eq:app-lpdef) by simply setting $c$ as $[c_1, \ c_2]^T$ and the linear inequality constraint as 
\begin{equation*}
   \begin{bmatrix}
      1 & 0 \\ -1 & 0 \\ 0 & 1 \\ 0 & -1
   \end{bmatrix} \begin{bmatrix}
      x_1 \\ x_2
   \end{bmatrix} \le \begin{bmatrix}
      l_1 \\ l_1 \\ l_2 \\ l_2
   \end{bmatrix}
\end{equation*}

Corresponding CVX codes are shown below: 
```matlab
%% Define the LP example setting
c1 = 2;
c2 = -5;
l1 = 3;
l2 = 7;
% parameters: c, A, b
c = [c1; c2];
A = [1, 0; -1, 0; 0, 1; 0, -1];
b = [l1; l1; l2; l2];

%% solve LP
cvx_begin
    variable x(2); % define variables [x1, x2]
    minimize(c' * x); % define the objective
    subject to
        A * x <= b; % define the linear constraint
cvx_end
```

### Quadratic Programming (QP)

**Definition.** A QP has the following form:
\begin{align}
   (\#eq:app-qpdef)
   \min_{x \in \mathbb{R}^n} \ & \frac{1}{2} x^T P x + q^T x \\
   \text{subject to } & Gx \le h \\
   & Ax = b
\end{align}
where $P \in \mathcal{S}_+^n, q\in \mathbb{R}^n, G \in \mathbb{R}^{m \times n}, h\in \mathbb{R}^m, A \in \mathbb{R}^{p \times n}, b \in \mathbb{R}^p$. Here $\mathcal{S}_+^n$ denotes the set of positive semidefinite matrices of size $n\times n$. Obviously, if we set $P$ as zero, QP will degenerate to LP.

**Example.** Consider the problem of minimizing a quadratic function
\begin{equation*}
   f(x_1, x_2) = p_1 x_1^2 + 2p_2 x_1 x_2 + p_3 x_2^2 + q_1 x_1 + q_2 x_2
\end{equation*}
over a rectangle $[-l_1, l_1] \times [-l_2, l_2]$. Since $P = 2 \begin{bmatrix}
   p_1 & p_2 \\ p_2 & p_3
\end{bmatrix} \succeq 0$, the following two conditions must hold:
\begin{equation*}
   \begin{cases}
      p_1 \ge 0 \\
      p_1 p_3 - 4 p_2^2 \ge 0
   \end{cases}
\end{equation*}
Same as in the LP example, $G$ and $h$ can be expressed as:
\begin{equation*}
   \begin{bmatrix}
      1 & 0 \\ -1 & 0 \\ 0 & 1 \\ 0 & -1
   \end{bmatrix} \begin{bmatrix}
      x_1 \\ x_2
   \end{bmatrix} \le \begin{bmatrix}
      l_1 \\ l_1 \\ l_2 \\ l_2
   \end{bmatrix}
\end{equation*}

Corresponding CVX codes are shown below:
```matlab
%% Define the QP example setting
p1 = 2;
p2 = 0.5;
p3 = 4;
q1 = -3;
q2 = -6.5;
l1 = 2;
l2 = 2.5;
% check if the generated P is positive semidefinite
tmp1 = (p1 >= 0);
tmp2 = (p1*p3 - 4*p2^2 >= 0);
if ~(tmp1 && tmp2)
    error("P is not positve semidefinite!");
end
% parameters: P, q, G, h
P = 2 * [p1, p2; p2, p3];
q = [q1; q2];
G = [1, 0; -1, 0; 0, 1; 0, -1];
h = [l1; l1; l2; l2];

%% Solve the QP problem
cvx_begin
    variable x(2); % define variables [x1; x2]
    % define the objective, where quad_form(x, P) = x'*P*x
    obj = 0.5 * quad_form(x, P) + q' * x; 
    minimize(obj); 
    subject to
        G * x <= h; % define the linear constraint
cvx_end
```

### Quadratically Constrained Quadratic Programming (QCQP)

**Definition.** An (convex) QCQP has the following form:
\begin{align}
   (\#eq:app-qcqpdef)
   \min_{x \in \mathbb{R}^n} \ & \frac{1}{2} x^T P_0 x + q_0^T x \\
   \text{subject to } & \frac{1}{2} x^T P_i x + q_i^T x + r_i \le 0, \ i = 1 \dots m \\
   & Ax = b
\end{align}
where $P_i \in \mathcal{S}_+^n, i = 0 \dots m$, $q_i \in \mathbb{R}^n, i = 0 \dots m$, $A \in \mathbb{R}^{p \times n}$, and $b \in \mathbb{R}^p$. Note that in other literature, you may find a more general form of QCQP: they don't require $P_i$'s to be positive semidefinite. Yet in this case, the problem is non-convex and beyond our scope. 

**Example.** We study the problem of getting the minimum distance between two ellipses. By convention, when the ellipses overlap, we set the minimum distance as $0$. This problem can be exactly solved by (convex) QCQP.
Consider two ellipses of the following form:
\begin{equation*}
   \begin{cases}
      \frac{1}{2} \begin{bmatrix} y_1 \\ z_1 \end{bmatrix}^T K_1 \begin{bmatrix} y_1 \\ z_1 \end{bmatrix}
      + k_1^T \begin{bmatrix} y_1 \\ z_1 \end{bmatrix} + c_1 \le 0 \\ 
      \frac{1}{2} \begin{bmatrix} y_2 \\ z_2 \end{bmatrix}^T K_2 \begin{bmatrix} y_2 \\ z_2 \end{bmatrix}
      + k_2^T \begin{bmatrix} y_2 \\ z_2 \end{bmatrix} + c_2 \le 0 \\ 
   \end{cases}
\end{equation*}
where $[y_1, z_1]^T$ and $[y_2, z_2]^T$ are arbitrary points inside the two ellipses respectively. Also, two ensure the ellipses are well defined, we should enforce the following properties in $(K_i, k_i, c_i), i = 1, 2$: (1) $K_i \succ 0$; (2) Let $K_i =  L_i L_i^T$ be the Cholesky decomposition of $K_i$. Then, ellipse $i$ can be rewritten as:
\begin{equation*}
   \frac{1}{2} \parallel L_i^T \begin{bmatrix} y_i \\ z_i \end{bmatrix} - L_i^{-1} k_i \parallel^2 \le 
   \frac{1}{2} \parallel L_i^{-1} k_i \parallel^2 - c_i
\end{equation*}
Thus, 
\begin{equation*}
   \frac{1}{2} \parallel L_i^{-1} k_i \parallel^2 - c_i > 0
\end{equation*}
With these two assumptions, we want to minimize:
\begin{equation*}
   \frac{1}{2} (y_1 - y_2)^2 + (z_1 - z_2)^2
\end{equation*}

Now, we construct $P, q, r$'s in QCQP with the above parameters. Define the variable $x$ as $[y_1, z_1, y_2, z_2]$.

(1) $P_0$ can be obtained from:
\begin{equation*}
   \frac{1}{2} (y_1 - y_2)^2 + (z_1 - z_2)^2 = \frac{1}{2} \begin{bmatrix}
      y_1 \\ z_1 \\ y_2 \\ z_2
   \end{bmatrix}^T \begin{bmatrix}
      1 & 0 & -1 & 0 \\ 0 & 1 & 0 & -1 \\ -1 & 0 & 1 & 0 \\ 0 & -1 & 0 & 1
   \end{bmatrix} \begin{bmatrix}
      y_1 \\ z_1 \\ y_2 \\ z_2
   \end{bmatrix}
\end{equation*} 

(2) $P_1, q_1, r_1$ can be obtained from:
\begin{equation*}
   \frac{1}{2} \begin{bmatrix} y_1 \\ z_1 \end{bmatrix}^T K_1 \begin{bmatrix} y_1 \\ z_1 \end{bmatrix}
      + k_1^T \begin{bmatrix} y_1 \\ z_1 \end{bmatrix} + c_1 
   = \frac{1}{2} x^T \begin{bmatrix}
      K_1 & O \\ O & O
   \end{bmatrix} + \begin{bmatrix}
      k_1 \\ O 
   \end{bmatrix}^T x + c_1 \le 0
\end{equation*}

(2) $P_2, q_2, r_2$ can be obtained from:
\begin{equation*}
   \frac{1}{2} \begin{bmatrix} y_2 \\ z_2 \end{bmatrix}^T K_2 \begin{bmatrix} y_2 \\ z_2 \end{bmatrix}
      + k_2^T \begin{bmatrix} y_2 \\ z_2 \end{bmatrix} + c_2
   = \frac{1}{2} x^T \begin{bmatrix}
      O & O \\ O & K_2
   \end{bmatrix} + \begin{bmatrix}
      O \\ k_2
   \end{bmatrix}^T x + c_2 \le 0
\end{equation*}

The corresponding codes are shown below. In this example, we test the minimum distance between a circle $y_1^2 + z_1^2 \le 1$ and another circle $(y_2 - 2)^2 + (z_2 - 2)^2 \le 1$. You can check whether the result from QCQP aligns with your manual calculation.

```matlab
%% Define the QCQP example setting
K1 = eye(2);
k1 = zeros(2, 1);
c1 = -0.5;
K2 = eye(2);
k2 = [2; 2];
c2 = 3.5;
if ~(if_ellipse(K1, k1, c1) && if_ellipse(K2, k2, c2))
    error("The example setting is not correct");
end
% define parameters P0, P1, P2, q1, q2, r1, r2
P0 = [1,0,-1,0; 0,1,0,-1; -1,0,1,0; 0,-1,0,1];
P1 = zeros(4, 4);
P1(1:2, 1:2) = K1;
P2 = zeros(4, 4);
P2(3:4, 3:4) = K2;
q1 = [k1; zeros(2, 1)];
q2 = [zeros(2, 1); k2];
r1 = c1;
r2 = c2;

%% Solve the QCQP problem
cvx_begin
    variable x(4); % define variables [y1; z1; y2; z2]
    % define the objective, where quad_form(x, P) = x'*P*x
    obj = 0.5 * quad_form(x, P0); 
    minimize(obj); 
    subject to
        0.5 * quad_form(x, P1) + q1' * x + r1 <= 0;
        0.5 * quad_form(x, P2) + q2' * x + r2 <= 0;
cvx_end

%% detect whether (K, k, c) generates a ellipse
function flag = if_ellipse(K, k, c)
    L = chol(K);
    radius_square = 0.5 * norm(L \ k)^2 - c; % L \ k = inv(L) * k
    flag = (radius_square > 0);
end
```

### Second-Order Cone Programming (SOCP)

**Definition.** An SOCP has the following form: 
\begin{align}
   (\#eq:app-socpdef)
   \min_{x \in \mathbb{R}^n} \ & f^T x \\
   \text{subject to } & || A_i x + b_i ||_2 \le c_i^T x + d_i, \ i = 1 \dots m \\
   & Fx = g
\end{align}
where $f \in \mathbb{R}^n, A_i \in \mathbb{R}^{n_i \times n}, b_i \in \mathbb{R}^{n_i}, c_i \in \mathbb{R}^n, d_i \in \mathbb{R}, F \in \mathbb{R}^{p \times n}$, and $g \in \mathbb{R}^p$.

**Example.** We consider the problem of stochastic linear programming:
\begin{align}
   \min_x \ & c^T x \\
   \text{subject to } & \mathbb{P}(a_i^T x \le b_i) \ge p, \ i = 1 \dots m \\
   & a_i \sim \mathcal{N}(\bar{a}_i, \Sigma_i), \ i = 1 \dots m
\end{align}
Here $p$ should be more than $0.5$. We show that this problem can be converted to a SOCP:

Since $a_i \sim \mathcal{N}(\bar{a}_i, \Sigma_i)$, then $(a_i^T x - b_i) \sim \mathcal{N}(\bar{a}_i^T x - b_i, x^T \Sigma_i x)$. Standardize it:
\begin{equation*}
   t := ||\Sigma_i^{\frac{1}{2}} x||_2^{-1} \left\{ (a_i^T x - b_i) - (\bar{a}_i^T x - b_i) \right\} \sim \mathcal{N}(0, 1)
\end{equation*} 
Then, 
\begin{align}
   \mathbb{P}(a_i^T x \le b_i) & = \mathbb{P}(a_i^T x - b_i \le 0) \\
   & = \mathbb{P}(t \le -||\Sigma_i^{\frac{1}{2}} x||_2^{-1}(\bar{a}_i^T x - b_i)) \\
   & = \Phi(-||\Sigma_i^{\frac{1}{2}} x||_2^{-1}(\bar{a}_i^T x - b_i))
\end{align}
Here $\Phi(\cdot)$ is the cumulative distribution function of the standard normal distribution:
\begin{equation*}
   \Phi(\xi) = \int_{-\infty}^{\xi} e^{-\frac{1}{2} t^2} \ dt
\end{equation*}
Thus, 
\begin{align}
   & \mathbb{P}(a_i^T x \le b_i) \ge p \\
   \Longleftrightarrow & \Phi(-||\Sigma_i^{\frac{1}{2}} x||_2^{-1}(\bar{a}_i^T x - b_i)) \ge p \\
   \Longleftrightarrow & -||\Sigma_i^{\frac{1}{2}} x||_2^{-1}(\bar{a}_i^T x - b_i) \ge \Phi^{-1}(p) \\
   \Longleftrightarrow & \Phi^{-1}(p) ||\Sigma_i^{\frac{1}{2}} x||_2 \le b_i - \bar{a}_i^T x
\end{align}
which is exactly the same as inequality constraints in SOCP formulation. (You can see why we enforce $p > 0.5$ here: otherwise $\Phi^{-1}(p)$ will be negative and the constraint with not be an second-order cone.)

In the following code example, we set up four inequality constraints and let $\bar{a}_i^T x \le b_i, \ i = 1 \dots 4$ form an square located at the origin of size $2$. Then, for convenience, we set $\Sigma_i \equiv \sigma^2 I$. 

```matlab
%% Define the SOCP example setting
bar_a1 = [1; 0];
b1 = 1;
bar_a2 = [0; 1];
b2 = 1;
bar_a3 = [-1; 0];
b3 = 1;
bar_a4 = [0; -1];
b4 = 1;
sigma = 0.1; 
c = [2; 3];
p = 0.9; % p should be more than 0.5
Phi_inv = norminv(p); % get Phi^{-1}(p)

%% Solve the SOCP problem
cvx_begin
    variable x(2); % define variables [x1; x2]
    minimize(c' * x); 
    subject to
        sigma*Phi_inv * norm(x) <= b1 - bar_a1' * x;
        sigma*Phi_inv * norm(x) <= b2 - bar_a2' * x;
        sigma*Phi_inv * norm(x) <= b3 - bar_a3' * x;
        sigma*Phi_inv * norm(x) <= b4 - bar_a4' * x;
cvx_end
```

### Semidefinite Programming (SDP)

**Definition.** An SDP has the following form:
\begin{align}
   (\#eq:app-sdpdef)
   \min_{X_i, x_i} \ & \sum_{i=1}^{n_s} C_i \cdot X_i + \sum_{i=1}^{n_u} c_i \cdot x_i \\
   \text{subject to } & \sum_{i=1}^{n_s} A_{i,j} \cdot X_i + \sum_{i=1}^{n_u} a_{i,j} \cdot x_i = b_j, \quad j = 1 \dots m \\
   & X_i \in \mathcal{S}_+^{D_i}, \quad i = 1 \dots n_s \\
   & x_i \in \mathbb{R}^{d_i}, \quad i = 1 \dots n_u  
\end{align}
where $C_i, A_{i, j} \in \mathbb{R}^{D_i \times D_i}$, $c_i, a_{i, j} \in \mathbb{R}^{d_i}$, and $\cdot$ means element-wise product. For two square matrices $A, B$, the dot product $A \cdot B$ is equal to $\text{tr}(A B)$; for two vectors $a, b$, the dot product $a \cdot b$ is the same as inner product $a^T b$.

Note that actually there are many "standard" forms of SDP. For example, in the convex optimization theory part, you may find an SDP that looks like:
\begin{align}
   \min_X \ & C \cdot X \\
   \text{subject to } & A \cdot X = b \\
   & X \succeq 0
\end{align}
It is convenient for us to analyze the theoretical properties of SDP with this form. Also, in SDP solvers' User Guide, you may see more complex SDP forms which involve more general convex cones. For example, see [MOSEK's MATLAB API docs](https://docs.mosek.com/10.0/toolbox/tutorial-sdo-shared.html#doc-tutorial-sdo). Here we turn to use the form of \@ref(eq:app-sdpdef) for two reasons: (1) it is general enough: our SDP example below can be converted to this form (also, SDPs from sum-of-squares programming in this book are exactly of the form \@ref(eq:app-sdpdef)); (2) it is more readable than more complex forms.

**Example.** We consider the problem of finding the minimum eigenvalue for a positive semidefinite matrix $S$. We will show that this problem can be converted to \@ref(eq:app-sdpdef). Since $S$ is positive semidefinite, the finding procedure can be cast as 
\begin{align}
    \max_\lambda & \ \lambda \\
    \text{subject to } & S - \lambda I \succeq 0
\end{align}
Now define an auxiliary matrix $X := S - \lambda I$. We have
\begin{align}
    \min_{\lambda, X} & \ -\lambda \\
   \text{subject to } &  X + \lambda I = S \\
   & X \succeq 0
\end{align}
It is obvious that the linear matrix equality constraint $X + \lambda I = S$ can be divided into several linear scalar equality constraints in \@ref(eq:app-sdpdef). For example, we consider $S \in \mathbb{S}_+^3$. Thereby $X + \lambda I = S$ will lead to $6$ linear equality constraints (We don't consider $X$ is a symmetric matrix here, since most solvers will implicitly consider this. Thus, only the upper-triangular part of $X$ and $S$ are actually used in the equality construction.):
\begin{align}
   &  \begin{bmatrix}
      1 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 0
   \end{bmatrix} \cdot X  + \lambda = S[0, 0],  
    \begin{bmatrix}
      0 & 1 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 0
   \end{bmatrix} \cdot X  = S[0, 1],
    \begin{bmatrix}
      0 & 0 & 1 \\ 0 & 0 & 0 \\ 0 & 0 & 0
   \end{bmatrix} \cdot X  = S[0, 2] \\
   &  \begin{bmatrix}
      0 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 0
   \end{bmatrix} \cdot X  + \lambda = S[1, 1],
    \begin{bmatrix}
      0 & 0 & 0 \\ 0 & 0 & 1 \\ 0 & 0 & 0
   \end{bmatrix} \cdot X  = S[1, 2], 
    \begin{bmatrix}
      0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 1
   \end{bmatrix} \cdot X  + \lambda = S[2, 2] 
\end{align}
Seems tedious? Fortunately, CVX provides a high-level API to handle these linear equality constraints: you just need to write down 

```matlab
X + lam * eye(3) == S; % linear equality constraints: X + lam *I = S
```

CVX will autometically convert this high-level constraint to \@ref(eq:app-sdpdef) and pass them to the underlying solver.

To generate a ramdom $S \in \mathcal{S}_+^3$, you just need to assign three nonnegative eigenvalues to the program. After that, an random $S$ will be generated by $S = Q \ \text{diag}(\lambda_1, \lambda_2, \lambda_3) \ Q^T$, where $Q$ is random orthonormal matrix.  

```matlab
%% Define the SDP example setting
lam_list = [0.7; 2.4; 3.7];
S = generate_random_PD_matrix(lam_list); % get a PD matrix S

%% Solve the SDP problem
cvx_begin
    variable X(3, 3) symmetric;
    variable lam; 
    maximize(lam); 
    subject to
        % here "==" should be read as "is in"
        X == semidefinite(3); 
        X + lam * eye(3) == S;
cvx_end

% this function help to generate PD matrix of size 3*3 
% if you provide the eigenvalues [lam_1, lam_2, lam_3]
function S = generate_random_PD_matrix(lam_list)
    if ~all(lam_list >= 0) % all eigenvalues >= 0
        error("All eigenvalues must be nonnegative.");
    end
    D = diag(lam_list);
    % use QR factorization to generate a random orthonormal matrix Q
    [Q, ~] = qr(rand(3, 3));
    S =  Q * D * Q';
end
```

### CVXPY Introduction and Examples

Apart from CVX MATLAB, we also have a Python package called CVXPY, which functions almost the same as CVX MATLAB. To define and solve a convex optimization problem CVXPY, basically, there are three steps (apart from importing necessary packages):

- Step 1: Define parameters and variables in a certain type of convex problem. Here variables are what you are trying to optimize or "learn". Parameters are the "coefficients" of variables in the objective and constraints. 

- Step 2: Define the objective function and constraints.

- Step 3: Solve the problem and get the results.

Here we provide the CVXPY codes for the above five convex optimization examples.

#### LP

```python
import cvxpy as cp
import numpy as np

## Define the LP example setting
c1 = 2
c2 = -5
l1 = 3
l2 = 7

## Step 1: define variables and parameters
x = cp.Variable(2) # variable: x = [x1, x2]^T
# parameters: c, A, b
c = np.array([c1, c2]) 
A = np.array([[1, 0], [-1, 0], [0, 1], [0, -1]])
b = np.array([l1, l1, l2, l2])

## Step 2: define objective and constraints
obj = cp.Minimize(c.T @ x)
constraints = [A @ x <= b]
prob = cp.Problem(obj, constraints) # form the problem

## Step 3: solve problem and get results
prob.solve()  
print("status: ", prob.status) # check whether the status is "optimal"
print("optimal value: ", prob.value) # optimal objective
print("optimal solution: ", x.value) # optimal x
```

#### QP

```python
import cvxpy as cp
import numpy as np

## Define the LP example setting
p1 = 2
p2 = 0.5
p3 = 4
q1 = -3
q2 = -6.5
l1 = 2
l2 = 2.5
# check if the generated P is positive semidefinite
tmp1 = (p1 >= 0)
tmp2 = (p1*p3 - 4*p2**2 >= 0)
assert(tmp1 and tmp2, "P is not positve semidefinite!")

## Step 1: define variables and parameters
x = cp.Variable(2) # variable: x = [x1, x2]^T
# parameters: P, q, G, h
P = 2*np.array([[p1, p2], [p2, p3]])
q = np.array([q1, q2]) 
G = np.array([[1, 0], [-1, 0], [0, 1], [0, -1]])
h = np.array([l1, l1, l2, l2])

## Step 2: define the objective and constraints
fx = 0.5 * cp.quad_form(x, P) + q.T @ x
obj = cp.Minimize(fx)
constraints = [G @ x <= h]
prob = cp.Problem(obj, constraints) # form the problem

## Step 3: solve the problem and get results
prob.solve()  
print("status: ", prob.status) # check whether the status is "optimal"
print("optimal value: ", prob.value) # optimal objective
print("optimal solution: ", x.value) # optimal x
```

#### QCQP

```python
import cvxpy as cp
import numpy as np
from numpy.linalg import cholesky, inv, norm

## Define the QCQP example setting
def if_ellipse(K, k, c):
    # examine whether 0.5*x^T K x + k^T x + c <= 0 is a ellipse
    # if K is not positive semidefinite, Cholesky will raise an error
    L = cholesky(K) 
    radius_square = 0.5 * norm(inv(L) @ k)**2 - c
    return radius_square > 0
K1 = np.eye(2)
k1 = np.zeros(2)
c1 = -0.5
K2 = np.array([[1, 0], [0, 1]])
k2 = np.array([2, 2])
c2 = 3.5
if not (if_ellipse(K1, k1, c1) and if_ellipse(K2, k2, c2)):
    raise ValueError("The example setting is not correct")

## Step 1: define variables and parameters
P0 = np.array([[1,0,-1,0], [0,1,0,-1], [-1,0,1,0], [0,-1,0,1]])
P1 = np.zeros((4,4))
P1[:2, :2] = K1
P2 = np.zeros((4,4))
P2[2:, 2:] = K2
q1 = np.concatenate([k1, np.zeros(2)])
q2 = np.concatenate([np.zeros(2), k2])
r1 = c1
r2 = c2

## Step 2: define objective and constraints
x = cp.Variable(4) # variable: x = [y1, z1, y2, z2]^T
fx = 0.5 * cp.quad_form(x, P0)
obj = cp.Minimize(fx)
con1 = (0.5 * cp.quad_form(x, P1) + q1.T @ x + r1 <= 0) # ellipse 1
con2 = (0.5 * cp.quad_form(x, P2) + q2.T @ x + r2 <= 0) # ellipse 2
constraints = [con1, con2]
prob = cp.Problem(obj, constraints) # form the problem

## Step 3: solve problem and get results
prob.solve()  
print("status: ", prob.status) # check whether the status is "optimal"
print("optimal value: ", prob.value) # optimal objective
print("optimal solution: ", x.value) # optimal x
```

#### SOCP

```python
import cvxpy as cp
import numpy as np
from scipy.stats import norm

## Define the SOCP example setting
# define bar_ai, bi (i = 1, 2, 3, 4)
bar_a1 = np.array([1, 0])
b1 = 1
bar_a2 = np.array([0, 1])
b2 = 1
bar_a3 = np.array([-1, 0])
b3 = 1
bar_a4 = np.array([0, -1])
b4 = 1
sigma = 0.1 
c = np.array([2, 3])
p = 0.9 # p should be more than 0.5

## Step 1: define variables and parameters
Phi_inv = norm.ppf(p) # get Phi^{-1}(p)

## Step 2: define objective and constraints
x = cp.Variable(2) # variable: x = [x1, x2]^T
obj = cp.Minimize(c.T @ x)
# use cp.SOC(t, x) to create the SOC constraint ||x||_2 <= t
constraints = [
    cp.SOC(b1 - bar_a1.T @ x, sigma*Phi_inv*x),
    cp.SOC(b2 - bar_a2.T @ x, sigma*Phi_inv*x),
    cp.SOC(b3 - bar_a3.T @ x, sigma*Phi_inv*x),
    cp.SOC(b4 - bar_a4.T @ x, sigma*Phi_inv*x),
]
prob = cp.Problem(obj, constraints) # form the problem

## Step 3: solve problem and get results
prob.solve()  
print("status: ", prob.status) # check whether the status is "optimal"
print("optimal value: ", prob.value) # optimal objective
print("optimal solution: ", x.value) # optimal x
```

#### SDP

```python
import cvxpy as cp
import numpy as np
from scipy.stats import ortho_group

## Define the SDP example setting
# this function help to generate PD matrix of size 3*3 
# if you provide the eigenvalues [lam_1, lam_2, lam_3]
def generate_random_PD_matrix(lam_list):
    assert np.all(lam_list >= 0) # all eigenvalues >= 0
    # S = Q @ D @ Q.T
    D = np.diag(lam_list)
    Q = ortho_group.rvs(3)
    return Q @ D @ Q.T
lam_list = np.array([0.5, 2.4, 3.7])
S = generate_random_PD_matrix(lam_list) # get a PD matrix S

## Step 1: define variables and parameters
# get coefficients for equality constraints
A_00 = np.array([[1, 0, 0], [0, 0, 0], [0, 0, 0]]) # tr(A_00 @ X) + lam = S_00
A_01 = np.array([[0, 1, 0], [0, 0, 0], [0, 0, 0]]) # tr(A_01 @ X) = S_01
A_02 = np.array([[0, 0, 1], [0, 0, 0], [0, 0, 0]]) # tr(A_02 @ X) = S_02
A_11 = np.array([[0, 0, 0], [0, 1, 0], [0, 0, 0]]) # tr(A_11 @ X) + lam = S_11
A_12 = np.array([[0, 0, 0], [0, 0, 1], [0, 0, 0]]) # tr(A_12 @ X) = S_12
A_22 = np.array([[0, 0, 0], [0, 0, 0], [0, 0, 1]]) # tr(A_22 @ X) + lam = S_22

## Step 2: define objective and constraints
# define a PD matrix variable X of size 3*3
X = cp.Variable((3, 3), symmetric=True)
constraints = [X >> 0] # the operator >> denotes matrix inequality
lam = cp.Variable(1)
constraints += [
    cp.trace(A_00 @ X) + lam == S[0,0],
    cp.trace(A_01 @ X) == S[0,1],
    cp.trace(A_02 @ X) == S[0,2],
    cp.trace(A_11 @ X) + lam == S[1,1],
    cp.trace(A_12 @ X) == S[1,2],
    cp.trace(A_22 @ X) + lam == S[2,2],
]
obj = cp.Minimize(-lam)
prob = cp.Problem(obj, constraints) # form the problem

## Step 3: solve problem and get results
prob.solve()  
print("status: ", prob.status) # check whether the status is "optimal"
print("optimal value: ", prob.value) # optimal objective
print("optimal solution: ", lam.value) # optimal lam
```
